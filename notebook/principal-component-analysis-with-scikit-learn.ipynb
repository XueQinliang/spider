{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"d31499e5-ebd1-e178-1ced-16f82608db96"},"source":"Here I am going to apply Principal component analysis on the given dataset using Scikit-learn and find out the dimensions(also known as components) with maximum variance(where the data is spread out).Features with little variance in the data are then projected into new lower dimension. Then the models are  trained on transformed dataset to apply machine learning models.Then I have applied  Random forest Regressor on old and the transformed datasets and compared them.\nIf you want to know the basic concept behind Principal Component Analysis check this out.\n(https://www.kaggle.com/nirajvermafcb/d/ludobenistant/hr-analytics/principal-component-analysis-explained)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e7f0ba99-5629-9e26-85ac-1660eb33f056"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"61e8090a-db25-b4c6-3635-514217f78bb4"},"outputs":[],"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2682c5c2-b2ab-d65f-9d39-6fd4b96d075a"},"outputs":[],"source":"df=pd.read_csv('../input/data.csv') #Replace it with your path where the data file is stored\ndf.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c7ae0580-f900-4153-631f-069d0f242e35"},"outputs":[],"source":"df.describe()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4d2dbc2b-9d1e-7935-9e51-213a2f451c7c"},"outputs":[],"source":"df.corr()"},{"cell_type":"markdown","metadata":{"_cell_guid":"c3382394-548d-1b77-dd06-8f1f914571e4"},"source":"Let us find if there is any relationship between temperature and apparent_temperature"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0857d200-a5db-3776-4d4e-0ee4f7338f06"},"outputs":[],"source":"x=df['temperature']\ny=df['apparent_temperature']\ncolors=('r','b')\nplt.xlabel('Temperature')\nplt.ylabel('Apparent_temperature')\nplt.scatter(x,y,c=colors)"},{"cell_type":"markdown","metadata":{"_cell_guid":"bf7a5858-5f8e-5279-508f-1e571dc14f19"},"source":"The temperture given here is in fahrenheit.We will convert it into Celsius using the formula \n**Celsius=(Fahrenheit-32)* (5/9)**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"189df387-8b1c-5571-9bf8-9ffbc2a73993"},"outputs":[],"source":"Fahrenheit=df['temperature']"},{"cell_type":"markdown","metadata":{"_cell_guid":"d3b7aafd-37bf-87cc-5fdc-91c09f719997"},"source":"Converting it into the list so we can apply lambda function"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f64c0a50-d66b-a657-60be-7947f78a8ee0"},"outputs":[],"source":"F=Fahrenheit.tolist()"},{"cell_type":"markdown","metadata":{"_cell_guid":"8aacb499-e91b-b33a-aec5-fde3a2dff657"},"source":"Applying Lambda function"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5cbbc763-da62-45f5-6db2-de6deb0f3af2"},"outputs":[],"source":"C= map(lambda x: (float(5)/9)*(x-32),F)\nCelsius=(list(C))"},{"cell_type":"markdown","metadata":{"_cell_guid":"867da8e1-89a3-e26b-f9c7-6a12f0e09d2c"},"source":"Converting list to series"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a9fabe25-0a84-7408-264c-2397b7d1ee80"},"outputs":[],"source":"temperature_celsius=pd.Series(Celsius)"},{"cell_type":"markdown","metadata":{"_cell_guid":"f0b6b71b-773b-c36e-de3b-5082a11e352e"},"source":"Applying the series to temperature column"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9372df8e-2f2e-ea95-bd7e-9be7f9595596"},"outputs":[],"source":"df['temperature']= temperature_celsius\ndf['temperature']\ndf.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"4ae4e2bb-6651-da25-3d4f-90b8a60b0c0b"},"source":"Thus we have converted the temperature column from fahrenheit to degree celsius.Similarly we are now converting apparent_temperature to degree celsius."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7a858452-ad77-926e-f6be-c8fccc1064ec"},"outputs":[],"source":"at_fahrenheit=df['apparent_temperature']\nat_F=at_fahrenheit.tolist()\nat_C= map(lambda x: (float(5)/9)*(x-32),at_F)\nat_Celsius=(list(C))\nat_celsius=pd.Series(at_Celsius)\nat_celsius"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a732ddf5-a9bb-8d87-329a-225b080ea27c"},"outputs":[],"source":"apparent_temperature_celsius=pd.Series(at_Celsius)\nprint(apparent_temperature_celsius)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5511a760-b87f-3023-f9c9-0c72580436d6"},"outputs":[],"source":"df['apparent_temperature']= temperature_celsius\ndf['apparent_temperature']\ndf.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"68fa682d-a05f-65d1-0f9b-e3adf58660be"},"outputs":[],"source":"X = df.iloc[:,1:8]  # all rows, all the features and no labels\ny = df.iloc[:, 0]  # all rows, label only\n#X\n#y"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f2f628d5-74b1-9533-615c-b67ad4f368d7"},"outputs":[],"source":"df.corr()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ce87ea95-ecb9-6efd-3edb-aad6f36b0c18"},"outputs":[],"source":"correlation = df.corr()\nplt.figure(figsize=(10,10))\nsns.heatmap(correlation, vmax=1, square=True,annot=True,cmap='viridis')\n\nplt.title('Correlation between different fearures')"},{"cell_type":"markdown","metadata":{"_cell_guid":"dfbae261-e10b-74fa-c330-ebfaad9c7bc4"},"source":"Standardising data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"190f9d7e-9527-0a7a-1bb4-cc163016ffe3"},"outputs":[],"source":"# Scale the data to be between -1 and 1\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX=scaler.fit_transform(X)\nX"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"985295c0-1ef4-5ddb-a048-e85cc21e2360"},"outputs":[],"source":"from sklearn.decomposition import PCA\npca = PCA()\npca.fit_transform(X)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"37a76d04-29fe-9a20-4d0c-a686a18cca29"},"outputs":[],"source":"pca.get_covariance()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c7f9ec22-472e-4458-2d85-02c24bc92a33"},"outputs":[],"source":"explained_variance=pca.explained_variance_ratio_\nexplained_variance"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a836f786-1fb1-9cf2-24ba-b48ff82f9c68"},"outputs":[],"source":"with plt.style.context('dark_background'):\n    plt.figure(figsize=(6, 4))\n\n    plt.bar(range(7), explained_variance, alpha=0.5, align='center',\n            label='individual explained variance')\n    plt.ylabel('Explained variance ratio')\n    plt.xlabel('Principal components')\n    plt.legend(loc='best')\n    plt.tight_layout()"},{"cell_type":"markdown","metadata":{"_cell_guid":"2e8f750b-b7e3-f5aa-0a26-048739a4ee70"},"source":"**Thus we can see from the above plot that  first two components constitute almost 55% of the variance.Third,fourth and fifth components has 42% of the data sprad.The last component has less than 5% of the variance.Hence we can drop the fifth component  **"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4bf9dda2-bd49-123a-b210-a0eebde4e143"},"outputs":[],"source":"pca=PCA(n_components=5)\nX_new=pca.fit_transform(X)\nX_new"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5e24ed72-560f-ea4d-8666-828a08433d6a"},"outputs":[],"source":"pca.get_covariance()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f0912408-e4fc-fecc-3c31-65d94105eca5"},"outputs":[],"source":"explained_variance=pca.explained_variance_ratio_\nexplained_variance"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9dff6023-b064-81a7-b2d7-fbee96ec70c4"},"outputs":[],"source":"with plt.style.context('dark_background'):\n    plt.figure(figsize=(6, 4))\n\n    plt.bar(range(5), explained_variance, alpha=0.5, align='center',\n            label='individual explained variance')\n    plt.ylabel('Explained variance ratio')\n    plt.xlabel('Principal components')\n    plt.legend(loc='best')\n    plt.tight_layout()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"76356efb-11b9-3941-952d-c4a67d6a3e23"},"outputs":[],"source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\nX_train.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aeebfae2-3b4e-f06a-c120-7e71736566b7"},"outputs":[],"source":"# Establish model\nfrom sklearn.ensemble import RandomForestRegressor\nmodel = RandomForestRegressor()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"47f50275-827a-8941-996d-6df5684b54fb"},"outputs":[],"source":"# Try different numbers of n_estimators - this will take a minute or so\nestimators = np.arange(10, 200, 10)\nscores = []\nfor n in estimators:\n    model.set_params(n_estimators=n)\n    model.fit(X_train, y_train)\n    scores.append(model.score(X_test, y_test))\nprint(scores)    "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6f65d7b5-9a32-a330-0516-7bc96bf59bfd"},"outputs":[],"source":"plt.title(\"Effect of n_estimators\")\nplt.xlabel(\"n_estimator\")\nplt.ylabel(\"score\")\nplt.plot(estimators, scores)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3af5a41f-c928-8af7-6068-cbed122e82fb"},"outputs":[],"source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=1)\nX_train.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cf626a49-27f4-f251-9947-7efef301a670"},"outputs":[],"source":"# Establish model\nfrom sklearn.ensemble import RandomForestRegressor\nmodel = RandomForestRegressor()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bc9c5949-9c05-9864-0612-24b0b5904fa3"},"outputs":[],"source":"# Try different numbers of n_estimators - this will take a minute or so\nestimators = np.arange(10, 200, 10)\nscores = []\nfor n in estimators:\n    model.set_params(n_estimators=n)\n    model.fit(X_train, y_train)\n    scores.append(model.score(X_test, y_test))\nprint(scores)    "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"65834f80-dac5-656a-12b9-11b4fbe3f6c5"},"outputs":[],"source":"plt.title(\"Effect of n_estimators\")\nplt.xlabel(\"n_estimator\")\nplt.ylabel(\"score\")\nplt.plot(estimators, scores)"},{"cell_type":"markdown","metadata":{"_cell_guid":"27e1f2de-bb02-a4d5-b061-06644da0ba51"},"source":"You can find my notebook on Github:\n(\"https://github.com/nirajvermafcb/Data-Science-with-python\")"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}