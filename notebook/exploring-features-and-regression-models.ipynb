{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"93d49a5e-2d07-6965-c05b-8005cb19d386"},"source":"# House prices"},{"cell_type":"markdown","metadata":{"_cell_guid":"fd4d73b6-8bfb-78c1-b9fe-bd7a5b264a5e"},"source":"We will analyze and preprocess features of the dataset.\n\nWe will remove unimportant features according to Lasso regression.\n\nWe will improve linear model with transforming target variable.\n\nWe will compare several regression models."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3dfea807-a502-03b1-492e-979e94574acb"},"outputs":[],"source":"%matplotlib inline\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom matplotlib import cm\nfrom sklearn import preprocessing, manifold, linear_model, metrics, model_selection, ensemble\nimport seaborn as sns"},{"cell_type":"markdown","metadata":{"_cell_guid":"43465ec8-4c57-79e5-1c4e-299e0c3083e7"},"source":"## Reading data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1f3de092-d4ea-2fef-6c75-ff32b838d8d8"},"outputs":[],"source":"data_train = pd.read_csv('../input/train.csv')\ndata_test = pd.read_csv('../input/test.csv')\ndata_train.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a70995a5-632d-afff-6131-279f3eb0e22f"},"outputs":[],"source":"data_train.info()"},{"cell_type":"markdown","metadata":{"_cell_guid":"aa31404c-d5e7-6f6a-0814-13c4d79146dd"},"source":"## Let's look at the prices (targets)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"545827e8-1817-3d77-9b8f-221d9ac22caf"},"outputs":[],"source":"pd.concat([data_train, data_test])['SalePrice'].plot(kind='hist', bins=20, title='Price frequency')"},{"cell_type":"markdown","metadata":{"_cell_guid":"84e62e99-30bd-b042-82e8-8b2ca25e003a"},"source":"## Processing features"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9a19b3d3-50aa-9636-aee3-f39d50ef7fa9"},"outputs":[],"source":"# set features and labels (removing Id from features)\nX, y = data_train.iloc[:,1:-1], data_train['SalePrice']\nX_test = data_test.iloc[:,1:]"},{"cell_type":"markdown","metadata":{"_cell_guid":"a66e6bb1-ba09-9458-c368-236dfbdf99f0"},"source":"### Understanding feature types"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0f3f5154-9e6a-58b7-e52f-857baafe366f"},"outputs":[],"source":"X_all = pd.concat([X, X_test])\n\n# Convert CentralAir to binary feature\nX_all['CentralAir'] = X_all['CentralAir'].apply(lambda x: 1 if x=='Y' else 0)\n\n# Convert MSSubClass to categorial feature\nX_all['MSSubClass'] = X_all['MSSubClass'].astype(str)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79dc4339-6ee4-56f3-f05e-11b0cee0ba57"},"outputs":[],"source":"# types of features\nbinary_features = ['CentralAir']\ncategorial_features = X_all.select_dtypes(include=[object]).columns.values \nnumeric_features = X_all.select_dtypes(exclude=[object]).columns.values\nnumeric_features = np.delete(numeric_features, np.argwhere(numeric_features=='CentralAir'))"},{"cell_type":"markdown","metadata":{"_cell_guid":"f90e9a5b-4473-16a6-8705-75325aa6ee35"},"source":"### Process missing values"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3fd0b302-76e7-4431-9a86-1d418f6fc2a7"},"outputs":[],"source":"nans = X_all.isnull().sum()\nnans = nans[nans > 0]\nprint(nans)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6ab0d0ea-6b7c-a455-e413-df0b6c853f03"},"outputs":[],"source":"# 'MiscFeature' and 'PoolQC' have more than 96% nan values, so we can remove them\nto_remove = ['MiscFeature', 'PoolQC']\nX_all.drop(to_remove, axis=1, inplace=True)\ncategorial_features = categorial_features[~np.in1d(categorial_features, to_remove)]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"99410daa-dd5e-3bf6-0101-bb4c58e74a30"},"outputs":[],"source":"# For following categorial columns change NaN for most frequent values\nnan2frequent = ['MasVnrType', 'Electrical', 'MSZoning', 'Utilities']\nfor column in nan2frequent:\n    X_all[column].fillna(X_all[column].value_counts().idxmax(), inplace=True)\n\n# For following categorial columns change NaN for new NA category\nnan2new = categorial_features[np.in1d(categorial_features, nan2frequent, invert=True)]\nfor column in nan2new:\n    X_all[column].fillna('NA', inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"69084a47-cf78-1cdc-9884-e3831d6375e3"},"outputs":[],"source":"# Numeric features with NaN\nnans = X_all[numeric_features].isnull().sum()\nnan2numeric = nans[nans > 0].index.values\nprint(nan2numeric)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"20d0a1c7-75f3-1f86-8125-284b741bc583"},"outputs":[],"source":"# Let's look on the distribution of numerical features with many NaNs\nX_all[['LotFrontage', 'MasVnrArea', 'GarageYrBlt']].hist(bins=80, figsize=(10,5))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"30068241-487c-7831-bfa5-76261117e15e"},"outputs":[],"source":"# Replace NaNs with medians (for mean they are too skewed)\nfor column in nan2numeric:\n    X_all[column].fillna(X_all[column].median(), inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"16982f6d-59c3-4264-9646-e1527d6d09d6"},"outputs":[],"source":"# Check that we didn't miss anything\nnans = X_all.isnull().sum()\nprint(nans[nans > 0])"},{"cell_type":"markdown","metadata":{"_cell_guid":"9275bf33-e3aa-915b-cabd-95554e271b7a"},"source":"### Explore categorial features"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f941de25-d632-0a56-f3ad-f00a6f8731af"},"outputs":[],"source":"fig, axes = plt.subplots(9, 5, figsize=(15, 30))\nfor i, feature in enumerate(categorial_features):\n    sns.countplot(x=feature, data=X_all, ax=axes[i//5][i%5])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"af99e16a-8379-6d3a-33d2-1f395e124a81"},"outputs":[],"source":"print(X_all['Street'].value_counts())\nprint(X_all['Utilities'].value_counts())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"521da976-17be-5461-cd9d-716ef6a3e602"},"outputs":[],"source":"# Remove Street and Utilities features\nto_remove = ['Street', 'Utilities']\nX_all.drop(to_remove, axis=1, inplace=True)\ncategorial_features = categorial_features[~np.in1d(categorial_features, to_remove)]"},{"cell_type":"markdown","metadata":{"_cell_guid":"d09a1ccf-e468-3ecf-3ed8-6571e5996c8d"},"source":"### Explore numeric features"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e1d1e935-2917-6e04-23f2-5909e5f883a8"},"outputs":[],"source":"expl_data = X_all[:data_train.shape[0]][numeric_features]\nexpl_data['SalePrice'] = y\n# heatmap\nplt.figure(figsize=(12, 8))\nsns.heatmap(expl_data.corr())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d3ffd178-6d3f-1437-62c3-6d0fdec5f9ea"},"outputs":[],"source":"# Select features poorly correlated with target\nbad_features = ['BsmtFinSF2', 'LowQualFinSF', 'BsmtHalfBath', '3SsnPorch', 'ScreenPorch', \n                'PoolArea', 'MiscVal', 'MoSold', 'YrSold']\nexpl_data[bad_features].hist(bins=20, figsize=(9, 9))\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1218ec7d-33aa-52de-f5d3-8bf003999035"},"outputs":[],"source":"# Remove first 3 of these features because almost all their values are 0\nto_remove = ['BsmtFinSF2', 'LowQualFinSF', 'BsmtHalfBath']\nX_all.drop(to_remove, axis=1, inplace=True)\nnumeric_features = numeric_features[~np.in1d(numeric_features, to_remove)]"},{"cell_type":"markdown","metadata":{"_cell_guid":"cd0163f4-8734-b1b3-523a-eda931633de4"},"source":"### Categorical features encoding"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7f321046-68c4-3253-cd19-0a595f8ae06c"},"outputs":[],"source":"# encode with dummy features\nX_all = pd.get_dummies(data=X_all, columns=categorial_features)\nX_all.info()"},{"cell_type":"markdown","metadata":{"_cell_guid":"fe7dae16-0feb-9ea3-abe6-9e12a23be456"},"source":"### Scaling features"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4a70118e-e73c-e38b-b042-06ee513635b3"},"outputs":[],"source":"scaler = preprocessing.StandardScaler()\nX_all[numeric_features] = scaler.fit_transform(X_all[numeric_features])\nX_all.info()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"273f3da3-8f6d-a33c-d4f8-56675045fe7a"},"outputs":[],"source":"# extract train and test parts of the data\nX = X_all[:data_train.shape[0]]\nX_test = X_all[data_train.shape[0]:]\nprint(X.shape, X_test.shape)"},{"cell_type":"markdown","metadata":{"_cell_guid":"2ac3c66a-657f-3019-bfb6-137eb225f342"},"source":"## Visualizing data"},{"cell_type":"markdown","metadata":{"_cell_guid":"55850d2a-4bf9-ab45-6132-fd1af0077022"},"source":"For visualizing let's divide the data on 6 price categories"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5f4d62d6-2d9d-b837-fd77-bd987c430c02"},"outputs":[],"source":"def price_category(y):\n    cl = pd.Series(index=y.index)\n    cl[y < 100000] = 0\n    cl[(y >= 100000) & (y < 150000)] = 1\n    cl[(y >= 150000) & (y < 200000)] = 2\n    cl[(y >= 200000) & (y < 250000)] = 3\n    cl[(y >= 250000) & (y < 300000)] = 4\n    cl[y >= 300000] = 5\n    return cl\nprice_classes = price_category(y)\nlabels = ['<100K', '100-150K', '150-200K', '200-250K', '250-300K', '>300K']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b4a2b9c0-ad7d-b271-43ea-ab445e626e72"},"outputs":[],"source":"from sklearn.manifold import MDS\nmds = MDS(random_state=123)\nMDS_transformed = mds.fit_transform(X)\n\nplt.figure(figsize=(10, 8))\ncolors = cm.rainbow(np.linspace(0, 1, 6))\nfor cls, color, label in zip(range(6), colors, labels):\n    plt.scatter(MDS_transformed[price_classes.values==cls, 0], \n                MDS_transformed[price_classes.values==cls, 1], c=color, alpha=0.5, label=label)\nplt.legend()"},{"cell_type":"markdown","metadata":{"_cell_guid":"6363b023-b462-e740-e5b7-3ddd1944a72e"},"source":"We can make out different price categories on the plot"},{"cell_type":"markdown","metadata":{"_cell_guid":"0bcb33e8-9b6f-a714-d83f-82b9fec75e4a"},"source":"## Linear regression"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"057c3323-98eb-49c4-aaf5-895012df773e"},"outputs":[],"source":"# Root mean squared logarithmic error (RMSLE) - underprediction is penalized greater than overprediction\ndef rmsle_score(y, p):\n    return -np.sqrt(np.sum((np.log(1+y) - np.log(1+p))**2)/y.shape[0])\nrmsle = metrics.make_scorer(rmsle_score)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6cf25d77-9ca9-e689-2487-d09a0cd97236"},"outputs":[],"source":"# Ridge regression: Count RMSLE on cross-validation\nparam_grid = {\n              'alpha': [0.5, 1, 2, 6, 10, 15, 20, 30, 40, 50, 75, 100, 125, 150],\n             }\n\nridge = linear_model.Ridge()\nridge_gs = model_selection.GridSearchCV(ridge, param_grid, cv=3, scoring=rmsle)\nridge_gs.fit(X, y)\nprint(ridge_gs.best_score_)\nprint(ridge_gs.best_params_)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"944d5f7b-ee27-a577-6021-8b5dfa34a1d0"},"outputs":[],"source":"plt.plot([item['alpha'] for item in ridge_gs.cv_results_['params']], \n         [-item for item in ridge_gs.cv_results_['mean_test_score']])\nplt.xlabel('alpha')\nplt.ylabel('RSMLE')\nplt.title('Ridge grid search')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a3de4b5d-7cc2-0d63-41b9-c789e797c165"},"outputs":[],"source":"# Lasso regression\nparam_grid = {\n              'alpha': [75, 100, 125, 150, 175],\n             }\nlasso = linear_model.Lasso()\nlasso_gs = model_selection.GridSearchCV(lasso, param_grid, cv=3, scoring=rmsle)\nlasso_gs.fit(X, y)\nprint(lasso_gs.best_score_)\nprint(lasso_gs.best_params_)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"74a9eb6e-3473-a421-6bfb-017b4891a2c6"},"outputs":[],"source":"plt.plot([item['alpha'] for item in lasso_gs.cv_results_['params']], \n         [-item for item in lasso_gs.cv_results_['mean_test_score']])\nplt.xlabel('alpha')\nplt.ylabel('RSMLE')\nplt.title('Lasso grid search')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"52d7d429-50c1-15e8-3d9e-60d2c478bc2b"},"outputs":[],"source":"# Check how many coefficients become zero\ncoef = lasso_gs.best_estimator_.coef_\nnot_zero_indices = np.where(coef!=0)\n\n# Display most important features\nlarge_indices = np.where(abs(coef) >= 5000)\nplt.barh(range(len(large_indices[0])), coef[large_indices[0]])\nplt.yticks(range(len(large_indices[0])), X.columns[large_indices[0]])\nplt.title('Most imporant features')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"96564894-2638-0289-4226-d44217803487"},"outputs":[],"source":"# let's throw out unimportant features (that become zero in lasso regression)\nX_selected = X.iloc[:,not_zero_indices[0]]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"255be5bd-391d-e895-f41b-86300db019a2"},"outputs":[],"source":"# look at the residuals\npredicts = lasso_gs.best_estimator_.predict(X)\nplt.scatter(predicts, predicts-y, alpha=0.5)\nplt.xlabel('true y values')\nplt.ylabel('residuals')\nplt.show()\nprint('R2 score: %s' % metrics.r2_score(predicts, y))"},{"cell_type":"markdown","metadata":{"_cell_guid":"83093a45-d8f8-3b0e-02a9-96585ee95606"},"source":"We can see §Ñ tail going down a little bit, so it seems like target has some non-linear dependency. Let's try to take logarithm and square root of y."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fd17c01b-62be-29d7-5e2f-e35753493c34"},"outputs":[],"source":"# log of y\ny_log = np.log(y)\nplt.hist(y_log)\nplt.xlabel('log y')\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"93935b23-9abe-08d6-80b5-607ecf4e3239"},"outputs":[],"source":"# In case of log y Ridge regression perfoms better. \nparam_grid = {\n              'alpha': [0.005, 0.01, 0.05, 1],\n             }\nridge = linear_model.Ridge()\nridge_gs = model_selection.GridSearchCV(ridge, param_grid, cv=3, scoring=rmsle)\nridge_gs.fit(X_selected, y_log)\nprint(ridge_gs.best_score_)\nprint(ridge_gs.best_params_)\n\n# the real score\nridge_regr = ridge_gs.best_estimator_\npredicts = ridge_regr.predict(X_selected)\nrmsle_score(np.exp(y_log), np.exp(predicts))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0d911dfa-4bc5-9ca8-3f72-a30a72253d78"},"outputs":[],"source":"plt.scatter(np.exp(predicts), np.exp(predicts) - np.exp(y_log), alpha=0.5)\nplt.xlabel('true y values')\nplt.ylabel('residuals')\nplt.show()\nprint('R2 score: %s' % metrics.r2_score(np.exp(predicts), np.exp(y_log)))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b774aa8d-b4d4-4c44-42d0-bd501eaf00c2"},"outputs":[],"source":"# Square root of y\ny_root = np.sqrt(y)\nplt.hist(y_root)\nplt.xlabel('sqrt y')\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"733e944f-49be-75de-19d0-45f3be688afe"},"outputs":[],"source":"# Lasso regression for square root y\nparam_grid = {\n              'alpha': [0.005, 0.01, 0.05, 1],\n             }\nlasso = linear_model.Lasso()\nlasso_gs = model_selection.GridSearchCV(lasso, param_grid, cv=3, scoring=rmsle)\nlasso_gs.fit(X_selected, y_root)\nprint(lasso_gs.best_score_)\nprint(lasso_gs.best_params_)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8d03fc29-aa00-f589-cf08-eac3a491a6d5"},"outputs":[],"source":"# the real score\nlasso_regr = lasso_gs.best_estimator_\npredicts = lasso_regr.predict(X_selected)\nrmsle_score(y_root**2, predicts**2)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5dfab81f-de5f-4dbc-6fde-549778c68c5f"},"outputs":[],"source":"plt.scatter(predicts**2, predicts**2 - y_root**2, alpha=0.5)\nplt.xlabel('true y values')\nplt.ylabel('residuals')\nplt.show()\nprint('R2 score: %s' % metrics.r2_score(predicts**2, y_root**2))"},{"cell_type":"markdown","metadata":{"_cell_guid":"e0750813-aa50-10e7-7808-f7ade59f8f5e"},"source":"Square root y transformation performs slightly better. \n\nLet's compare the achieved results with Random Forest and Gradient Boosting (XGBoost)."},{"cell_type":"markdown","metadata":{"_cell_guid":"dde19174-bd13-e33f-b33d-b522795794a3"},"source":"## Random Forest regression"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"33dbbbb1-d0cd-987c-944f-8d72e50611f3"},"outputs":[],"source":"# Tune hyperparameters with grid search\n# I've checked more values, this is just for example\nparam_grid = {\n              'n_estimators': [100, 200, 300],\n              'min_samples_leaf': [1, 3],  \n             }\nforest = ensemble.RandomForestRegressor()\nforest_gs = model_selection.GridSearchCV(forest, param_grid, cv=3, scoring=rmsle)\nforest_gs.fit(X_selected, y)\nprint(forest_gs.best_score_)\nprint(forest_gs.best_params_)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b37cfc4e-04b5-3ab5-8401-b3dbde2bf039"},"outputs":[],"source":"# look at the residuals\npredicts = forest_gs.best_estimator_.predict(X_selected)\nplt.scatter(predicts, predicts-y, alpha=0.5)\nplt.xlabel('true y values')\nplt.ylabel('residuals')\nplt.show()\nprint('R2 score: %s' % metrics.r2_score(predicts, y))"},{"cell_type":"markdown","metadata":{"_cell_guid":"c3ef5aeb-9698-1f27-ead2-d4f6be123dfd"},"source":"## XGBoost"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1182a00e-ddb0-0b68-0e22-533bacf299dd"},"outputs":[],"source":"import xgboost as xgb\nxgb_regressor = xgb.XGBRegressor()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6ff05fde-f6a9-c63e-3e0a-bc34f842546a"},"outputs":[],"source":"# Tune hyperparameters with grid search\n# I've checked more values, this is just for example\nparam_grid = {\n              'n_estimators': [400, 500],\n              'learning_rate': [0.05, 0.1],\n             }\nxgb_gs = model_selection.GridSearchCV(xgb_regressor, param_grid, cv=3, scoring=rmsle)\nxgb_gs.fit(X_selected, y)\nprint(xgb_gs.best_score_)\nprint(xgb_gs.best_params_)"},{"cell_type":"markdown","metadata":{"_cell_guid":"84efb2c9-fe93-7657-9d7e-bdfda8c52d41"},"source":"Learning rate = 0.05 and number of trees = 500 gives best results."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e7c60cc4-f87e-4e40-9b4d-cef4bf268235"},"outputs":[],"source":"# look at the residuals\npredicts = xgb_gs.best_estimator_.predict(X_selected)\nplt.scatter(predicts, predicts-y, alpha=0.5)\nplt.xlabel('true y values')\nplt.ylabel('residuals')\nplt.show()\nprint('R2 score: %s' % metrics.r2_score(predicts, y))"},{"cell_type":"markdown","metadata":{"_cell_guid":"3f042e4a-297f-1476-eca9-49c81301db89"},"source":"## Conclusion\nTransforming the target variable with square root dramatically improves predictions with linear regression. The result is better than with Random Forest and XGBoost. "},{"cell_type":"markdown","metadata":{"_cell_guid":"9bb3168b-eeef-5700-71c6-0a76c7bb2702"},"source":"## Predict test data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"befff034-c68a-ca69-8e71-a28c644deb65"},"outputs":[],"source":"X_test_selected = X_test.iloc[:,not_zero_indices[0]]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ecaa54f3-49b0-93fc-108f-fdee3aa70be9"},"outputs":[],"source":"best_regressor = lasso_gs.best_estimator_ # Lasso regression {'alpha': 0.05}\nbest_regressor.fit(X_selected, y_root)\ny_test = best_regressor.predict(X_test_selected)\ny_test = y_test**2 # back to the real values\n\nresult_df = pd.DataFrame(columns=['Id', 'SalePrice'])\nresult_df.Id = data_test.Id\nresult_df.SalePrice = y_test\nresult_df.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2dd42581-6564-58b5-f0a0-ba89dfded2b5"},"outputs":[],"source":"result_df.to_csv('output.csv', index=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b9f240c3-e72e-d520-e418-f5d036453b38"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}