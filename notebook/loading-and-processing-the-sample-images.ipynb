{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"f67e5916-8513-11dd-7e9d-9658b2746ec7"},"source":"Here I'll go over the process of loading the DICOM images in python with pydicom and doing some light processing tasks on them"},{"cell_type":"markdown","metadata":{"_cell_guid":"d3057f76-ca54-7f6d-45a5-067dd6f79e07"},"source":"Initial Loading\n---------------"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"58703766-4072-95b6-2759-bbee39e96b2d"},"outputs":[],"source":"%pylab --no-import-all\n%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport dicom\nimport os\nimport scipy.ndimage\n\nimages_path = '../input/sample_images/'"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8d8d6628-d979-392b-991a-1065ffbb79d1"},"outputs":[],"source":"def get_3d_data(path):\n    slices = [dicom.read_file(path + '/' + s) for s in os.listdir(path)]\n    slices.sort(key = lambda x: int(x.InstanceNumber))\n    return np.stack([s.pixel_array for s in slices])"},{"cell_type":"markdown","metadata":{"_cell_guid":"f75bca7b-6bd1-a6e3-5ae4-4db171122df7"},"source":"the get_3d_data function above reads all the files, orders the slices, and returns all the data as a 3D numpy array. With that we can visualize slices in any planes on the data, or pass it directly as 3D data to a CNN"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1fc1ba20-9550-9168-4614-a08a75feb934"},"outputs":[],"source":"patients = os.listdir(images_path)\npatients.sort()\n\nsample_image = get_3d_data(images_path + patients[0])\nsample_image.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"01baf9a9-c829-2a92-6c02-46410b22c9ea"},"outputs":[],"source":"#the images have the unavailable pixel set to -2000, changing them to 0 makes the picture clearer\nsample_image[sample_image == -2000] = 0"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e85f7aeb-b54a-781a-17cb-761a214ccfe2"},"outputs":[],"source":"#same plane as the original data, cut at the Z axis\npylab.imshow(sample_image[100], cmap=pylab.cm.bone)\npylab.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fb3e8529-f8ae-7c21-b0bb-52d2e19c5561"},"outputs":[],"source":"#cut at the Y axis\npylab.imshow(sample_image[:, 100, :], cmap=pylab.cm.bone)\npylab.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9dd0a526-25d6-bce1-7608-646597db9d62"},"outputs":[],"source":"#cut at the X axis\npylab.imshow(sample_image[:, :, 100], cmap=pylab.cm.bone)\npylab.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b25d9ab5-53b3-f0c7-a272-95bd8736e4d7"},"outputs":[],"source":"#can also do some operations on the images directly, mostly useful for exploration\npylab.imshow(np.average(sample_image, 0), cmap=pylab.cm.bone)\npylab.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"0b6009b6-7ef1-4783-6f6e-8a95d03575ab"},"source":"Processing the Images\n---------------------"},{"cell_type":"markdown","metadata":{"_cell_guid":"84bfc725-dd28-1570-0767-efc257acf502"},"source":"It's often a good idea to pre-process the images before doing anything with them. In this case, it makes sense to normalize the images either by slice or as the 3D whole."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0b0aed29-3a3f-f7c7-93ea-54a8c825ce66"},"outputs":[],"source":"#remaping the image to 1 standard deviation of the average and clipping it to 0-1\nimg_std = np.std(sample_image)\nimg_avg = np.average(sample_image)\nstd_image = np.clip((sample_image - img_avg + img_std) / (img_std * 2), 0, 1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"130189f3-5583-b2cc-d299-cfb02e193580"},"outputs":[],"source":"#same cut as before, a bit easier to spot the features\npylab.imshow(std_image[100], cmap=pylab.cm.bone)\npylab.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"b999872b-4640-617d-e091-6d5e144c87f6"},"source":"Silly CNN example\n-----------------"},{"cell_type":"markdown","metadata":{"_cell_guid":"467ca48b-98fd-dbd4-240b-6791dba09733"},"source":"I'll show a quick example on how to process all the sample images and use them directly to train a CNN.\n\nI initially tried to just shove the 3D images on my GPU, but it didn't have enough RAM to handle the massive images, so I had to downsample them. Oddly enough, it still somewhat works."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5864b5e6-ab68-1763-dc39-b418427d2e1a"},"outputs":[],"source":"# load training labels\nlabels_csv = pd.read_csv(images_path + '../stage1_labels.csv', index_col='id')\n\n# Remove the (single) unlabbeled patient from our list\npatients = labels_csv.ix[patients].dropna().index\n\n# And finally get the training labels\ntrain_labels = labels_csv.ix[patients].cancer.astype(np.float16).as_matrix()\ntrain_labels = train_labels.reshape([len(train_labels), 1])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cb7122a7-c5af-dd04-970a-49f15edbd834"},"outputs":[],"source":"# Loads, resizes and processes the image\ndef process_image(path):\n    img = get_3d_data(path)\n    img[img == -2000] = 0\n    img = scipy.ndimage.zoom(img.astype(np.float), 0.25)\n    img_std = np.std(img)\n    img_avg = np.average(img)\n    return np.clip((img - img_avg + img_std) / (img_std * 2), 0, 1).astype(np.float16)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"82147d0b-23dd-8f91-f852-e79234417b77"},"outputs":[],"source":"train_features = np.zeros([len(patients), 1, 128, 128, 128], np.float16)\nfor i in range(len(patients)):\n    f = process_image(images_path + patients[i])\n    f = np.concatenate([f, np.zeros([128 - f.shape[0], 128, 128], np.float16)]) # Pads the image\n    f = f.reshape([1, 128, 128, 128]) # add an extra dimension for the color channel\n    train_features[i] = f\ntrain_features.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7ee695c9-edec-8b0b-47d4-96ddbcbedbc7"},"outputs":[],"source":"# This is a 5 minute CNN model roughly based on VGG, don't try to find any deep insights here, it's mostly random\nimport keras\n\nnn = keras.models.Sequential([\n        keras.layers.convolutional.Convolution3D(32, 3, 3, 3, border_mode='same', activation='relu', input_shape=train_features.shape[1:], dim_ordering='th'),\n        keras.layers.convolutional.MaxPooling3D((2, 2, 2), (2, 2, 2), dim_ordering='th'),\n        keras.layers.convolutional.Convolution3D(32, 3, 3, 3, border_mode='same', activation='relu', dim_ordering='th'),\n        keras.layers.convolutional.MaxPooling3D((2, 2, 2), (2, 2, 2), dim_ordering='th'),\n        keras.layers.convolutional.Convolution3D(64, 3, 3, 3, border_mode='same', activation='relu', dim_ordering='th'),\n        keras.layers.convolutional.MaxPooling3D((2, 2, 2), (2, 2, 2), dim_ordering='th'),\n        keras.layers.convolutional.Convolution3D(64, 3, 3, 3, border_mode='same', activation='relu', dim_ordering='th'),\n        keras.layers.convolutional.MaxPooling3D((2, 2, 2), (2, 2, 2), dim_ordering='th'),\n        keras.layers.convolutional.Convolution3D(128, 3, 3, 3, border_mode='same', activation='relu', dim_ordering='th'),\n        keras.layers.convolutional.MaxPooling3D((2, 2, 2), (2, 2, 2), dim_ordering='th'),\n        keras.layers.convolutional.Convolution3D(256, 3, 3, 3, border_mode='same', activation='relu', dim_ordering='th'),\n        keras.layers.convolutional.AveragePooling3D((4, 4, 4), dim_ordering='th'),\n        keras.layers.core.Flatten(),\n        keras.layers.core.Dense(32, activation='relu'),\n        keras.layers.BatchNormalization(),\n        keras.layers.core.Dense(1, activation='sigmoid')\n    ])\nnn.compile(optimizer=keras.optimizers.Adam(), loss='binary_crossentropy', metrics=['accuracy'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"56cd7981-9343-ab8e-5e0d-d7503583be35"},"outputs":[],"source":"# Finally train the CNN\n# nn.fit(train_features, train_labels, batch_size=1, validation_split=0.1, nb_epoch=1)"},{"cell_type":"markdown","metadata":{"_cell_guid":"b1083a29-5774-f9aa-ffa8-0f54dacc8c9e"},"source":"Not running the nn.fit here, the kernel worker doesn't seems to have a GPU, or there's some trick to getting Keras to use it. Here's my local output:\n\n    Train on 17 samples, validate on 2 samples\n    Epoch 1/10\n    17/17 [==============================] - 13s - loss: 0.6884 - acc: 0.6471 - val_loss: 0.6530 - val_acc: 1.0000\n    Epoch 2/10\n    17/17 [==============================] - 13s - loss: 0.6743 - acc: 0.7059 - val_loss: 0.6346 - val_acc: 1.0000\n    Epoch 3/10\n    17/17 [==============================] - 13s - loss: 0.6659 - acc: 0.7059 - val_loss: 0.6119 - val_acc: 1.0000\n    Epoch 4/10\n    17/17 [==============================] - 13s - loss: 0.6576 - acc: 0.7059 - val_loss: 0.5866 - val_acc: 1.0000\n    Epoch 5/10\n    17/17 [==============================] - 13s - loss: 0.6493 - acc: 0.7059 - val_loss: 0.5643 - val_acc: 1.0000\n    Epoch 6/10\n    17/17 [==============================] - 13s - loss: 0.6438 - acc: 0.7059 - val_loss: 0.5382 - val_acc: 1.0000\n    Epoch 7/10\n    17/17 [==============================] - 13s - loss: 0.6398 - acc: 0.7059 - val_loss: 0.5085 - val_acc: 1.0000\n    Epoch 8/10\n    17/17 [==============================] - 12s - loss: 0.6314 - acc: 0.7059 - val_loss: 0.5031 - val_acc: 1.0000\n    Epoch 9/10\n    17/17 [==============================] - 12s - loss: 0.6259 - acc: 0.7059 - val_loss: 0.4861 - val_acc: 1.0000\n    Epoch 10/10\n    17/17 [==============================] - 12s - loss: 0.6231 - acc: 0.7059 - val_loss: 0.4663 - val_acc: 1.0000\n\nNot too surprisingly, it was fitting the network, but with such a small sample size, it's unlikely to be able to produce anything else than an overfitted random number. It's unlikely this simplistic architecture will do anything with the still smallish full training set, but I'll probably try it just to see what happens.\n\nI'll probably add the final prediction and CSV generation soon too :-)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}