{"cells":[{"metadata":{"_uuid":"9d52bb00b8b17ad8e533d3f4aa0bc34e5f693245"},"cell_type":"markdown","source":"# Convolutional Neural Network to detect Pneumonia\n### This is my first successful attempt at a convolutional neural net. I'll walk you through the steps taken to complete this neural net."},{"metadata":{"_uuid":"16a37325d73ba834e33b7c3e166d40accc974dcb"},"cell_type":"markdown","source":"## Fundamental terms:\n### NB: Analogies used in this explanation of the fundamental terms are in a school/calinary school environment\n1. ** Overfitting **\n      Overfitting occurs when a neural network model memorises patterns in a dataset instead of learning the general idea/pattern of the data.\n      This is usually cause by an overly complicated neural network model.\n      Analogy: When you spend too much time in cooking class than in a real resturant kitchen.\n    \n2. **Underfitting**\n        Underfitting occurs when a  neural network model does not even recognise patterns in the dataset.\n        This is usually caused by a too simple neural network model, or when there's too much noise in the dataset.\n        Analogy: When you don't spend enough time to study for you test/exam, or when the curriculum is all over the place."},{"metadata":{"_uuid":"7bb153280b26e6ab556c937fbecbb7a39fb3c217"},"cell_type":"markdown","source":"**The main purpose of this notebook is to show you how to harness the power of convolutional neural networks in order to detect pneumonia in a person based of off their chest x-ray image.**\nThis tutorial assumes you know what a neural network is and a little bit of python.\n\n**NB: You don't have to be an extensively experienced AI guru in order to follow this tutorial, I am not that experienced with machine learning myself, in fact, this is my second neural network.**\n\nI hope you enjoy this mini tutorial and feel free to ask me any questions you don't understand in this tutorial, I'll make sure I explain thoroughly.\nAnd if you're an experienced person in this field and you find mistakes in this notebook, please let me know, your wisdom is highly appreciated."},{"metadata":{"_uuid":"78c31e3a47a05c679ada3b1f21d6c8d3b90f19ef"},"cell_type":"markdown","source":"You can also check out these resources:\n\n* [Best Reference Website](https://machinelearningmastery.com/)\n\n* [Cheat sheet reference guides](https://github.com/kailashahirwar/cheatsheets-ai/blob/master/All%20Cheat%20Sheets.pdf)\n\n**Videos**\n\n* [YOLO Object Detection: Detecting Custom Images](https://www.youtube.com/watch?v=eFJOGsQ_YTA)\n\n* [Deep Learning Concepts](https://www.youtube.com/watch?v=gZmobeGL0Yg&list=PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU)\n\n* [Keras Practical Deep learning by Deep Lizard](https://www.youtube.com/watch?v=RznKVRTFkBY&list=PLZbbT5o_s2xrwRnXk_yCPtnqqo4_u2YGL)\n\n* [Best Tutorials for absolut beginners](https://www.youtube.com/watch?v=ZzWaow1Rvho&list=PLxt59R_fWVzT9bDxA76AHm3ig0Gg9S3So)"},{"metadata":{"_uuid":"849e02e1c8c42b50045060cc14659ee338358055"},"cell_type":"markdown","source":"#### Importing essential libraries\nNow we're importing all necesarry libraries for us to work with."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true,"collapsed":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt #Ploting charts\nfrom glob import glob #retriving an array of files in directories\nfrom keras.models import Sequential #for neural network models\nfrom keras.layers import Dense, Dropout, Flatten, ZeroPadding2D, Conv2D, MaxPooling2D\nfrom keras.preprocessing.image import ImageDataGenerator #Data augmentation and preprocessing\nfrom keras.utils import to_categorical #For One-hot Encoding\nfrom keras.optimizers import Adam, SGD, RMSprop #For Optimizing the Neural Network\nfrom keras.callbacks import EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"756184cd8620c70938016efbc85f99dbb0673207"},"cell_type":"markdown","source":"Exploring the paths of the dataset.\nThis is where our data is stored."},{"metadata":{"trusted":true,"_uuid":"779f27419b175a66c92d9f2cb3bc0b36962006be","collapsed":true},"cell_type":"code","source":"#Cheking datasets\nimport os\npaths = os.listdir(path=\"../input\")\nprint(paths)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cbc521dcb863f9ce144a10addf703e556e2f6100"},"cell_type":"markdown","source":"## Data Analysis and Preprocessing"},{"metadata":{"_uuid":"fd3681e371dc55728ab314748a79e04c7727f675"},"cell_type":"markdown","source":"### Now we're going to explore the dataset that contains chest x-ray images of people who have pneumonia and people who don't.\nOur main goal is to predict if a person has pneumonia or not based of off their chest x-ray image.\n\n#### So now we'll display one chest x-ray image of a person with pneumonia and one with a person without pneumonia, just to have a glimpse of what each image looks like in general."},{"metadata":{"_uuid":"9f3a8f76996019313a330af1082a80983f3c0601"},"cell_type":"markdown","source":"Getting all images in the dataset"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8456c5020dbbe6f83c1a7fe218789925d7fb975e"},"cell_type":"code","source":"path_train = \"../input/chest_xray/chest_xray/train\"\npath_val = \"../input/chest_xray/chest_xray/val\"\npath_test = \"../input/chest_xray/chest_xray/test\"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1a069310cd5a13020f99f4f8cc165bf78e432b33"},"cell_type":"markdown","source":"#### Pneumonia:"},{"metadata":{"trusted":true,"_uuid":"cc82f2b3e80545c47211cd20aa06dcf46830b948","collapsed":true},"cell_type":"code","source":"img = glob(path_train+\"/PNEUMONIA/*.jpeg\") #Getting all images in this folder","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b1875fec769d002a6626fbd53239666be3b4f264"},"cell_type":"markdown","source":"Converting the first image we get from the above directory/path into a numpy array"},{"metadata":{"trusted":true,"_uuid":"bde6a5febb928fe190e714ba70eaed28f9b9ab45","collapsed":true},"cell_type":"code","source":"img = np.asarray(plt.imread(img[0]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e436165de78ef02be083d6534e4c2b27f492ff20"},"cell_type":"markdown","source":"Plotting the image "},{"metadata":{"trusted":true,"_uuid":"9b0e0025ff34dea89ea438ec22de5925ffefa864","collapsed":true},"cell_type":"code","source":"plt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d3ce22f25c4a6636df97eea45ba2e5dcb2b2c26","collapsed":true},"cell_type":"code","source":"img.shape #Checking the shape of this image. It seems like a two deminsional shape (1422 x 1152)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fbc7df746353cbe5d35685a1fe1014bc3e40a988"},"cell_type":"markdown","source":"#### Normal:"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e0f9e00b87ea9fd0966c214a59d6a29f3c6befc0"},"cell_type":"code","source":"img = glob(path_train+\"/NORMAL/*.jpeg\") #Getting all images in this folder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e5da1e326aeee5705b760b26a1062f4cca050d10","collapsed":true},"cell_type":"code","source":"img = np.asarray(plt.imread(img[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d553d0679d58b93f477ee082f5adc0e4b9dd4fef","collapsed":true},"cell_type":"code","source":"plt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4915c1dbe62a580927fe7a91e9acc625b8c6dcb4","collapsed":true},"cell_type":"code","source":"img.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c2223c7073cc46e9a01f2881517f7fdbaca09a9b"},"cell_type":"markdown","source":"### Transforming the images\n* Now we're applying a technique called Data Augmentation.\n* We're changing the sizes of the images to 226 x 226 and we'll flip the images horizontally as well so that we can have more data(images) to train on."},{"metadata":{"_uuid":"be14be32fc6b797e011d50fe7959d96720310019"},"cell_type":"markdown","source":"#### In our dataset we're given three sets of images:\n1. The training set. These are images we're going to train the neural network on.\n2. The validation set. These are images we're going to use to check if the model is underfitting or overfitting, while training and compare the training and validation results in real time.\n3. The test set. These are images we're going to use to check how good our neural network is with data it has not seen before."},{"metadata":{"_uuid":"e31fd6bc5b7bdaa8db2a09f23dd9582d8b4f3add"},"cell_type":"markdown","source":"In the following example, we're attempting to avoid overfitting by augmenting our image data.\nData augmentation means we're going to make slight variations to our data so that we have more data, without losing semantic meaning in our data.\nThe augmentation occurs in the parameters of the ImageDataGenerator method. To get a better understanding of these parameters you can check out [this link](https://machinelearningmastery.com/image-augmentation-deep-learning-keras/) and [this one.](https://keras.io/preprocessing/image/)\n\nLet me explain a few of them.\n**horizontal_flip** set to true implies that some images in the data will be randomly horizontally flipped, as chest x-ray images don't have any significant meaning when horizontally flipped(at least for machine learning purpose).\n\n**channel_shift_range** will randomly shift the channels of our images. Image channel refers to the RGB color scheme, which implies some imges will slightly vary in color.\n\n**rotation_range** will slighty rotate the image according value given to it.\n\n**zoom_range** will slightly zoom in to the image according value given to it.\n\n"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":false,"collapsed":true},"cell_type":"code","source":"#Data preprocessing and analysis\nclasses = [\"NORMAL\", \"PNEUMONIA\"]\ntrain_data = glob(path_train+\"/NORMAL/*.jpeg\")\ntrain_data += glob(path_train+\"/PNEUMONIA/*.jpeg\")\ndata_gen = ImageDataGenerator() #Augmentation happens here\n#But in this example we're not going to give the ImageDataGenerator method any parameters to augment our data.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e110a80e256fddf7b871c2093afb75e552260d3","collapsed":true},"cell_type":"code","source":"train_batches = data_gen.flow_from_directory(path_train, target_size = (226, 226), classes = classes, class_mode = \"categorical\")\nval_batches = data_gen.flow_from_directory(path_val, target_size = (226, 226), classes = classes, class_mode = \"categorical\")\ntest_batches = data_gen.flow_from_directory(path_test, target_size = (226, 226), classes = classes, class_mode = \"categorical\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"283796e255c899910559419f54b8ad9550493ebc","collapsed":true},"cell_type":"code","source":"train_batches.image_shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7990db2d817f4eac244b424aed15668f1f6b3b2b"},"cell_type":"markdown","source":"## The Artificial Neural Network\n### This particular neural network is called a convolutional neural network because it has convolutional layers that convolve the images/arrays of data it's being trained on.\nThis model is based off a model that won the ImageNet competition back in 2014"},{"metadata":{"_uuid":"d968fd9de30f849dac5c64c2484d7d07abf86188"},"cell_type":"markdown","source":"One of the best things about being in a tech industry is that fellow smart techies who've created cool and robust neural network are generous enough to share their model architecture with us, so we don't have re-invent the wheel.\nThis will save us some time and headache. We're going to use a method known as **transfer learning**. This means instead of creating a brand new neural net that's going to be time consuming, we can just use a pre-trained [good] model and fine tune it in order for it to work for our own scenario.\n\nUsually when people do transfer learning, they use both the architecture and weights of a pre-trained model. But in this tutorial we're only using the architecture of a pretrained model, not their weights."},{"metadata":{"_uuid":"9b223c246034b36262e7233e0e6fdc7ed7b183c8"},"cell_type":"markdown","source":"Source to model is [here.](https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3)"},{"metadata":{"trusted":true,"_uuid":"8b60d27aa4e21493fdab757baf6d2116619444f7","scrolled":false,"collapsed":true},"cell_type":"code","source":"#This is a Convolutional Artificial Neural Network\n#VGG16 Model\nmodel = Sequential()\nmodel.add(ZeroPadding2D((1,1),input_shape=train_batches.image_shape))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2,2), strides=(2,2)))\n\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2,2), strides=(2,2)))\n\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(256, (3, 3), activation='relu'))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(256, (3, 3), activation='relu'))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(256, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2,2), strides=(2,2)))\n\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(512, (3, 3), activation='relu'))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(512, (3, 3), activation='relu'))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(512, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2,2), strides=(2,2)))\n\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(512, (3, 3), activation='relu'))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(512, (3, 3), activation='relu'))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(512, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2,2), strides=(2,2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(4096, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(4096, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(2, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"3256d49c683e35184d560ea5dcc3e5c3f21f246a","collapsed":true},"cell_type":"code","source":"#Viewing the summary of the model\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eac8327eefa70ce07b90572abf0ec91a3e7e69fa"},"cell_type":"markdown","source":"### Training the neural net"},{"metadata":{"_uuid":"2406297c42a8fdae3095a8c3acaa7496873a7230"},"cell_type":"markdown","source":"Now the training begins"},{"metadata":{"_uuid":"a3ca49946b95b8786e930946ec6a1e0045bd4785"},"cell_type":"markdown","source":"We're training our model for 5 epochs.\nThis means we're giving the model 5 chances to learn patterns about our data.\n\nDuring training we will apply a technique called Early Stopping. This technique will stop training of the model if there's no improvement during the training process(this helps with not wating time and resources).\nIn the below example of early stopping, our parameter **patience** tells the model to stop training if there's no improvements after 3 consecutive epochs, and monitor tells the model which metric to look at in order to apply early stopping.\nFor more information on this very useful method check out [this page](https://keras.io/callbacks/)."},{"metadata":{"trusted":true,"_uuid":"8d031f95350bafedfe8b8e54e2392c8582735d7c","scrolled":true,"collapsed":true},"cell_type":"code","source":"optimizer = Adam(lr = 0.0001)\nearly_stopping_monitor = EarlyStopping(patience = 3, monitor = \"val_acc\", mode=\"max\", verbose = 2)\nmodel.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\nhistory = model.fit_generator(epochs=5, callbacks=[early_stopping_monitor], shuffle=True, validation_data=val_batches, generator=train_batches, steps_per_epoch=500, validation_steps=10,verbose=2)\nprediction = model.predict_generator(generator=train_batches, verbose=2, steps=100)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8c1c7ba996b0c2944b2f0312efb96e797b020d8d"},"cell_type":"markdown","source":"## Ploting the model performance"},{"metadata":{"_uuid":"fec5126d12fd231f8ef0f9660dfd8475bc687e95"},"cell_type":"markdown","source":"Now we're going to plot the model's performance\n\n### What does this all mean?\n  If validation/test accuracy is greater than training accuracy, that's good, it means our model has managed to learn and get a general idea/pattern of our data.\n  But if training accuracy is greater than validation/testing accuracy, tha's not good. That means our model is overfitting.\n \n \n The opposite is true for the loss chart.\n The ideal situation is to have validation/test loss way low. But train loss should not be lower than test/validation loss."},{"metadata":{"_uuid":"a59250c07cc5a71b2b669f14e106c5c21f0bdc21"},"cell_type":"markdown","source":"## Model Accuracy Chart"},{"metadata":{"trusted":true,"_uuid":"506ed81a1b3a96a634a05c7ccd461a1a83ac1ad8","collapsed":true},"cell_type":"code","source":"'''\nSource: Jason Brownlee\nSite: https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n'''\n\n# summarize history for accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2e840ecb100ced27b66f81bde009fefe85465890"},"cell_type":"markdown","source":"## Model Loss Chart"},{"metadata":{"trusted":true,"_uuid":"c2fff9f3e1465649db74a494837268ab12a6ee9c","collapsed":true},"cell_type":"code","source":"'''\nSource: Jason Brownlee\nSite: https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n'''\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"80cc167451ae0ac3afd9e9d84f615e0481758746"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}