{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"13d13201-52e7-b83c-6f8b-41e5d4b8e708"},"source":"# Decision trees\n\n### I am still missing the output of the decision tree itself so that we can't discuss the interpretation of the data. Will come in following updates."},{"cell_type":"markdown","metadata":{"_cell_guid":"68caf3e2-1d18-b78b-f8cd-e49da60b0fcd"},"source":"# Import required packages"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"53647043-19c7-d032-cff2-3817914d5fe3"},"outputs":[],"source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n%matplotlib inline"},{"cell_type":"markdown","metadata":{"_cell_guid":"89a62c3f-b93a-fa2f-b0b6-7650aa8dc54d"},"source":"# Loading dataset"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"24a7a4cb-5aee-9eb9-a74a-0763627a1246"},"outputs":[],"source":"from sklearn import datasets\niris = datasets.load_iris()\n\nX1_sepal = iris.data[:,[0,1]]\nX2_petal = iris.data[:,[2,3]]\ny = iris.target"},{"cell_type":"markdown","metadata":{"_cell_guid":"8955bb5c-7ccf-801f-b5bc-a659c16c76d0"},"source":"# Visualising the data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a0b3299a-a596-317b-9948-7ef87b0af6ee"},"outputs":[],"source":"plt.figure(figsize=(15,5))\n\nplt.subplot(1,2,1)\nplt.scatter(X1_sepal[:,0],X1_sepal[:,1],c=y)\nplt.xlabel('Sepal length')\nplt.ylabel('Sepal width')\n\nplt.subplot(1,2,2)\nplt.scatter(X2_petal[:,0],X2_petal[:,1],c=y)\nplt.xlabel('Petal length')\nplt.ylabel('Petal width')"},{"cell_type":"markdown","metadata":{"_cell_guid":"caefe400-cf17-8eb4-0bce-e21d394370ea"},"source":"### Create function used to plot decision regions"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7919be5c-2159-77a5-4b0f-d1becdeea417"},"outputs":[],"source":"from matplotlib.colors import ListedColormap\n\ndef plot_decision_regions(X,y,classifier,test_idx=None,resolution=0.02):\n    \n    # Initialise the marker types and colors\n    markers = ('s','x','o','^','v')\n    colors = ('red','blue','lightgreen','gray','cyan')\n    color_Map = ListedColormap(colors[:len(np.unique(y))]) #we take the color mapping correspoding to the \n                                                            #amount of classes in the target data\n    \n    # Parameters for the graph and decision surface\n    x1_min = X[:,0].min() - 1\n    x1_max = X[:,0].max() + 1\n    x2_min = X[:,1].min() - 1\n    x2_max = X[:,1].max() + 1\n    xx1, xx2 = np.meshgrid(np.arange(x1_min,x1_max,resolution),\n                           np.arange(x2_min,x2_max,resolution))\n    \n    Z = classifier.predict(np.array([xx1.ravel(),xx2.ravel()]).T)\n    Z = Z.reshape(xx1.shape)\n    \n    plt.contour(xx1,xx2,Z,alpha=0.4,cmap = color_Map)\n    plt.xlim(xx1.min(),xx1.max())\n    plt.ylim(xx2.min(),xx2.max())\n    \n    # Plot samples\n    X_test, Y_test = X[test_idx,:], y[test_idx]\n    \n    for idx, cl in enumerate(np.unique(y)):\n        plt.scatter(x = X[y == cl, 0], y = X[y == cl, 1],\n                    alpha = 0.8, c = color_Map(idx),\n                    marker = markers[idx], label = cl\n                   )"},{"cell_type":"markdown","metadata":{"_cell_guid":"82a4337a-f103-2b92-b745-075c42a26134"},"source":"# Splitting and scaling the dataset\n\n#### Unlike other classification algorithms, decision trees do not require data scaling!"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6a54fa10-ffe5-d6df-23f0-523d2ac3250e"},"outputs":[],"source":"from sklearn.cross_validation import train_test_split\n# from sklearn.preprocessing import StandardScaler\n\n#######################################################################\n## SPLITTING\n\n\nX_train_sepal, X_test_sepal, y_train_sepal, y_test_sepal = train_test_split(X1_sepal,y,test_size=0.3,random_state=0)\n\nprint(\"# training samples sepal: \", len(X_train_sepal))\nprint(\"# testing samples sepal: \", len(X_test_sepal))\n\nX_train_petal, X_test_petal, y_train_petal, y_test_petal = train_test_split(X2_petal,y,test_size=0.3,random_state=0)\n\nprint(\"# training samples petal: \", len(X_train_petal))\nprint(\"# testing samples petal: \", len(X_test_petal))\n\n#####################################################################\n## SCALING ---> NOT REQUIRED!!\n\n# sc = StandardScaler()\n# X_train_sepal_std = sc.fit_transform(X_train_sepal)\n# X_test_sepal_std = sc.transform(X_test_sepal)\n\n# sc = StandardScaler()\n# X_train_petal_std = sc.fit_transform(X_train_petal)\n# X_test_petal_std = sc.transform(X_test_petal)"},{"cell_type":"markdown","metadata":{"_cell_guid":"d681e025-9a2f-af95-a0bb-5dd5fe008ff4"},"source":"# (\"Free\") Decision tree \n\n#### For this example, I will start by creating decision trees for the Sepal and Petal dataset without specifying any stopping criteria. In other words, the tree will be able to split as many times as it likes until each node/leaf have only 1 class. As you can imagine, this approach can lead to overfitting, as the training model will be very tailored to the training data. Let's check what happens and then we will create models with different restrictions so that we can compare how the tree works."},{"cell_type":"markdown","metadata":{"_cell_guid":"ffb1c74a-d502-9661-595a-697c5c540ad7"},"source":"### Sepal dataset"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4f89fb65-e42c-6f4d-9e4f-660b302c4c47"},"outputs":[],"source":"from sklearn.tree import DecisionTreeClassifier, export_graphviz\nfrom sklearn.metrics import accuracy_score\n\ntree = DecisionTreeClassifier()\ntree.fit(X_train_sepal,y_train_sepal)\n\ny_pred_sepal_tree_train = tree.predict(X_train_sepal)\ny_pred_sepal_tree = tree.predict(X_test_sepal)\n\nplot_decision_regions(X = X1_sepal\n                      ,y = y\n                      ,classifier = tree\n                      ,test_idx = range(105,150))\nplt.xlabel('Sepal length')\nplt.ylabel('Sepal width')\nplt.legend(loc='upper left')"},{"cell_type":"markdown","metadata":{"_cell_guid":"6c422add-786c-0725-bff2-fa2ef76af936"},"source":"### Petal dataset"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5d4407b2-07f4-5bb3-7b21-60726ddbae7d"},"outputs":[],"source":"tree = DecisionTreeClassifier()\ntree.fit(X_train_petal,y_train_petal)\n\ny_pred_petal_tree_train = tree.predict(X_train_petal)\ny_pred_petal_tree = tree.predict(X_test_petal)\n\nplot_decision_regions(X = X2_petal\n                      ,y = y\n                      ,classifier = tree\n                      ,test_idx = range(105,150))\nplt.xlabel('Petal length')\nplt.ylabel('Petal width')\nplt.legend(loc='upper left')"},{"cell_type":"markdown","metadata":{"_cell_guid":"21336f87-baaf-6ff3-c4db-6dbfb2b06ca3"},"source":"### Overfitting\n\n#### As we mentioned earlier, by not restricting the algorithm with a sensible stoppage criterion, our training model will perfectly match our training dataset, but will fail to generalise to unseen data from the testing dataset. The perfect example of this is the Sepal dataset. Let's check the training vs testing accuracies for these models."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"07f8e5e1-8888-233b-04ea-0a25b3784b72"},"outputs":[],"source":"print(\"SEPAL\")\nprint(\"------------------------------\")\nprint(\"Training accuracy: %.2f\" % accuracy_score(y_train_sepal,y_pred_sepal_tree_train))\nprint(\"Testing accuracy: %.2f\" % accuracy_score(y_test_sepal,y_pred_sepal_tree))\nprint(\"\")\nprint(\"PETAL\")\nprint(\"------------------------------\")\nprint(\"Training accuracy: %.2f\" % accuracy_score(y_train_petal,y_pred_petal_tree_train))\nprint(\"Testing accuracy: %.2f\" % accuracy_score(y_test_petal,y_pred_petal_tree))\n"},{"cell_type":"markdown","metadata":{"_cell_guid":"4d069026-6c97-6925-24c7-9a73312a3c0f"},"source":"# Decision tree using different max depths"},{"cell_type":"markdown","metadata":{"_cell_guid":"6f0f981d-2d62-d1f4-778b-615e2172e2b2"},"source":"### Sepal dataset"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ba3e630a-6cfb-c154-78a5-ff62b287ebff"},"outputs":[],"source":"plt.figure(figsize=(10, 10))\n\nmax_depth_range = [1,2,3,4,5,6]\n\nj = 0\nfor i in max_depth_range:\n    \n    # Creating the decision tree\n    tree = DecisionTreeClassifier(max_depth = i)\n    tree.fit(X_train_sepal,y_train_sepal)\n    \n    # Printing decision regions\n    plt.subplot(3,2,i)\n    plt.subplots_adjust(hspace = 0.4)\n    plot_decision_regions(X = X1_sepal\n                      , y = y\n                      , classifier = tree\n                      , test_idx = range(105,150))\n    plt.xlabel('Sepal length')\n    plt.ylabel('Sepal width')\n    plt.title('Max depth tree = %s'%i)"},{"cell_type":"markdown","metadata":{"_cell_guid":"82a2ae5d-2d84-1425-6ba7-abc13978403d"},"source":"### Petal dataset"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aa4920d7-bf75-f37a-7885-2428527dca5c"},"outputs":[],"source":"plt.figure(figsize=(10, 10))\n\nmax_depth_range = [1,2,3,4,5,6]\n\nfor i in max_depth_range:\n    \n    # Creating the decision tree\n    tree = DecisionTreeClassifier(max_depth = i)\n    tree.fit(X_train_petal,y_train_petal)\n    \n    # Printing decision regions\n    plt.subplot(3,2,i)\n    plt.subplots_adjust(hspace = 0.4)\n    plot_decision_regions(X = X2_petal\n                      , y = y\n                      , classifier = tree\n                      , test_idx = range(105,150))\n    plt.xlabel('Petal length')\n    plt.ylabel('Petal width')\n    plt.title('Max depth tree = %s'%i)"},{"cell_type":"markdown","metadata":{"_cell_guid":"01086861-775f-16cc-02ef-a70f839d9161"},"source":"### Validation curves when changing the max depth for the tree"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e1459637-cc7c-86fc-ae03-d6319b47ba59"},"outputs":[],"source":"from sklearn.learning_curve import validation_curve\n\nmax_depth_range = [1,2,3,4,5,6]\n\nplt.figure(figsize=(15,10))\n\n# Decision tree model\ntree = DecisionTreeClassifier(max_depth=i)\n\n# SEPAL validation curve\ntrain_sepal_scores, test_sepal_scores = validation_curve(estimator = tree\n                                                        , X = X1_sepal\n                                                        , y = y\n                                                        , param_name = 'max_depth'\n                                                        , param_range = max_depth_range\n                                                        , scoring = 'accuracy')\n\ntrain_sepal_mean = np.mean(train_sepal_scores, axis = 1)\ntest_sepal_mean = np.mean(test_sepal_scores, axis = 1)\n\nplt.subplot(2,2,1)\nplt.plot(max_depth_range\n        ,train_sepal_mean\n        ,color='blue'\n        ,marker='o'\n        ,markersize=5\n        ,label='training accuracy')\n\nplt.plot(max_depth_range\n        ,test_sepal_mean\n        ,color='green'\n        ,marker='x'\n        ,markersize=5\n        ,label='test accuracy') \n\nplt.legend(loc='upper left')\nplt.xlabel('Max depth of tree')\nplt.ylabel('Accuracy')\nplt.title('Sepal validation curves')\n\n# PETAL validation curve\ntrain_petal_scores, test_petal_scores = validation_curve(estimator = tree\n                                                        , X = X2_petal\n                                                        , y = y\n                                                        , param_name = 'max_depth'\n                                                        , param_range = max_depth_range\n                                                        , scoring = 'accuracy')\n\ntrain_petal_mean = np.mean(train_petal_scores, axis = 1)\ntest_petal_mean = np.mean(test_petal_scores, axis = 1)\n\nplt.subplot(2,2,2)\nplt.plot(max_depth_range\n        ,train_petal_mean\n        ,color='blue'\n        ,marker='o'\n        ,markersize=5\n        ,label='training accuracy')\n\nplt.plot(max_depth_range\n        ,test_petal_mean\n        ,color='green'\n        ,marker='x'\n        ,markersize=5\n        ,label='test accuracy') \n\nplt.legend(loc='lower right')\nplt.xlabel('Max depth of tree')\nplt.ylabel('Accuracy')\nplt.title('Sepal validation curves')"},{"cell_type":"markdown","metadata":{"_cell_guid":"2cad6d31-0674-fff0-fb01-d1a7e86202c2"},"source":"# Random forests\n\n### Using default 10 trees per forest (we could also try to optimise this, although generally, the more trees in the forest the better, although this comes with a computational cost)."},{"cell_type":"markdown","metadata":{"_cell_guid":"ca945fc9-4a57-96fd-d274-0483d351a89f"},"source":"### Sepal dataset"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"98c61a66-a65e-ee33-e778-4d028218bfcb"},"outputs":[],"source":"from sklearn.ensemble import RandomForestClassifier\n\nplt.figure(figsize=(10, 10))\n\nmax_depth_range = [1,2,3,4,5,6]\n\nj = 0\nfor i in max_depth_range:\n    \n    # Creating the decision tree\n    RF = RandomForestClassifier(max_depth = i)\n    RF.fit(X_train_sepal,y_train_sepal)\n    \n    # Printing decision regions\n    plt.subplot(3,2,i)\n    plt.subplots_adjust(hspace = 0.4)\n    plot_decision_regions(X = X1_sepal\n                      , y = y\n                      , classifier = RF\n                      , test_idx = range(105,150))\n    plt.xlabel('Sepal length')\n    plt.ylabel('Sepal width')\n    plt.title('Max depth tree = %s'%i)"},{"cell_type":"markdown","metadata":{"_cell_guid":"4346afdf-cdd9-fdb9-ec86-9b384f865007"},"source":"### Petal dataset"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"38193c32-69ad-910d-7c39-0e053d46c038"},"outputs":[],"source":"plt.figure(figsize=(10, 10))\n\nmax_depth_range = [1,2,3,4,5,6]\n\nj = 0\nfor i in max_depth_range:\n    \n    # Creating the decision tree\n    RF = RandomForestClassifier(max_depth = i)\n    RF.fit(X_train_petal,y_train_petal)\n    \n    # Printing decision regions\n    plt.subplot(3,2,i)\n    plt.subplots_adjust(hspace = 0.4)\n    plot_decision_regions(X = X2_petal\n                      , y = y\n                      , classifier = RF\n                      , test_idx = range(105,150))\n    plt.xlabel('Petal length')\n    plt.ylabel('Petal width')\n    plt.title('Max depth tree = %s'%i)"},{"cell_type":"markdown","metadata":{"_cell_guid":"7dc47ffe-c0b6-99f5-12d3-e7f331d05d6d"},"source":"### Validation curves"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6fbf87e3-2de5-11f9-b47f-3311df48923e"},"outputs":[],"source":"max_depth_range = [1,2,3,4,5,6]\n\nplt.figure(figsize=(15,10))\n\n# Decision tree model\nRF = RandomForestClassifier(max_depth = i)\n\n# SEPAL validation curve\ntrain_sepal_scores, test_sepal_scores = validation_curve(estimator = RF\n                                                        , X = X1_sepal\n                                                        , y = y\n                                                        , param_name = 'max_depth'\n                                                        , param_range = max_depth_range\n                                                        , scoring = 'accuracy')\n\ntrain_sepal_mean = np.mean(train_sepal_scores, axis = 1)\ntest_sepal_mean = np.mean(test_sepal_scores, axis = 1)\n\nplt.subplot(2,2,1)\nplt.plot(max_depth_range\n        ,train_sepal_mean\n        ,color='blue'\n        ,marker='o'\n        ,markersize=5\n        ,label='training accuracy')\n\nplt.plot(max_depth_range\n        ,test_sepal_mean\n        ,color='green'\n        ,marker='x'\n        ,markersize=5\n        ,label='test accuracy') \n\nplt.legend(loc='upper left')\nplt.xlabel('Max depth of tree')\nplt.ylabel('Accuracy')\nplt.title('Petal validation curves')\n\n# PETAL validation curve\ntrain_petal_scores, test_petal_scores = validation_curve(estimator = RF\n                                                        , X = X2_petal\n                                                        , y = y\n                                                        , param_name = 'max_depth'\n                                                        , param_range = max_depth_range\n                                                        , scoring = 'accuracy')\n\ntrain_petal_mean = np.mean(train_petal_scores, axis = 1)\ntest_petal_mean = np.mean(test_petal_scores, axis = 1)\n\nplt.subplot(2,2,2)\nplt.plot(max_depth_range\n        ,train_petal_mean\n        ,color='blue'\n        ,marker='o'\n        ,markersize=5\n        ,label='training accuracy')\n\nplt.plot(max_depth_range\n        ,test_petal_mean\n        ,color='green'\n        ,marker='x'\n        ,markersize=5\n        ,label='test accuracy') \n\nplt.legend(loc='lower right')\nplt.xlabel('Max depth of tree')\nplt.ylabel('Accuracy')\nplt.title('Petal validation curves')"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}