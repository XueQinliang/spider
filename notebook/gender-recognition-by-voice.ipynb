{"cells":[{"metadata":{"_cell_guid":"0acf2adb-baa4-6efa-3392-58b4d9b573f9","_uuid":"e5d019fbc8e4295fffde8ead68a461a76357c598"},"cell_type":"markdown","source":"* In this notebook,various ML algorithms are used on the voice.csv dataset which consists of of various features of voice:mean frequency etc. Here we will use feature_selection from sklearn to improve our learning dataset.\n======="},{"metadata":{"_cell_guid":"59855808-788c-46be-e2b9-f4f7721f18fd","_uuid":"7123d168dd88cfd82e53634950d2a4f4b791caaa","trusted":true},"cell_type":"code","source":"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"133ccbac-177a-73af-f120-91feb8b9f5bd","_uuid":"22f4b1ba65c0de11994184a0cf4942761f684f26"},"cell_type":"markdown","source":"Importing:\n======="},{"metadata":{"_cell_guid":"ed2d5732-2655-9f4d-d297-602508ffb9c5","_uuid":"515ce8fe588b0be34626859caf4e7e8fbd56f15e","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing, neighbors\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nimport seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b21b40f4-84df-c100-a6d9-9fa63b6fccfb","_uuid":"383260ca5534447ed3b1225a458d580e9cf6b249","trusted":true},"cell_type":"code","source":"# Reading and uploading the file\ndf = pd.read_csv('../input/voice.csv')\ndf.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e4a08dfc-dc7c-4371-28dd-fd55d10d10d9","_uuid":"90b1a1133e31710002ec86a3c1e0890c891f7e89"},"cell_type":"markdown","source":"Visualizing the correlation among the features.\n======="},{"metadata":{"_cell_guid":"b3a15083-96c8-1134-4c97-815ae61336ce","_uuid":"e1a5e6a338269bbcc4724b61f34391e6101f644c","trusted":true},"cell_type":"code","source":"corrmat=df.corr()\nsns.heatmap(corrmat,linewidths=0.25,vmax=1.0, square=True, cmap=\"YlGnBu\", linecolor='black')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"aa48133a-1735-c4d4-51f2-28911dc8b883","_uuid":"1d5c37e5ebe5abcf592d142b9bc33b9f99b344a7","trusted":true},"cell_type":"code","source":"# Name of the columns\ncol_names = list(df.columns.values)\nprint(col_names)\nprint (type(df.columns.values))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3b483eca-41cf-2caf-0e81-4159fe1a9c63","_uuid":"dfd6a13fa23a30966124653cbf13f73cb52457b2","trusted":true},"cell_type":"code","source":"df = df.rename(columns={'label': 'gender'})\ndf.columns.values","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"17cad688-8873-5822-1ce2-04f2d5aa3474","_uuid":"086aa6c9b2676373659fe8d3ae71a4a462767886","trusted":true},"cell_type":"code","source":"#Lets use logistic Regression:\n\n#Producing X and y\nX = np.array(df.drop(['gender'], 1))\ny = np.array(df['gender'])\n\n#Dividing the data randomly into training and test set\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n\nmodel=LogisticRegression()\nmodel.fit(X_train,y_train)\n\nprint('Accuracy1 :',model.score(X_train,y_train))\nprint('Accuracy2 :',model.score(X_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0fb14366-99c3-c325-1e1f-fcd9d60ab41c","_uuid":"e6bac46e1fc9a21de2b02bc24f9f93ca997d72d5","trusted":true},"cell_type":"code","source":"\n#KNN Classifier\n#Producing X and y\nX = np.array(df.drop(['gender'], 1))\ny = np.array(df['gender'])\n\n#Dividing the data randomly into training and test set\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n\nmodel = neighbors.KNeighborsClassifier()\nmodel.fit(X_train, y_train)\n\naccuracy = model.score(X_test, y_test)\nprint('Accuracy='+str(accuracy))\n\n\n#The above was without any tuning ,now we will drop some columns which does not make any sense\n#We will drop col=median,mode,Q25,Q75,IQR.\n#next edit use only few=meanfreq,sd,median,gender(for no error)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6a047ba9-b380-ea45-59a3-4279b8303d53","_uuid":"33ebea9090bc2f578a8b44fce1612cb59f2f7cef","trusted":true},"cell_type":"code","source":"df1=df[['meanfreq','sd','median','meanfun','gender']]\nX = np.array(df1.drop(['gender'], 1))\ny = np.array(df1['gender'])\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n\nmodel = neighbors.KNeighborsClassifier()\nmodel.fit(X_train, y_train)\n\naccuracy2 = model.score(X_test, y_test)\nprint('Accuracy2='+str(accuracy2))\n\n#All the models should be above the base_line model:Base line model acc=50:50\n#But this is not very helpful,have to find new ways for k-nearest neibhors","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c65d017d-2514-9310-3ef4-9c7daec5d9d3","_uuid":"e92efd0d029756337ba7945e38311845359b0948","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3e970aa7-7eea-fd5b-05c1-47e9a0ddfda7","_uuid":"090270db38f0f45fe17175eb57bb00f72301b32a","trusted":true},"cell_type":"code","source":"df2=df[['meanfreq','sd','meanfun','gender']]\nX = np.array(df2.drop(['gender'], 1))\ny = np.array(df2['gender'])\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n\nmodel = neighbors.KNeighborsClassifier()\nmodel.fit(X_train, y_train)\n\naccuracy2 = model.score(X_test, y_test)\nprint('Accuracy='+str(accuracy2))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"646b22f4-f422-23ca-da3b-2b0e74e6e08c","_uuid":"561304b99944a10ee651a1927a1110ccfa3ad8b2","trusted":true},"cell_type":"code","source":"#print(X_train.shape,y_train.shape,)\nprint(X_test.shape,y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1f0dff59-5462-bc9d-4be2-a6015aff88c1","_uuid":"9018c5ab0380cafb62705aaf1bd93337aff41407"},"cell_type":"markdown","source":"Improving the model using feature_selection from sklearn\n======="},{"metadata":{"_cell_guid":"2f9f1deb-f9c1-2a82-ba90-42a6c024ee24","_uuid":"58d2f928467c679e88130fb71d3d1735592a65ff","trusted":true,"scrolled":true},"cell_type":"code","source":"\nfrom sklearn.feature_selection import SelectKBest, f_classif\n\ndef select_kbest_clf(data_frame, target, k=5):\n    \"\"\"\n    Selecting K-Best features for classification\n    :param data_frame: A pandas dataFrame with the training data\n    :param target: target variable name in DataFrame\n    :param k: desired number of features from the data\n    :returns feature_scores: scores for each feature in the data as \n    pandas DataFrame\n    \"\"\"\n    feat_selector = SelectKBest(f_classif, k=k)\n    _ = feat_selector.fit(data_frame.drop(target, axis=1), data_frame[target])\n    \n    feat_scores = pd.DataFrame()\n    feat_scores[\"F Score\"] = feat_selector.scores_\n    feat_scores[\"P Value\"] = feat_selector.pvalues_\n    feat_scores[\"Support\"] = feat_selector.get_support()\n    feat_scores[\"Attribute\"] = data_frame.drop(target, axis=1).columns\n    \n    return feat_scores\nk=select_kbest_clf(df, 'gender', k=5).sort_values(['F Score'],ascending=False)\n\nk","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"603b55ef-c2df-d2ac-cd9a-4b8105d7a4bb","_uuid":"2f2837860713302e45b300370f39978a55a29292","trusted":true},"cell_type":"code","source":"k1=sns.barplot(x=k['F Score'],y=k['Attribute'])\nk1.set_title('Feature Importance')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"91502612-86d6-4579-33ee-64cd4634b84f","_uuid":"38761a68582e968456bf27bcc5038da67094ed66"},"cell_type":"markdown","source":"k-Nearest Neighbors\n======="},{"metadata":{"_cell_guid":"aa6172f7-8dc1-fce0-89ac-8e861c58b302","_uuid":"7c77955cb63b0868a82184268c7cca8d6902c91e","trusted":true},"cell_type":"code","source":"df3=df[['meanfun','IQR','Q25','sp.ent','sd','sfm','meanfreq','gender']]\nX = np.array(df3.drop(['gender'], 1))\ny = np.array(df3['gender'])\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n\nmodel = neighbors.KNeighborsClassifier()\nmodel.fit(X_train, y_train)\n\naccuracy3 = model.score(X_test, y_test)\nprint('Accuracy3='+str(accuracy3))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"cc84bd8e-6fd7-c024-a499-d371bd856266","_uuid":"ca08b6daa874e9e497edd62f7f2c0750f44d4aaf"},"cell_type":"markdown","source":"Decision Tree with Boosting(AdaBoostClassifier)\n======="},{"metadata":{"_cell_guid":"f409bab5-b26f-c4d8-9c7d-773591be9b30","_uuid":"17ee6794abc27425f695579b743115bd4db4edf8","trusted":true},"cell_type":"code","source":"df.replace({'male':0,'female':1},inplace=True)\nX = np.array(df.drop(['gender'], 1))\ny = np.array(df['gender'])\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d3df7346-2b8e-6613-1a60-7d225166a754","_uuid":"e91508ea993abcbd737236b2bee08fe85efd04a0","trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.ensemble import AdaBoostClassifier\n#DecisionTreeClassifier\ndt=DecisionTreeClassifier(max_depth=3,min_samples_leaf=int(0.5*len(X_train)))\nboosted_dt=AdaBoostClassifier(dt,algorithm='SAMME',n_estimators=800,learning_rate=0.5)\nboosted_dt.fit(X_train,y_train)\ny_predicted=boosted_dt.predict(X_test)\n\nprint (\"Area under ROC curve: %.4f\"%(roc_auc_score(y_test, y_predicted)))\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4a9f3a85-154e-c28d-8f29-62f049ab7d34","_uuid":"5275c579a7155258ccb525d72efc32883f4ee69f"},"cell_type":"markdown","source":"Support Vector Machine \n======="},{"metadata":{"_cell_guid":"a4fb7d47-f0fe-8d28-e4bf-5f6759565600","_uuid":"01970fd729d41c4c5bbf9cc2c1aeb1b172fc5f81","trusted":true},"cell_type":"code","source":"from sklearn import svm\nsvc = svm.SVC(kernel='linear', C=1,gamma='auto').fit(X_train, y_train)\ny_pred=svc.predict(X_test)\naccuracy=roc_auc_score(y_test,y_pred)\nprint('Accuracy :',accuracy)","execution_count":null,"outputs":[]}],"metadata":{"_is_fork":false,"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"_change_revision":0,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}