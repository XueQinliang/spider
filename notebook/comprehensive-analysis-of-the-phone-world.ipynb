{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"596ee98a-a698-593f-c83c-1a89125541d9"},"source":"# Amazon Reviews Unlocked Mobile Phones"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"501e8e53-e306-f41d-8345-64c34b003146"},"outputs":[],"source":"import smtplib\nfrom matplotlib import style\nimport seaborn as sns\nsns.set(style='ticks', palette='RdBu')\nimport pandas as pd\nimport numpy as np\nimport time\nimport datetime \n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom subprocess import check_output\npd.options.display.max_colwidth = 1000\nfrom time import gmtime, strftime\nTime_now = strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\nimport timeit\nstart = timeit.default_timer()\npd.options.display.max_rows = 100\nfrom wordcloud import WordCloud\nimport sqlite3\nimport nltk\nimport string\nfrom nltk.corpus import stopwords\nimport re\nfrom bs4 import BeautifulSoup\nfrom nltk.stem.porter import PorterStemmer\nenglish_stemmer=nltk.stem.SnowballStemmer('english')\nfrom sklearn.feature_selection.univariate_selection import SelectKBest, chi2, f_classif\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import SGDClassifier, SGDRegressor\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nimport random\nimport itertools\nimport sys\nimport os\nimport argparse\nfrom sklearn.pipeline import Pipeline\nfrom scipy.sparse import csr_matrix\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport six\nfrom abc import ABCMeta\nfrom scipy import sparse\nfrom scipy.sparse import issparse\nfrom sklearn.base import BaseEstimator, ClassifierMixin\nfrom sklearn.utils import check_X_y, check_array\nfrom sklearn.utils.extmath import safe_sparse_dot\nfrom sklearn.preprocessing import normalize, binarize, LabelBinarizer\nfrom sklearn.svm import LinearSVC\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.feature_selection import RFECV, SelectKBest\nfrom sklearn.ensemble import RandomForestClassifier \nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.tree import DecisionTreeClassifier,ExtraTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB, BernoulliNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn import svm\nfrom scipy.stats import skew\nfrom scipy.stats.stats import pearsonr\nfrom sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, LassoLarsCV\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression, Lasso\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier\nfrom sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n"},{"cell_type":"markdown","metadata":{"_cell_guid":"2bd13abb-05da-8ea1-661d-2f8ff3c9c2da"},"source":"# Read the data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"adc5da3a-6611-6717-56a0-d1b882e091ba"},"outputs":[],"source":"data = pd.read_csv('../input/Amazon_Unlocked_Mobile.csv', encoding='utf-8')\ndf = data\ndf.columns = ['ProductName', 'BrandName', 'Price', 'Rating', 'Reviews', 'ReviewVotes']\ndf.head().T"},{"cell_type":"markdown","metadata":{"_cell_guid":"d989488c-0abf-babb-d83c-d495463a8cc3"},"source":"# Describe the data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"83559453-d4af-9026-ce57-0d041f607c19"},"outputs":[],"source":"data.columns"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e7c1c298-0421-ff80-c8bf-592a8863a820"},"outputs":[],"source":"data.head(n=2)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e5717e12-62a2-827f-f621-b4d09cbd9d16"},"outputs":[],"source":"df['Price'] = df['Price'].fillna(0)\ndf['ReviewVotes'] = df['ReviewVotes'].fillna(0)\ndata.describe()"},{"cell_type":"markdown","metadata":{"_cell_guid":"c3ad649e-a26f-b9a9-0bc8-38a17049fb9c"},"source":"# Categorical features"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ee039e38-5bc6-deef-fac5-78230c3f0151"},"outputs":[],"source":"categorical_features = (data.select_dtypes(include=['object']).columns.values)\ncategorical_features"},{"cell_type":"markdown","metadata":{"_cell_guid":"633c0205-6c35-84d4-832a-258c93b7fbb9"},"source":"# Numerical Features"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6f9b3d75-5dc6-bb1d-ed54-bf761316ed78"},"outputs":[],"source":"numerical_features = data.select_dtypes(include = ['float64', 'int64']).columns.values\nnumerical_features"},{"cell_type":"markdown","metadata":{"_cell_guid":"af5e7593-8666-c719-b23c-d876a719577d"},"source":"# How many Brands exist? "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"813c8cce-665d-0c9f-8cd9-707506abf053"},"outputs":[],"source":"len(list(set(df['BrandName'])))"},{"cell_type":"markdown","metadata":{"_cell_guid":"77fcce73-eb4e-f12d-55c0-c76ccb656843"},"source":"# How many unique products exist? "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"687d3346-0cd0-b284-4bec-fadf52cf4b5a"},"outputs":[],"source":"len(list(set(df['ProductName'])))"},{"cell_type":"markdown","metadata":{"_cell_guid":"d6a564e8-3a3f-2cfe-fc7e-b2738697cad0"},"source":"# Pivot tables"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7b8f7ae0-ffd7-3611-37b8-d627a221fd1a"},"outputs":[],"source":"pivot = pd.pivot_table(df,\n            values = ['Rating', 'ReviewVotes'],\n            index = ['BrandName'], \n                       columns= [],\n                       aggfunc=[np.sum, np.mean, np.count_nonzero, np.std], \n                       margins=True).fillna('')\npivot.head(10)"},{"cell_type":"markdown","metadata":{"_cell_guid":"3dc166bf-ecf6-f345-5489-c8c537cee654"},"source":"# Which are the top 10 prominent brands?\nAnd how many ratings do they have?  "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ad737f7b-429d-0094-323b-41c58a8f6c0a"},"outputs":[],"source":"pivot = pd.pivot_table(df,\n            values = ['Rating', 'ReviewVotes'],\n            index =  ['BrandName'],\n                       columns= [],\n                       aggfunc=[np.sum, np.mean, np.count_nonzero, np.std], \n                       margins=True, fill_value=0).sort_values(by=('count_nonzero', 'Rating'), ascending=False).fillna('')\ntop_10_brands = pivot.reindex().head(n=11)\ntop_10_brands"},{"cell_type":"markdown","metadata":{"_cell_guid":"dcb51804-e1e1-f41e-a4a8-e072fafbe6da"},"source":"# Lets extract data only for top 10 brands. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f97af8df-7c70-2ffd-7e2e-e904d02cd956"},"outputs":[],"source":"top_10_brands = top_10_brands.reset_index()\ntt_brand = top_10_brands['BrandName']\ntt_brand2 = tt_brand.reset_index()\ntop_10_brand_list = list(set(tt_brand2['BrandName']))\ntop_10_brand_list.remove('All')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2ccc5d58-a7cd-e8bb-60b6-0592f26128ee"},"outputs":[],"source":"top_10_brand_list"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"771cb91a-c11a-3f06-21ab-9d94807bb69b"},"outputs":[],"source":"df_small=df.loc[df['BrandName'].isin(top_10_brand_list)]\npivot = pd.pivot_table(df_small,\n            values = ['Rating'],\n            index =  ['BrandName'], \n                       columns= [],\n                       aggfunc=[np.mean, np.std], \n                       margins=True, fill_value=0).sort_values(by=('mean', 'Rating'), ascending=False).fillna('')\npivot"},{"cell_type":"markdown","metadata":{"_cell_guid":"5736a091-4c69-238c-d1c0-3365490d26bb"},"source":"# How do average ratings look like for top 10 brands? "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e1f2cd2c-1189-44b9-64c5-324155adb1f6"},"outputs":[],"source":"cmap = sns.cubehelix_palette(start = 1.5, rot = 1.5, as_cmap = True)\nplt.subplots(figsize = (15, 8))\nsns.heatmap(pivot.T,linewidths=0.2,xticklabels=True, yticklabels=True)"},{"cell_type":"markdown","metadata":{"_cell_guid":"aa737749-1b4c-b6b0-3198-a46ca1d4ac0d"},"source":"# Lets find out their topmost products: For 10 Brands, what are top 10 products?"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7b587542-6c8f-bb50-d6b2-3aea8d662115"},"outputs":[],"source":"df_small.columns.values"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5db3b63e-7f65-2327-d647-586b6990fad9"},"outputs":[],"source":"def plot_one_company(company, n=20):\n    df_one_company = df_small.loc[df_small['BrandName'].isin([company])]\n    pivot = pd.pivot_table(df_one_company,\n            values = ['Rating', 'ReviewVotes'],\n            index =  ['ProductName'],\n                       columns= [],\n                       aggfunc=[np.sum, np.mean, np.count_nonzero, np.std], \n                       margins=True, fill_value=0).sort_values(by=('count_nonzero', 'Rating'), ascending=False).fillna('')\n    top_10_prods = pivot.reindex().head(n=20)\n    top_10_prods = top_10_prods.reset_index()\n    tt_prods = top_10_prods['ProductName']\n    tt_prods2 = tt_prods.reset_index()\n    top_10_prods_list = list(set(tt_prods2['ProductName']))\n    #top_30_prod_list\n\n    try:\n        aa= df_one_company[df_one_company['ProductName'].isin(top_10_prods_list)]\n        g = sns.factorplot(x='ProductName', \n                           y='Rating',\n                           data=aa, \n                           saturation=1, \n                           kind=\"bar\", \n                           ci=None, \n                           aspect=4, \n                           linewidth=1) \n        locs, labels = plt.xticks()\n        plt.setp(labels, rotation=90)\n    except: \n        pass\n        \nfor i in top_10_brand_list:\n    plot_one_company(i, 20)\n    "},{"cell_type":"markdown","metadata":{"_cell_guid":"34806248-8c3f-6891-f9f6-97236786f48d"},"source":"# Correlations"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5fb150c2-3b3a-1b24-159c-ec816ae2d4d2"},"outputs":[],"source":"def heat_map(corrs_mat):\n    sns.set(style=\"white\")\n    f, ax = plt.subplots(figsize=(10, 10))\n    mask = np.zeros_like(corrs_mat, dtype=np.bool)\n    mask[np.triu_indices_from(mask)] = True \n    # Generate a custom diverging colormap\n    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n    sns.heatmap(corrs_mat, mask=mask, cmap=cmap, ax=ax)\n\nvariable_correlations = df.corr()\n#variable_correlations\nheat_map(variable_correlations)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5be89067-57ea-0d56-981e-305b6bcb96c9"},"outputs":[],"source":"df.columns.values"},{"cell_type":"markdown","metadata":{"_cell_guid":"13c161bb-dec8-033e-9c92-e8328fed0647"},"source":"# How are review votes distributed for different prices and different ratings? "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fb0c44f3-d775-dfda-b4e8-1db963d6f74a"},"outputs":[],"source":"df_small = df[['BrandName', \n               'Price', \n               'Rating', \n               'ReviewVotes']]\nsns.pairplot(df_small, size=4)"},{"cell_type":"markdown","metadata":{"_cell_guid":"283dc74d-4f79-10f2-9d4f-d802b1ccea4a"},"source":"# Complex plots"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c9529eaf-8617-c273-3a0e-8b7aca80db36"},"outputs":[],"source":"#data = df\nsns.set(style=\"white\", palette=\"muted\", color_codes=True)\nf, axes = plt.subplots(2, 3, figsize=(20,20))\nsns.despine(left=True)\nsns.distplot(df['Price'],            color=\"b\", ax=axes[0, 0])\nsns.distplot(df['Rating'],           color=\"r\", ax=axes[0, 1])\nsns.distplot(df['ReviewVotes'],      color=\"g\", ax=axes[0, 2])\nsns.distplot(df['Price'],            kde=False, color=\"b\", ax=axes[1, 0])\nsns.distplot(df['Rating'],           kde=False, color=\"r\", ax=axes[1, 1])\nsns.distplot(df['ReviewVotes'],      kde=False, color=\"g\", ax=axes[1, 2])\n#sns.distplot(df['hour'],                  kde=False, color=\"b\", ax=axes[1, 2])\nplt.tight_layout()"},{"cell_type":"markdown","metadata":{"_cell_guid":"58b67d74-9209-6228-40aa-174a19d24dce"},"source":"# What can we know about Apple, its products and ratings? "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"53854f07-43ec-b1e4-3a10-391dc161c80b"},"outputs":[],"source":"df_apple = df.loc[df['BrandName'].isin(['Apple'])]\npivot = pd.pivot_table(df_apple,\n        values = ['Rating', 'ReviewVotes'],\n        index =  ['ProductName'],\n                   columns= [],\n                   aggfunc=[np.sum, np.mean, np.count_nonzero], \n                   margins=True, fill_value=0).sort_values(by=('count_nonzero', 'Rating'), ascending=False).fillna('')\ntopmost_prods = pivot.reindex().head(n=30)\ntopmost_prods = topmost_prods.reset_index()\ntopmost_prods"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6301f727-54b6-0ae5-6827-99b49760fa31"},"outputs":[],"source":"tt_brand = topmost_prods['ProductName']\ntt_brand2 = tt_brand.reset_index()\ntop_10_prod_list = list(set(tt_brand2['ProductName']))\ntop_10_prod_list"},{"cell_type":"markdown","metadata":{"_cell_guid":"ff5d041d-b68e-88f9-0f58-07db7f9b6ac6"},"source":"Apple's flagship products are cetainly a slightly costlier. "},{"cell_type":"markdown","metadata":{"_cell_guid":"8e5a847e-0d79-a959-6338-bcf7cb941da2"},"source":"# Who is able to charge more to the customers? Apple or Samsung?"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a674265e-8ad5-61ad-5dd7-b10c14fbee42"},"outputs":[],"source":"apple_samsumg = ['Apple', 'Samsung']\ndf_top_ten = df.loc[df['BrandName'].isin(apple_samsumg)]\ndf_small = df_top_ten[['BrandName', \n               'Price', \n               'Rating'\n              ]]\nsns.pairplot(df_small, hue='BrandName', size=5)"},{"cell_type":"markdown","metadata":{"_cell_guid":"d81d345f-910d-7b51-65a9-794eb4e19074"},"source":"I was expecting something different, but this is it! I have to admit, this simple method is not exactly creating a one to one comparison. "},{"cell_type":"markdown","metadata":{"_cell_guid":"ed3136bd-af43-d109-292d-18be935e9809"},"source":"# K Mean clustering use to find out important words in top ten Brands"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bc5a6588-ed3e-9f7a-dfcf-33847d01714a"},"outputs":[],"source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_selection import SelectKBest\n\ndef find_correlations_one_brand(company):\n    df_one_company = df.loc[df['BrandName'].isin([company])]\n    def corr_matrix_of_important_words(term_doc_mat, word_list, scores, n_features_to_keep):\n        selector = SelectKBest(k=n_features_to_keep).fit(term_doc_mat, scores)\n        informative_words_index = selector.get_support(indices=True)\n        labels = [word_list[i] for i in informative_words_index]\n        data = pd.DataFrame(term_doc_mat[:,informative_words_index].todense(), columns=labels)\n        data['Score'] = df_one_company.Rating\n        return(data.corr())\n\n    def heat_map(corrs_mat):\n        sns.set(style=\"white\")\n        f, ax = plt.subplots(figsize=(20, 20))\n        mask = np.zeros_like(corrs_mat, dtype=np.bool)\n        mask[np.triu_indices_from(mask)] = True \n        # Generate a custom diverging colormap\n        cmap = sns.diverging_palette(220, 10, as_cmap=True)\n        sns.heatmap(corrs_mat, mask=mask, cmap=cmap, ax=ax)\n    vectorizer = CountVectorizer(max_features = 500, stop_words='english')\n    term_doc_mat = vectorizer.fit_transform(df_one_company.Reviews.values.astype('U'))\n    word_list = vectorizer.get_feature_names()\n\n    corrs_large = corr_matrix_of_important_words(term_doc_mat, word_list, df_one_company.Rating, 60)\n    #print(corrs_large.Score.sort_values(inplace=False)[:-1])\n    corrs_small = corr_matrix_of_important_words(term_doc_mat, word_list, df_one_company.Rating, 15)\n    heat_map(corrs_small)\n\nfor item in top_10_brand_list:\n    print (item)\n    find_correlations_one_brand(item)"},{"cell_type":"markdown","metadata":{"_cell_guid":"b63399ed-5d01-77f0-5553-b21d444aaf6b"},"source":"# Funny to see those words :) "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"85db911d-bad9-6004-9017-a159d414c7f8"},"outputs":[],"source":"df_one_company.columns"},{"cell_type":"markdown","metadata":{"_cell_guid":"4566d51c-3dba-7977-adbe-ff4155306802"},"source":"# Lets make a word cloud of words appearing in the reviews of various companies: For speed, running this only on Apple vs Samsung "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7b601fd3-8fa3-26b8-e47c-8a6cc491aa6d"},"outputs":[],"source":"def create_word_cloud(one_company):\n    try: \n        df_one_company = df.loc[df['BrandName'].isin([one_company])]\n        df_one_company_sample = df_one_company.sample(frac=0.05)\n        word_cloud_collection = ''\n        for val in df_one_company_sample.Reviews.str.lower():\n            tokens = nltk.word_tokenize(val)\n            tokens = [word for word in tokens if word not in stopwords.words('english')]\n            for words in tokens:\n                word_cloud_collection = word_cloud_collection + words + ' '\n        wordcloud = WordCloud(max_font_size=50, width=500, height=500).generate(word_cloud_collection)\n        plt.figure(figsize=(20,20))\n        plt.imshow(wordcloud)\n        plt.axis(\"off\")\n        plt.show()\n    except: \n        pass\n    \n#company_list = ['Apple', 'Samsung']\nfor i in top_10_brand_list:\n    print (i)\n    create_word_cloud(i)"},{"cell_type":"markdown","metadata":{"_cell_guid":"143f9a27-2f02-b133-0e23-4797b30191b7"},"source":"# Let us run machine learning algorithms on the text data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5b719148-1201-1af7-bd72-33e7f0523d87"},"outputs":[],"source":"def review_to_wordlist( review, remove_stopwords=True ):\n    # Function to convert a document to a sequence of words,\n    # optionally removing stop words.  Returns a list of words.\n    # 1. Remove HTML\n    review_text = BeautifulSoup(review).get_text()\n    # 2. Remove non-letters\n    review_text = re.sub(\"[^a-zA-Z]\",\" \", review)\n    # 3. Convert words to lower case and split them\n    words = review_text.lower().split()\n    # 4. Optionally remove stop words (false by default)\n    if remove_stopwords:\n        stops = set(stopwords.words(\"english\"))\n        words = [w for w in words if not w in stops]\n\n    b=[]\n    stemmer = english_stemmer #PorterStemmer()\n    for word in words:\n        b.append(stemmer.stem(word))\n    # 5. Return a list of words\n    return(words)\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.figure(figsize=(10,10))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        cm = cm.round(3)\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4eede84b-a199-6088-0867-f9eaa00feb94"},"outputs":[],"source":"mod_df = df[df['Reviews'].isnull()==False]\nmod_df = mod_df.sample(frac = 0.01)\ntrain, test = train_test_split(mod_df, test_size = 0.3)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"143b3bc5-a8cb-74fb-254e-769b86aef6d8"},"outputs":[],"source":"clean_train_reviews = []\nfor review in train['Reviews']:\n    clean_train_reviews.append( \" \".join(review_to_wordlist(review)))\n    \nclean_test_reviews = []\nfor review in test['Reviews']:\n    clean_test_reviews.append( \" \".join(review_to_wordlist(review)))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1bb30088-a588-8e8f-c037-49d0faedb21a"},"outputs":[],"source":"vectorizer = TfidfVectorizer( min_df=2, max_df=0.95, max_features = 200000, ngram_range = ( 1, 4 ),\n                              sublinear_tf = True )\n\nvectorizer = vectorizer.fit(clean_train_reviews)\ntrain_features = vectorizer.transform(clean_train_reviews)\n\ntest_features = vectorizer.transform(clean_test_reviews)\nfselect = SelectKBest(chi2 , k=10000)\ntrain_features = fselect.fit_transform(train_features, train[\"Rating\"])\ntest_features = fselect.transform(test_features)"},{"cell_type":"markdown","metadata":{"_cell_guid":"93dc9270-9910-a3b9-94bd-6903a89b186c"},"source":"# Machine learning"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"14ef9ee8-c283-0252-8694-34af23a82f6a"},"outputs":[],"source":"classifiers = [('RandomForestClassifierG', RandomForestClassifier(n_jobs=-1, criterion='gini')),\n               ('RandomForestClassifierE', RandomForestClassifier(n_jobs=-1, criterion='entropy')),\n               ('AdaBoostClassifier', AdaBoostClassifier()),\n               ('ExtraTreesClassifier', ExtraTreesClassifier(n_jobs=-1)),\n               ('DecisionTreeClassifier', DecisionTreeClassifier()),\n               ('LogisticRegression', LogisticRegression()),\n               ('MultinomialNB', MultinomialNB(alpha=0.001)), \n               ('SGDClassifier', SGDClassifier(loss='modified_huber', n_iter=5, random_state=0, shuffle=True)),\n               ('GradientBoostingClassifier', GradientBoostingClassifier()),\n               \n              ]\nallscores = []\nfor name, classifier in classifiers:\n    scores = []\n    for i in range(1): # 3 runs\n        print (name)\n\n        classifier.fit( train_features, train[\"Rating\"] )\n        pred = classifier.predict( test_features.toarray() )\n        print('prediction accuracy: ', accuracy_score(test['Rating'], pred))\n        cnf_matrix = confusion_matrix(test['Rating'], pred)\n        plot_confusion_matrix(cnf_matrix, classes=['1','2','3','4','5'],\n                      title='Confusion matrix, with normalization', normalize=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a857fd29-16c6-d721-e480-29c7563c7286","collapsed":true},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}