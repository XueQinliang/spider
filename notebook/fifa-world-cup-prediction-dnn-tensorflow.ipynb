{"cells":[{"metadata":{"_uuid":"705572518e4ba527bc7dc67891feef3cb284e6e9"},"cell_type":"markdown","source":"Version 2 : \n\n* Made the neural deep to 4 level to improve the accuracy\n* Decreased number of steps and increased batch size "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport os\nprint(os.listdir(\"../input\"))\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"52446757bb655037a83447b1844d3d3d34f8869a"},"cell_type":"markdown","source":"**FIFA Ranking Data Set **\n\nTaking Data for [FIFA Ranking ](https://www.kaggle.com/tadhgfitzgerald/fifa-international-soccer-mens-ranking-1993now)\n\n* Collecting relevant columns and adjusting according to other Data set"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"rankings = pd.read_csv('../input/fifa-international-soccer-mens-ranking-1993now/fifa_ranking.csv')\n\nrankings = rankings.loc[:,['rank', 'country_full', 'country_abrv', 'cur_year_avg_weighted', 'rank_date', \n                           'two_year_ago_weighted', 'three_year_ago_weighted']]\nrankings.country_full.replace(\"^IR Iran*\", \"Iran\", regex=True, inplace=True)\nrankings['weighted_points'] =  rankings['cur_year_avg_weighted'] + rankings['two_year_ago_weighted'] + rankings['three_year_ago_weighted']\nrankings['rank_date'] = pd.to_datetime(rankings['rank_date'])\nrankings.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"baaac6a5023c6962c2989f918d5d8408ac3256ec"},"cell_type":"markdown","source":"**International Football result Data Set**\n\n* Data is taken from [International football results from 1872 to 2018](https://www.kaggle.com/martj42/international-football-results-from-1872-to-2017)\n* Adjusting the Country name according to other data set"},{"metadata":{"trusted":true,"_uuid":"2d7e757d3606e1354e63a4d9c0b9143672b148bc"},"cell_type":"code","source":"matches = pd.read_csv(\"../input/international-football-results-from-1872-to-2017/results.csv\")\nmatches =  matches.replace({'Germany DR': 'Germany', 'China': 'China PR'})\nmatches['date'] = pd.to_datetime(matches['date'])\nmatches.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"77e3bb18aa0989456035e7e2edb4d4ee13e0df90"},"cell_type":"markdown","source":"**World Cup 2018 Data Set**\n\n* Used World Cup 2018 Data set from [FIFA worldcup 2018 Dataset](https://www.kaggle.com/ahmedelnaggar/fifa-worldcup-2018-dataset)\n* Adjusted the Country Name according to other Data Set"},{"metadata":{"trusted":true,"_uuid":"7d4d36a7aaa0ab950e1b741b1812824c02660a29"},"cell_type":"code","source":"world_cup = pd.read_csv(\"../input/fifa-worldcup-2018-dataset/World Cup 2018 Dataset.csv\")\nworld_cup = world_cup.loc[:, ['Team', 'Group', 'First match \\nagainst', 'Second match\\n against', 'Third match\\n against']]\nworld_cup = world_cup.dropna(how='all')\nworld_cup = world_cup.replace({\"IRAN\": \"Iran\", \n                               \"Costarica\": \"Costa Rica\", \n                               \"Porugal\": \"Portugal\", \n                               \"Columbia\": \"Colombia\", \n                               \"Korea\" : \"Korea Republic\"})\nworld_cup = world_cup.set_index('Team')\nworld_cup.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b16024ecff4fa26b8e18371a14b3ff083c519a45"},"cell_type":"markdown","source":"** Feature extraction**\n\nI join the matches with the ranks of the different teams.\n\nThen extract some features:\n\n* point and rank differences\n* if the game was for some stakes, because my naive view was that typically friendly matches are harder to predict (TODO differentiate the WC matches from the rest)\n* how many days the different teams were able to rest but this turned out to be not important enough to be worth the hassle\n* include the participant countries as a one hot vector but that did not appear to be a strong predictor either"},{"metadata":{"trusted":true,"_uuid":"fe58f97e207bf5191d7788b3fee1c4a37228c744"},"cell_type":"code","source":"# Get Complete Date wise Ranking table\nrankings = rankings.set_index(['rank_date'])\\\n                    .groupby(['country_full'],group_keys = False)\\\n                    .resample('D').first()\\\n                    .fillna(method='ffill')\\\n                    .reset_index()\nrankings.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7e1d14ab8701fb1b0a49a5f20402aa250726da22"},"cell_type":"code","source":"#Join Ranking with match \nmatches = matches.merge(rankings,\n                         left_on=['date', 'home_team'],\n                         right_on=['rank_date', 'country_full'])\n# matches.head()\n\nmatches = matches.merge(rankings, \n                        left_on=['date', 'away_team'], \n                        right_on=['rank_date', 'country_full'], \n                        suffixes=('_home', '_away'))\nmatches.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"13f10c061e597cac0c59c63a1d96533869071dd4"},"cell_type":"markdown","source":"**Finding corrilation with each columns **"},{"metadata":{"trusted":true,"_uuid":"864426596810605cafcc430b99294892e749fc1d"},"cell_type":"code","source":"fig, ax = plt.subplots()\nfig.set_size_inches(20, 20)\ncorr1 = matches.corr()\ncorr1\nsns.heatmap(corr1,annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"56b3f0efe15f5e6841d476911d05589fa468267d","collapsed":true},"cell_type":"code","source":"# feature generation\nmatches['rank_difference'] = matches['rank_home'] - matches['rank_away']\nmatches['average_rank'] = (matches['rank_home'] + matches['rank_away'])/2\nmatches['point_difference'] = matches['weighted_points_home'] - matches['weighted_points_away']\nmatches['score_difference'] = matches['home_score'] - matches['away_score']\nmatches['is_won'] = matches['score_difference'] > 0 # take draw as lost\nmatches['is_stake'] = matches['tournament'] != 'Friendly'\n\n# I tried earlier rest days but it did not turn to be useful\nmax_rest = 30\nmatches['rest_days'] = matches.groupby('home_team').diff()['date'].dt.days.clip(0,max_rest).fillna(max_rest)\n\n# I tried earlier the team as well but that did not make a difference either\nmatches['wc_participant'] = matches['home_team'] * matches['home_team'].isin(world_cup.index.tolist())\nmatches['wc_participant'] = matches['wc_participant'].replace({'':'Other'})\nmatches = matches.join(pd.get_dummies(matches['wc_participant']))\n#matches.to_csv(\"out.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1b23fc6639b959505d0ab76b88b2aef665c1701b"},"cell_type":"markdown","source":"**Modeling using deep neural net**\n\n* Created a deep neural net with 2 hidden layer of 5 and 10 nodes \n* Tried different parameters in batch size and learning rate, maximum AUC and accuracy found around 0.7\n"},{"metadata":{"trusted":true,"_uuid":"4c9a7f1dedb6e02bfff706ae037e8c5e3b541032","collapsed":true},"cell_type":"code","source":"from __future__ import print_function\n\nimport math\n\nfrom IPython import display\nfrom matplotlib import cm\nfrom matplotlib import gridspec\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn import metrics\nimport tensorflow as tf\nfrom tensorflow.python.data import Dataset\n\ntf.logging.set_verbosity(tf.logging.ERROR)\npd.options.display.max_rows = 10\npd.options.display.float_format = '{:.1f}'.format\nmatches = matches.reindex(\n       np.random.permutation(matches.index))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"947bdc7dd84f40f92134b5d0b35c96177208f242"},"cell_type":"code","source":"def preprocess_features(matches):\n    \n    selected_features = matches[[\"average_rank\", \"rank_difference\", \"point_difference\", \"is_stake\"]]\n    processed_features = selected_features.copy()\n    return processed_features\n\ndef preprocess_targets(matches):\n    output_targets = pd.DataFrame()\n  # Scale the target to be in units of thousands of dollars.\n    output_targets[\"is_won\"] = matches['is_won']\n    return output_targets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8151c1d943dac2a91d85beab113386f487de452a","collapsed":true},"cell_type":"code","source":"# Choose the first 60% i.e 10900 (out of 18167) examples for training.\ntraining_examples = preprocess_features(matches.head(10900))\ntraining_targets = preprocess_targets(matches.head(10900))\n\n# Choose the last 40% i.e 7267 (out of 18167) examples for validation.\nvalidation_examples = preprocess_features(matches.tail(7267))\nvalidation_targets = preprocess_targets(matches.tail(7267))\n\nComplete_Data_training = preprocess_features(matches)\nComplete_Data_Validation = preprocess_targets(matches)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"7bdfc223ba2f2a04081c646d12b3e1be0a9afa57"},"cell_type":"code","source":"def construct_feature_columns(input_features):\n    return set([tf.feature_column.numeric_column(my_feature)\n              for my_feature in input_features])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d2951abe18ccae452347ef7725077efc33bc3d72"},"cell_type":"code","source":"def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n    \"\"\"Trains a neural network model.\n  \n    Args:\n      features: pandas DataFrame of features\n      targets: pandas DataFrame of targets\n      batch_size: Size of batches to be passed to the model\n      shuffle: True or False. Whether to shuffle the data.\n      num_epochs: Number of epochs for which data should be repeated. None = repeat indefinitely\n    Returns:\n      Tuple of (features, labels) for next data batch\n    \"\"\"\n    \n    # Convert pandas data into a dict of np arrays.\n    features = {key:np.array(value) for key,value in dict(features).items()}                                           \n     # Construct a dataset, and configure batching/repeating.\n    ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit\n    ds = ds.batch(batch_size).repeat(num_epochs)\n    \n    # Shuffle the data, if specified.\n    if shuffle:\n        ds = ds.shuffle(10000)\n    \n    # Return the next batch of data.\n    features, labels = ds.make_one_shot_iterator().get_next()\n    return features, labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf7a907ac3c8c70de6f5e2bc2e30e0cc0593ffac","collapsed":true},"cell_type":"code","source":"def train_nn_classification_model(\n    my_optimizer,\n    steps,\n    batch_size,\n    hidden_units,\n    training_examples,\n    training_targets,\n    validation_examples,\n    validation_targets):\n    periods = 10\n    steps_per_period = steps / periods\n  # Create a DNNRegressor object.\n    my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 3.0)\n    dnn_classifier = tf.estimator.DNNClassifier(\n      feature_columns=construct_feature_columns(training_examples),\n      hidden_units=hidden_units,\n      optimizer=my_optimizer\n  )\n  # Create input functions.\n    training_input_fn = lambda: my_input_fn(training_examples, \n                                          training_targets[\"is_won\"], \n                                          batch_size=batch_size)\n    predict_training_input_fn = lambda: my_input_fn(training_examples, \n                                                  training_targets[\"is_won\"], \n                                                  num_epochs=1, \n                                                  shuffle=False)\n    predict_validation_input_fn = lambda: my_input_fn(validation_examples, \n                                                    validation_targets[\"is_won\"], \n                                                    num_epochs=1, \n                                                    shuffle=False)\n\n  # Train the model, but do so inside a loop so that we can periodically assess\n  # loss metrics.\n    # Train the model, but do so inside a loop so that we can periodically assess\n  # loss metrics.\n    print(\"Training model...\")\n    print(\"LogLoss (on training data):\")\n    training_log_losses = []\n    validation_log_losses = []\n    for period in range (0, periods):\n    # Train the model, starting from the prior state.\n        dnn_classifier.train(\n        input_fn=training_input_fn,\n        steps=steps_per_period\n    )\n        # Take a break and compute predictions.    \n        training_probabilities = dnn_classifier.predict(input_fn=predict_training_input_fn)\n        training_probabilities = np.array([item['probabilities'] for item in training_probabilities])\n    \n        validation_probabilities = dnn_classifier.predict(input_fn=predict_validation_input_fn)\n        validation_probabilities = np.array([item['probabilities'] for item in validation_probabilities])\n    \n        training_log_loss = metrics.log_loss(training_targets, training_probabilities)\n        validation_log_loss = metrics.log_loss(validation_targets, validation_probabilities)\n    # Occasionally print the current loss.\n        print(\"  period %02d : %0.2f\" % (period, training_log_loss))\n    # Add the loss metrics from this period to our list.\n        training_log_losses.append(training_log_loss)\n        validation_log_losses.append(validation_log_loss)\n    print(\"Model training finished.\")\n      # Output a graph of loss metrics over periods.\n    plt.ylabel(\"LogLoss\")\n    plt.xlabel(\"Periods\")\n    plt.title(\"LogLoss vs. Periods\")\n    plt.tight_layout()\n    plt.plot(training_log_losses, label=\"training\")\n    plt.plot(validation_log_losses, label=\"validation\")\n    plt.legend()\n\n    return dnn_classifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a802d4bd6e9c38e7edfca871ed3b01a1110e77fc"},"cell_type":"code","source":"linear_classifier = train_nn_classification_model(\n    my_optimizer=tf.train.AdagradOptimizer(learning_rate=0.07),\n    steps=3000,\n    batch_size=2000,\n    hidden_units=[5, 5,6,5],\n    training_examples=training_examples,\n    training_targets=training_targets,\n    validation_examples=validation_examples,\n    validation_targets=validation_targets)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da103a88c4b4780f0366f7880bfa34cb9959cf20"},"cell_type":"markdown","source":"**Checking AUC and accuracy of DNN Classifier model **"},{"metadata":{"trusted":true,"_uuid":"ecd85841ce50bdc2f5209c8004d2b83d7996c4ba"},"cell_type":"code","source":"predict_validation_input_fn = lambda: my_input_fn(validation_examples, \n                                                  validation_targets[\"is_won\"], \n                                                  num_epochs=1, \n                                                  shuffle=False)\n\n\nvalidation_probabilities = linear_classifier.predict(input_fn=predict_validation_input_fn)\n# Get just the probabilities for the positive class.\nvalidation_probabilities = np.array([item['probabilities'][1] for item in validation_probabilities])\n\nfalse_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(\n    validation_targets, validation_probabilities)\nplt.plot(false_positive_rate, true_positive_rate, label=\"our model\")\nplt.plot([0, 1], [0, 1], label=\"random classifier\")\n_ = plt.legend(loc=2)\n\n\nevaluation_metrics = linear_classifier.evaluate(input_fn=predict_validation_input_fn)\n\nprint(\"AUC on the validation set: %0.2f\" % evaluation_metrics['auc'])\nprint(\"Accuracy on the validation set: %0.2f\" % evaluation_metrics['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f91ee691f649a6002ab99611be57c5b9e5826b9"},"cell_type":"markdown","source":"**Training model on complete data set (Training + Validation) **"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0cd05a23009d1318a02940bafedc423dee21629a"},"cell_type":"code","source":"def train_complete_model(my_optimizer,\n    steps,\n    batch_size,\n    hidden_units,\n    Complete_Data_training,\n    Complete_Data_Validation) :\n    \n    periods = 10\n    steps_per_period = steps / periods\n  # Create a DNNRegressor object.\n    my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 3.0)\n    dnn_classifier = tf.estimator.DNNClassifier(\n      feature_columns=construct_feature_columns(Complete_Data_training),\n      hidden_units=hidden_units,\n      optimizer=my_optimizer\n  )\n    # Create input functions.\n    Complete_training_input_fn = lambda: my_input_fn(Complete_Data_training, \n                                          Complete_Data_Validation[\"is_won\"], \n                                          batch_size=batch_size)\n    predict_Complete_training_input_fn = lambda: my_input_fn(Complete_Data_training, \n                                                  Complete_Data_Validation[\"is_won\"], \n                                                  num_epochs=1, \n                                                  shuffle=False)\n    \n    print(\"Training model...\")\n    print(\"LogLoss (on training data):\")\n    training_log_losses = []\n    # validation_log_losses = []\n    for period in range (0, periods):\n    # Train the model, starting from the prior state.\n        dnn_classifier.train(\n        input_fn=Complete_training_input_fn,\n        steps=steps_per_period\n    )\n        # Take a break and compute predictions.    \n        Complete_training_probabilities = dnn_classifier.predict(input_fn=predict_Complete_training_input_fn)\n        Complete_training_probabilities = np.array([item['probabilities'] for item in Complete_training_probabilities])\n    \n        \n        training_log_loss = metrics.log_loss(Complete_Data_Validation, Complete_training_probabilities)\n        #validation_log_loss = metrics.log_loss(Complete_Data_Validation, validation_probabilities)\n    # Occasionally print the current loss.\n        print(\"  period %02d : %0.2f\" % (period, training_log_loss))\n    # Add the loss metrics from this period to our list.\n        training_log_losses.append(training_log_loss)\n        #validation_log_losses.append(validation_log_loss)\n    print(\"Model training finished.\")\n      # Output a graph of loss metrics over periods.\n    plt.ylabel(\"LogLoss\")\n    plt.xlabel(\"Periods\")\n    plt.title(\"LogLoss vs. Periods\")\n    plt.tight_layout()\n    plt.plot(training_log_losses, label=\"training\")\n    #plt.plot(validation_log_losses, label=\"validation\")\n    plt.legend()\n\n    return dnn_classifier\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c95851f026b26c4971f219e9e527a44289b5128d","collapsed":true},"cell_type":"code","source":"linear_classifier = train_complete_model(\n    my_optimizer=tf.train.AdagradOptimizer(learning_rate=0.07),\n    steps=3000,\n    batch_size=2000,\n    hidden_units=[5, 5,6,5],\n    Complete_Data_training=Complete_Data_training,\n    Complete_Data_Validation=Complete_Data_Validation)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7bcfe04a94dc612eb2a22f42486bf35c0cbf751c"},"cell_type":"markdown","source":"**World Cup simulation**"},{"metadata":{"_uuid":"4b6962611b01161558149c652b033495beea80f0"},"cell_type":"markdown","source":"**Group Ranking**"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e8e9547b77714a6933e4dfa87fa299da0982dcf9"},"cell_type":"code","source":"# let's define a small margin when we safer to predict draw then win\nmargin = 0.05\n\n# let's define the rankings at the time of the World Cup\nworld_cup_rankings = rankings.loc[(rankings['rank_date'] == rankings['rank_date'].max()) & \n                                    rankings['country_full'].isin(world_cup.index.unique())]\nworld_cup_rankings = world_cup_rankings.set_index(['country_full'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e4bc66805b7a9a9b194ea5b4e2e2564c314c06e"},"cell_type":"code","source":"world_cup_rankings.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"20b1c3d9cee75de364bd4b7529edf4601d9053c7"},"cell_type":"markdown","source":"**Looping through each loop to find out current match and predicting the value based on our trained model**"},{"metadata":{"trusted":true,"_uuid":"c5c0fb1d15efd7499ad21cc80576808884cd9f7e"},"cell_type":"code","source":"from itertools import combinations\n\nopponents = ['First match \\nagainst', 'Second match\\n against', 'Third match\\n against']\n\nworld_cup['points'] = 0\nworld_cup['total_prob'] = 0\n\nfor group in set(world_cup['Group']):\n    print('___Starting group {}:___'.format(group))\n    \n    for home, away in combinations(world_cup.query('Group ==\"{}\"'.format(group)).index, 2):\n        print(\"{} vs. {}: \".format(home, away), end='')\n        \n        row = pd.DataFrame(np.array([[np.nan, np.nan, np.nan, True]]), columns=validation_examples.columns)\n        home_rank = world_cup_rankings.loc[home, 'rank']\n        home_points = world_cup_rankings.loc[home, 'weighted_points']\n        opp_rank = world_cup_rankings.loc[away, 'rank']\n        opp_points = world_cup_rankings.loc[away, 'weighted_points']\n        row['average_rank'] = (home_rank + opp_rank) / 2\n        row['rank_difference'] = home_rank - opp_rank\n        row['point_difference'] = home_points - opp_points\n        row['is_won'] =np.nan\n        predict_validation_input_fn1 = lambda: my_input_fn(row, \n                                                  row[\"is_won\"], \n                                                  num_epochs=1, \n                                                  shuffle=False)\n        validation_probabilities1 = linear_classifier.predict(input_fn=predict_validation_input_fn1)\n        # Get just the probabilities for the positive class.\n        validation_probabilities1 = np.array([item['probabilities'][1] for item in validation_probabilities1])\n        #print(validation_probabilities1[0])\n        home_win_prob = validation_probabilities1[0]\n        world_cup.loc[home, 'total_prob'] += home_win_prob\n        world_cup.loc[away, 'total_prob'] += 1-home_win_prob\n        \n        points = 0\n        if home_win_prob <= 0.5 - margin:\n            print(\"{} wins with {:.2f}\".format(away, 1-home_win_prob))\n            world_cup.loc[away, 'points'] += 3\n        if home_win_prob > 0.5 - margin:\n            points = 1\n        if home_win_prob >= 0.5 + margin:\n            points = 3\n            world_cup.loc[home, 'points'] += 3\n            print(\"{} wins with {:.2f}\".format(home, home_win_prob))\n        if points == 1:\n            print(\"Draw\")\n            world_cup.loc[home, 'points'] += 1\n            world_cup.loc[away, 'points'] += 1\n\n        \n        \n        \n        \n        \n        ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bb85a418fe6211609a996051fcf4186bddc3e8c1"},"cell_type":"markdown","source":"**Single-elimination rounds**"},{"metadata":{"trusted":true,"_uuid":"cc79be63d5b287d4f4ed9705afa10254aed5710a"},"cell_type":"code","source":"pairing = [0,3,4,7,8,11,12,15,1,2,5,6,9,10,13,14]\n\nworld_cup = world_cup.sort_values(by=['Group', 'points', 'total_prob'], ascending=False).reset_index()\nnext_round_wc = world_cup.groupby('Group').nth([0, 1]) # select the top 2\nnext_round_wc = next_round_wc.reset_index()\nnext_round_wc = next_round_wc.loc[pairing]\nnext_round_wc = next_round_wc.set_index('Team')\n\nfinals = ['round_of_16', 'quarterfinal', 'semifinal', 'final']\n\nlabels = list()\nodds = list()\n\nfor f in finals:\n    print(\"___Starting of the {}___\".format(f))\n    iterations = int(len(next_round_wc) / 2)\n    winners = []\n\n    for i in range(iterations):\n        home = next_round_wc.index[i*2]\n        away = next_round_wc.index[i*2+1]\n        print(\"{} vs. {}: \".format(home,\n                                   away), \n                                   end='')\n        row = pd.DataFrame(np.array([[np.nan, np.nan, np.nan, True]]), columns=validation_examples.columns)\n        home_rank = world_cup_rankings.loc[home, 'rank']\n        home_points = world_cup_rankings.loc[home, 'weighted_points']\n        opp_rank = world_cup_rankings.loc[away, 'rank']\n        opp_points = world_cup_rankings.loc[away, 'weighted_points']\n        row['average_rank'] = (home_rank + opp_rank) / 2\n        row['rank_difference'] = home_rank - opp_rank\n        row['point_difference'] = home_points - opp_points\n        row['is_won'] =np.nan\n        predict_validation_input_fn1 = lambda: my_input_fn(row, \n                                                  row[\"is_won\"], \n                                                  num_epochs=1, \n                                                  shuffle=False)\n        validation_probabilities1 = linear_classifier.predict(input_fn=predict_validation_input_fn1)\n        # Get just the probabilities for the positive class.\n        validation_probabilities1 = np.array([item['probabilities'][1] for item in validation_probabilities1])\n        #print(validation_probabilities1[0])\n        home_win_prob = validation_probabilities1[0]\n\n        #home_win_prob = model.predict_proba(row)[:,1][0]\n        if home_win_prob <= 0.5:\n            print(\"{0} wins with probability {1:.2f}\".format(away, 1-home_win_prob))\n            winners.append(away)\n        else:\n            print(\"{0} wins with probability {1:.2f}\".format(home, home_win_prob))\n            winners.append(home)\n\n        labels.append(\"{}({:.2f}) vs. {}({:.2f})\".format(world_cup_rankings.loc[home, 'country_abrv'], \n                                                        1/home_win_prob, \n                                                        world_cup_rankings.loc[away, 'country_abrv'], \n                                                        1/(1-home_win_prob)))\n        odds.append([home_win_prob, 1-home_win_prob])\n                \n    next_round_wc = next_round_wc.loc[winners]\n    print(\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"27489e61c0473c664904ef0941913c85d9434ac3"},"cell_type":"markdown","source":"**Let's see a visualization**"},{"metadata":{"trusted":true,"_uuid":"6059e0f5a0c15c7f10b98ab3b4053e0bd0aff7e6","collapsed":true},"cell_type":"code","source":"import networkx as nx\nimport pydot\nfrom networkx.drawing.nx_pydot import graphviz_layout\n\nnode_sizes = pd.DataFrame(list(reversed(odds)))\nscale_factor = 0.3 # for visualization\nG = nx.balanced_tree(2, 3)\npos = graphviz_layout(G, prog='twopi', args='')\ncentre = pd.DataFrame(pos).mean(axis=1).mean()\n\nplt.figure(figsize=(10, 10))\nax = plt.subplot(1,1,1)\n# add circles \ncircle_positions = [(235, 'black'), (180, 'blue'), (120, 'red'), (60, 'yellow')]\n[ax.add_artist(plt.Circle((centre, centre), \n                          cp, color='grey', \n                          alpha=0.2)) for cp, c in circle_positions]\n\n# draw first the graph\nnx.draw(G, pos, \n        node_color=node_sizes.diff(axis=1)[1].abs().pow(scale_factor), \n        node_size=node_sizes.diff(axis=1)[1].abs().pow(scale_factor)*2000, \n        alpha=1, \n        cmap='Reds',\n        edge_color='black',\n        width=10,\n        with_labels=False)\n\n# draw the custom node labels\nshifted_pos = {k:[(v[0]-centre)*0.9+centre,(v[1]-centre)*0.9+centre] for k,v in pos.items()}\nnx.draw_networkx_labels(G, \n                        pos=shifted_pos, \n                        bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"black\", lw=.5, alpha=1),\n                        labels=dict(zip(reversed(range(len(labels))), labels)))\n\ntexts = ((10, 'Best 16', 'black'), (70, 'Quarter-\\nfinal', 'blue'), (130, 'Semifinal', 'red'), (190, 'Final', 'yellow'))\n[plt.text(p, centre+20, t, \n          fontsize=12, color='grey', \n          va='center', ha='center') for p,t,c in texts]\nplt.axis('equal')\nplt.title('Single-elimination phase\\npredictions with fair odds', fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2d5f880235af9a35424fe7660ebf19816efaec98"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}