{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"d1a5c055-7ba9-d3f7-916b-ccc80ad091b7"},"source":"A simple exploration notebook to get some insights about the data.\n\n**Please check the output tab for animation**\n\n**Objective:**\n\nIn this competition, The Nature Conservancy asks you to help them detect which species of fish appears on a fishing boat, based on images captured from boat cameras of various angles.  \n\nYour goal is to predict the likelihood of fish species in each picture.\n\nAs mentioned in the data page, there are eight target categories available in the dataset.\n\n 1. Albacore tuna\n 2. Bigeye tuna\n 3. Yellowfin tuna\n 4. Mahi Mahi\n 5. Opah\n 6. Sharks\n 7. Other (meaning that there are fish present but not in the above categories)\n 8. No Fish (meaning that no fish is in the picture)\n\n**Important points to note:**\n\n 1. Pre-trained models and external data are allowed in the competition, but need to be posted on this [official forum thread][1]\n 2. The competition comprises of two stages. Test data for second stage will be released in the last week.   \n\nFirst let us see the number of image files present for each of the species\n\n\n  [1]: https://www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring/forums/t/25428/official-pre-trained-model-and-data-thread/144487#post144487"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0d521342-a82f-7823-c3c0-3612c062220b"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom scipy.misc import imread\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input/train/\"]).decode(\"utf8\"))"},{"cell_type":"markdown","metadata":{"_cell_guid":"8c281f04-10ca-629f-aead-2c9876446bf4"},"source":"So there are 8 folders present inside the train folder, one for each species.\n\nNow let us check the number of files present in each of these sub folders. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"51729783-f7ec-695b-0c96-fff4b6e250e4"},"outputs":[],"source":"sub_folders = check_output([\"ls\", \"../input/train/\"]).decode(\"utf8\").strip().split('\\n')\ncount_dict = {}\nfor sub_folder in sub_folders:\n    num_of_files = len(check_output([\"ls\", \"../input/train/\"+sub_folder]).decode(\"utf8\").strip().split('\\n'))\n    print(\"Number of files for the species\",sub_folder,\":\",num_of_files)\n    count_dict[sub_folder] = num_of_files\n    \nplt.figure(figsize=(12,4))\nsns.barplot(list(count_dict.keys()), list(count_dict.values()), alpha=0.8)\nplt.xlabel('Fish Species', fontsize=12)\nplt.ylabel('Number of Images', fontsize=12)\nplt.show()\n    \n    "},{"cell_type":"markdown","metadata":{"_cell_guid":"2fd2fc45-2f65-2aa4-1c95-07225a6b9f40"},"source":"So the number of files for species ALB (Albacore tuna) is much higher than other species. \n\nLet us look at the number of files present in the test folder."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"58890b0d-6ab3-9703-efd5-2a4c7d1c2ea9"},"outputs":[],"source":"num_test_files = len(check_output([\"ls\", \"../input/test_stg1/\"]).decode(\"utf8\").strip().split('\\n'))\nprint(\"Number of test files present :\", num_test_files)"},{"cell_type":"markdown","metadata":{"_cell_guid":"d548a535-1913-73c4-3712-b963b693ef3a"},"source":"**Image Size:**\n\nNow let us look at the image size of each of the files and see what different sizes are available."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"edf3e546-fbe7-c5df-9930-5e1369d96f04"},"outputs":[],"source":"train_path = \"../input/train/\"\nsub_folders = check_output([\"ls\", train_path]).decode(\"utf8\").strip().split('\\n')\ndifferent_file_sizes = {}\nfor sub_folder in sub_folders:\n    file_names = check_output([\"ls\", train_path+sub_folder]).decode(\"utf8\").strip().split('\\n')\n    for file_name in file_names:\n        im_array = imread(train_path+sub_folder+\"/\"+file_name)\n        size = \"_\".join(map(str,list(im_array.shape)))\n        different_file_sizes[size] = different_file_sizes.get(size,0) + 1\n\nplt.figure(figsize=(12,4))\nsns.barplot(list(different_file_sizes.keys()), list(different_file_sizes.values()), alpha=0.8)\nplt.xlabel('Image size', fontsize=12)\nplt.ylabel('Number of Images', fontsize=12)\nplt.title(\"Image size present in train dataset\")\nplt.xticks(rotation='vertical')\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"38e19c5a-e3ad-31a2-0217-1f8e569b5a48"},"source":"So 720_1280_3 is the most common image size available in the train data and 10 different sizes are available. \n\n720_1244_3 is the smallest size of the available images in train set and 974_1732_3 is the largest one.\n\nNow let us look at the distribution in test dataset as well."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4358dd89-c6ed-67a4-4279-52bfded30aa6"},"outputs":[],"source":"test_path = \"../input/test_stg1/\"\nfile_names = check_output([\"ls\", test_path]).decode(\"utf8\").strip().split('\\n')\ndifferent_file_sizes = {}\nfor file_name in file_names:\n        size = \"_\".join(map(str,list(imread(test_path+file_name).shape)))\n        different_file_sizes[size] = different_file_sizes.get(size,0) + 1\n\nplt.figure(figsize=(12,4))\nsns.barplot(list(different_file_sizes.keys()), list(different_file_sizes.values()), alpha=0.8)\nplt.xlabel('File size', fontsize=12)\nplt.ylabel('Number of Images', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.title(\"Image size present in test dataset\")\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"7a8efb6b-9430-567a-d6b4-9afcdf238927"},"source":"Test set also has a very similar distribution.\n\n**Animation:**\n\nLet us try to have some animation on the available images.  Not able to embed the video in the notebook.\n\n**Please check the output tab for the animation**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"059855db-d8f1-7e3f-f46f-06c86c7a6b00"},"outputs":[],"source":"\nimport random\n\"\"\"\nimport matplotlib.animation as animation\nfrom matplotlib import animation, rc\nfrom IPython.display import HTML\n\nrandom.seed(12345)\ntrain_path = \"../input/train/\"\nsub_folders = check_output([\"ls\", train_path]).decode(\"utf8\").strip().split('\\n')\ndifferent_file_sizes = {}\nall_files = []\nfor sub_folder in sub_folders:\n    file_names = check_output([\"ls\", train_path+sub_folder]).decode(\"utf8\").strip().split('\\n')\n    selected_files = random.sample(file_names, 10)\n    for file_name in selected_files:\n        all_files.append([sub_folder,file_name])\n\nfig = plt.figure()\nsns.set_style(\"whitegrid\", {'axes.grid' : False})\nimg_file = \"\".join([train_path, sub_folder, \"/\", file_name])\nim = plt.imshow(imread(img_file), vmin=0, vmax=255)\n\ndef updatefig(ind):\n    sub_folder = all_files[ind][0]\n    file_name = all_files[ind][1]\n    img_file = \"\".join([train_path, sub_folder, \"/\", file_name])\n    im.set_array(imread(img_file))\n    plt.title(\"Species : \"+sub_folder, fontsize=15)\n    return im,\n\nani = animation.FuncAnimation(fig, updatefig, frames=len(all_files))\nani.save('lb.gif', fps=1, writer='imagemagick')\n#rc('animation', html='html5')\n#HTML(ani.to_html5_video())\nplt.show()\n\"\"\""},{"cell_type":"markdown","metadata":{"_cell_guid":"c090ddf7-c7ac-c2a4-2ac1-41d2dccf65f3"},"source":"**Basic CNN Model using Keras:**\n\nNow let us try to build a CNN model on the dataset. Due to the memory constraints of the kernels, let us take only (500,500,3) array from top left corner of each image and then try to classify based on that portion.\n\nKindly note that running it offline with the full image will give much better results."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fe675aa6-a84a-9264-8940-8c1a9f8ce374"},"outputs":[],"source":"\nimport random\nfrom subprocess import check_output\nfrom scipy.misc import imread\nimport numpy as np\nnp.random.seed(2016)\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Convolution2D, MaxPooling2D\nfrom keras.utils import np_utils\nfrom keras import backend as K\n\nbatch_size = 1\nnb_classes = 8\nnb_epoch = 1\n\nimg_rows, img_cols, img_rgb = 500, 500, 3\nnb_filters = 4\npool_size = (2, 2)\nkernel_size = (3, 3)\ninput_shape = (img_rows, img_cols, 3)\n\nspecies_map_dict = {\n'ALB':0,\n'BET':1,\n'DOL':2,\n'LAG':3,\n'NoF':4,\n'OTHER':5,\n'SHARK':6,\n'YFT':7\n}\n\ndef batch_generator_train(sample_size):\n\ttrain_path = \"../input/train/\"\n\tall_files = []\n\ty_values = []\n\tsub_folders = check_output([\"ls\", train_path]).decode(\"utf8\").strip().split('\\n')\n\tfor sub_folder in sub_folders:\n\t\tfile_names = check_output([\"ls\", train_path+sub_folder]).decode(\"utf8\").strip().split('\\n')\n\t\tfor file_name in file_names:\n\t\t\tall_files.append([sub_folder, '/', file_name])\n\t\t\ty_values.append(species_map_dict[sub_folder])\n\tnumber_of_images = range(len(all_files))\n\n\tcounter = 0\n\twhile True:\n\t\timage_index = random.choice(number_of_images)\n\t\tfile_name = \"\".join([train_path] + all_files[image_index])\n\t\tprint(file_name)\n\t\ty = [0]*8\n\t\ty[y_values[image_index]] = 1\n\t\ty = np.array(y).reshape(1,8)\n\t\t\n\t\tim_array = imread(file_name)\n\t\tX = np.zeros([1, img_rows, img_cols, img_rgb])\n\t\t#X[:im_array.shape[0], :im_array.shape[1], 3] = im_array.copy().astype('float32')\n\t\tX[0, :, :, :] = im_array[:500,:500,:].astype('float32')\n\t\tX /= 255.\n        \n\t\tprint(X.shape)\n\t\tyield X,y\n\t\t\n\t\tcounter += 1\n\t\t#if counter == sample_size:\n\t\t#\tbreak\n\ndef batch_generator_test(all_files):\n\tfor file_name in all_files:\n\t\tfile_name = test_path + file_name\n\t\t\n\t\tim_array = imread(file_name)\n\t\tX = np.zeros([1, img_rows, img_cols, img_rgb])\n\t\tX[0,:, :, :] = im_array[:500,:500,:].astype('float32')\n\t\tX /= 255.\n\n\t\tyield X\n\n\ndef keras_cnn_model():\n\tmodel = Sequential()\n\tmodel.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],\n                        border_mode='valid',\n                        input_shape=input_shape))\n\tmodel.add(Activation('relu'))\n\tmodel.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1]))\n\tmodel.add(Activation('relu'))\n\tmodel.add(MaxPooling2D(pool_size=pool_size))\n\tmodel.add(Dropout(0.25))\t\n\tmodel.add(Flatten())\n\tmodel.add(Dense(128))\n\tmodel.add(Activation('relu'))\n\tmodel.add(Dropout(0.5))\n\tmodel.add(Dense(nb_classes))\n\tmodel.add(Activation('softmax'))\n\tmodel.compile(loss='categorical_crossentropy', optimizer='adadelta')\n\treturn model\n\nmodel = keras_cnn_model()\nfit= model.fit_generator(\n\tgenerator = batch_generator_train(100),\n\tnb_epoch = 1,\n\tsamples_per_epoch = 100\n)\n\ntest_path = \"../input/test_stg1/\"\nall_files = []\nfile_names = check_output([\"ls\", test_path]).decode(\"utf8\").strip().split('\\n')\nfor file_name in file_names:\n\tall_files.append(file_name)\n#preds = model.predict_generator(generator=batch_generator_test(all_files), val_samples=len(all_files))\n\n#out_df = pd.DataFrame(preds)\n#out_df.columns = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\n#out_df['image'] = all_files\n#out_df.to_csv(\"sample_sub_keras.csv\", index=False)"},{"cell_type":"markdown","metadata":{"_cell_guid":"43c141d1-d19d-d739-56f1-7686a8710bca"},"source":"More to come.!"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}