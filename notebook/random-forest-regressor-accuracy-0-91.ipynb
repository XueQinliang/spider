{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"21ace5bc-23b6-9fc8-fc0e-a1ca3b59ee15"},"source":"Using a Random Forest Regressor now, getting a **much** better accuracy score. See below."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"578d0c98-1823-ed78-6e55-498e03ed14fe"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nimport matplotlib.pyplot as plt\n\nfrom subprocess import check_output\nfrom datetime import time\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"92db4e2c-3d79-33bd-f0e2-44be65de0d74"},"outputs":[],"source":"def time_to_seconds(time):\n    return time.hour * 3600 + time.minute * 60 + time.second"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"47fa2d50-b985-164f-ece1-29ddeb7561ef"},"outputs":[],"source":"df = pd.read_csv(\"../input/data.csv\")\n# Drop columns\ndf = df.drop(\"date\", axis=1)\n# center timestamp\nnoon = time_to_seconds(time(12, 0, 0))\ndf.timestamp = df.timestamp.apply(lambda t: abs(noon - t))\n# one hot encode categorical columns\ncolumns = [\"day_of_week\", \"month\", \"hour\"]\ndf = pd.get_dummies(df, columns=columns)\ndf.head(10)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4587767f-466b-3429-4510-bd87b6197295"},"outputs":[],"source":"# Extract the training and test data\ndata = df.values\nX = data[:, 1:]  # all rows, no label\ny = data[:, 0]  # all rows, label only\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ca586e1a-b6b7-3cbc-ef9d-1ee25f99fc4c"},"outputs":[],"source":"# Scale the data to be between -1 and 1\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ce28bb53-7566-3bc3-ff33-b581ff96991f"},"outputs":[],"source":"# Establish model\nmodel = RandomForestRegressor(n_jobs=-1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e3227ae1-1211-d458-4b8a-f5cb9f05b8c2"},"outputs":[],"source":"# Try different numbers of n_estimators - this will take a minute or so\nestimators = np.arange(10, 200, 10)\nscores = []\nfor n in estimators:\n    model.set_params(n_estimators=n)\n    model.fit(X_train, y_train)\n    scores.append(model.score(X_test, y_test))\nplt.title(\"Effect of n_estimators\")\nplt.xlabel(\"n_estimator\")\nplt.ylabel(\"score\")\nplt.plot(estimators, scores)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a3ca6b14-dd6b-2f2c-99b7-c6b3db57b755"},"outputs":[],"source":"scores"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d8c07b9f-a5f7-04b3-e4a2-cf08d127dadc"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}