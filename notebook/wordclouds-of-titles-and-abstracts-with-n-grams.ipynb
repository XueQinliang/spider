{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"3b9fce6a-0682-6a63-26cc-9f70ea8c9e50"},"source":"We generate simple, frequency-based wordclouds of both the abstracts and the titles, after some text normalization. We will identify bigrams and tigrams, lemmatize, and remove stopwords. We need a handful of tools from nltk:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5311c1c2-fecc-b9ec-a55e-e85a89b15ffe"},"outputs":[],"source":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport string\nfrom matplotlib import rcParams\nfrom nltk import WordNetLemmatizer\nfrom wordcloud import WordCloud, STOPWORDS\nfrom nltk.corpus import stopwords\nfrom nltk import pos_tag, sent_tokenize, word_tokenize, BigramAssocMeasures,\\\n    BigramCollocationFinder, TrigramAssocMeasures, TrigramCollocationFinder\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"},{"cell_type":"markdown","metadata":{"_cell_guid":"236ab273-8974-cc2a-e96d-3d8a55975c28"},"source":"The following functions do the text normalization"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b29e9690-759f-7bc5-3405-d00f3c1a56df"},"outputs":[],"source":"def get_bitrigrams(full_text, threshold=30):\n    if isinstance(full_text, str):\n        text = full_text\n    else:\n        text = \" \".join(full_text)\n    bigram_measures = BigramAssocMeasures()\n    trigram_measures = TrigramAssocMeasures()\n    finder = BigramCollocationFinder.from_words(text.split())\n    finder.apply_freq_filter(3)\n    bigrams = {\" \".join(words): \"_\".join(words)\n               for words in finder.above_score(bigram_measures.likelihood_ratio, threshold)}\n    finder = TrigramCollocationFinder.from_words(text.split())\n    finder.apply_freq_filter(3)\n    trigrams = {\" \".join(words): \"_\".join(words)\n                for words in finder.above_score(trigram_measures.likelihood_ratio, threshold)}\n    return bigrams, trigrams\n\n\ndef replace_bitrigrams(text, bigrams, trigrams):\n    if isinstance(text, str):\n        texts = [text]\n    else:\n        texts = text\n    new_texts = []\n    for t in texts:\n        t_new = t\n        for k, v in trigrams.items():\n            t_new = t_new.replace(k, v)\n        for k, v in bigrams.items():\n            t_new = t_new.replace(\" \" + k + \" \", \" \" + v + \" \")\n        new_texts.append(t_new)\n    if len(new_texts) == 1:\n        return new_texts[0]\n    else:\n        return new_texts\n\n\ndef process_text(text, lemmatizer, translate_table, stopwords):\n    processed_text = \"\"\n    for sentence in sent_tokenize(text):\n        tagged_sentence = pos_tag(word_tokenize(sentence.translate(translate_table)))\n        for word, tag in tagged_sentence:\n            word = word.lower()\n            if word not in stopwords:\n                if tag[0] != 'V':\n                    processed_text += lemmatizer.lemmatize(word) + \" \"\n    return processed_text\n\n\ndef get_all_processed_texts(texts, lemmatizer, translate_table, stopwords):\n    processed_texts = []\n    for index, doc in enumerate(texts):\n        processed_texts.append(process_text(doc, wordnet_lemmatizer, translate_table, stop))\n    bigrams, trigrams = get_bitrigrams(processed_texts)\n    very_processed_texts = replace_bitrigrams(processed_texts, bigrams, trigrams)\n    return \" \".join(very_processed_texts)"},{"cell_type":"markdown","metadata":{"_cell_guid":"2c6eb4a6-d8ff-e82b-fca8-c436e66629e6"},"source":"Next we read the dataset and initialize what we need for language processing. We restrict the analysis to 2016."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"31c57494-a1e8-e0e2-c974-d844665d2197"},"outputs":[],"source":"records = pd.read_csv(\"../input/scirate_quant-ph.csv\", dtype={\"id\": str}, index_col=0)\nrecords = records[records[\"year\"] == 2016]\nwordnet_lemmatizer = WordNetLemmatizer()\nstop = set(stopwords.words('english'))\ntranslate_table = dict((ord(char), \" \") for char in string.punctuation)"},{"cell_type":"markdown","metadata":{"_cell_guid":"a87fb741-c773-f255-0935-e9a0c3d63da2"},"source":"Using all words\n-------------------\nThe following image is the wordcloud for the titles. Unfortunately, very few of the bi- and trigrams appear."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"95290e62-2812-45d2-36ea-2bfb6b6a34c1"},"outputs":[],"source":"wordcloud = WordCloud(background_color=\"white\").\\\n    generate(get_all_processed_texts(records[\"title\"], wordnet_lemmatizer, translate_table, stop))\nplt.figure(figsize=(8, 5))\nplt.axis(\"off\")\nplt.imshow(wordcloud)"},{"cell_type":"markdown","metadata":{"_cell_guid":"a33b1408-480e-4b1a-3fc5-fdf9ad8c6097"},"source":"The following one is the same for the abstracts. Despite excessive stopword removal, we still see a lot of junk."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"465af974-fa57-8cdb-9dfa-8c85c9a50d3a"},"outputs":[],"source":"wordcloud = WordCloud(stopwords=STOPWORDS, background_color=\"white\").\\\n    generate(get_all_processed_texts(records[\"abstract\"], wordnet_lemmatizer, translate_table, stop))\nplt.figure(figsize=(8, 5))\nplt.axis(\"off\")\nplt.imshow(wordcloud)"},{"cell_type":"markdown","metadata":{"_cell_guid":"aea2c22a-4b5e-2c0a-514b-65a352ccc595"},"source":"Using bi- and trigrams alone\n-----------------------------------\nWe get something more interesting if we restrict the analysis to the bi- and trigrams. There is a reassuring overlap between the two, although curiously authors are more keen to point out tensor networks in the title than in the abstracts."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"db21608d-ee84-02e1-4824-d40ab83b23d3"},"outputs":[],"source":"def use_ngrams_only(texts, lemmatizer, translate_table, stopwords):\n    processed_texts = []\n    for index, doc in enumerate(texts):\n        processed_texts.append(process_text(doc, wordnet_lemmatizer, translate_table, stop))\n    bigrams, trigrams = get_bitrigrams(processed_texts)\n    indexed_texts = []\n    for doc in processed_texts:\n        current_doc = []\n        for k, v in trigrams.items():\n            c = doc.count(k)\n            if c > 0:\n                current_doc += [v] * c\n                doc = doc.replace(k, v)\n        for k, v in bigrams.items():\n            current_doc += [v] * doc.count(\" \" + k + \" \")\n        indexed_texts.append(\" \".join(current_doc))\n    return \" \".join(indexed_texts)\n\nwordcloud = WordCloud(stopwords=STOPWORDS, background_color=\"white\").\\\n    generate(use_ngrams_only(records[\"title\"], wordnet_lemmatizer, translate_table, stop))\nplt.figure(figsize=(8, 5))\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.show()\n\nwordcloud = WordCloud(stopwords=STOPWORDS, background_color=\"white\").\\\n    generate(use_ngrams_only(records[\"abstract\"], wordnet_lemmatizer, translate_table, stop))\nplt.figure(figsize=(8, 5))\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"cb09375a-b8d6-cfce-a624-5975bb467255"},"source":"I love how \"et al\" becomes a leading topic in the abstracts."},{"cell_type":"markdown","metadata":{"_cell_guid":"df1b8391-0ac5-ea8c-ed0e-bdcb6a0b1fcd"},"source":"Alternative representation of author histogram\n-----------------------------------------------------------\nWe can plot a word cloud for the authors as well, instead of a [histogram](https://www.kaggle.com/peterwittek/d/peterwittek/scirate-quant-ph/top-authors-in-quant-ph-in-2016)."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"331ff298-f060-eccc-02a3-4f6486f7316b"},"outputs":[],"source":"wordcloud = WordCloud(stopwords=STOPWORDS, background_color=\"white\").\\\n    generate(\";\".join(records[\"authors\"]).replace(\" \", \"_\"))\nplt.figure(figsize=(8, 5))\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.show()"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}