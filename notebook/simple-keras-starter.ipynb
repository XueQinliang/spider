{"cells":[{"metadata":{"_cell_guid":"d93e43c9-8a48-41c7-93f2-1dbeec38f80e","_uuid":"b2538ad6607dc541ad42195df42b3c70ecdd59a3"},"cell_type":"markdown","source":"# Simple Keras Starter"},{"metadata":{"_uuid":"1cd566d05d67d624f5e466a3a28ff4eb6af7aa5b"},"cell_type":"markdown","source":"EDITS: \n- Added rescaling in image preprocessing for better NN stability\n- Cleared the clutter in `imshow_group()` function"},{"metadata":{"_uuid":"ef8f53f55994115f65bb320cffac92b17d6f2103"},"cell_type":"markdown","source":"This is a simple 5 layer CNN model built with keras. It gets a score of around 0.75 on the leaderboard."},{"metadata":{"_cell_guid":"c386cfd1-3d2e-4bd0-b1bf-2c72698afe96","_uuid":"4cdc8ebf9bc167498cace36993800c819556eb04","trusted":true,"collapsed":true},"cell_type":"code","source":"# Importing necessary libraries\nimport numpy as np\nimport os\nimport glob\nimport cv2\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport pickle\nfrom keras.utils import to_categorical\nfrom keras.layers import Dense, Input, Conv2D, Flatten, MaxPool2D, Activation\nfrom keras.models import Model\nfrom keras.callbacks import ModelCheckpoint\nfrom keras import backend as K","execution_count":1,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"a42ae61e-565e-48ae-b618-370dc4bd3718","_uuid":"8f087bcd8bb6c49f440bd5bea4769ddd692d291e","trusted":true},"cell_type":"code","source":"#Declaring constants\nFIG_WIDTH=20 # Width of figure\nROW_HEIGHT=3 # Height of each row when showing a figure which consists of multiple rows\nRESIZE_DIM=28 # The images will be resized to 28x28 pixels","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"13edfd90e27cf0376dadb606eed4013bad77132c"},"cell_type":"markdown","source":"# Setup path variables\n"},{"metadata":{"collapsed":true,"_cell_guid":"e786b5c7-7f0b-42d4-a3e4-fd4b7d66fbd9","_uuid":"a1454525b854abf797ea8763431da25e7aa99f92","trusted":true},"cell_type":"code","source":"data_dir=os.path.join('..','input')\npaths_train_a=glob.glob(os.path.join(data_dir,'training-a','*.png'))\npaths_train_b=glob.glob(os.path.join(data_dir,'training-b','*.png'))\npaths_train_e=glob.glob(os.path.join(data_dir,'training-e','*.png'))\npaths_train_c=glob.glob(os.path.join(data_dir,'training-c','*.png'))\npaths_train_d=glob.glob(os.path.join(data_dir,'training-d','*.png'))\npaths_train_all=paths_train_a+paths_train_b+paths_train_c+paths_train_d+paths_train_e\n\npaths_test_a=glob.glob(os.path.join(data_dir,'testing-a','*.png'))\npaths_test_b=glob.glob(os.path.join(data_dir,'testing-b','*.png'))\npaths_test_e=glob.glob(os.path.join(data_dir,'testing-e','*.png'))\npaths_test_c=glob.glob(os.path.join(data_dir,'testing-c','*.png'))\npaths_test_d=glob.glob(os.path.join(data_dir,'testing-d','*.png'))\npaths_test_f=glob.glob(os.path.join(data_dir,'testing-f','*.png'))+glob.glob(os.path.join(data_dir,'testing-f','*.JPG'))\npaths_test_auga=glob.glob(os.path.join(data_dir,'testing-auga','*.png'))\npaths_test_augc=glob.glob(os.path.join(data_dir,'testing-augc','*.png'))\npaths_test_all=paths_test_a+paths_test_b+paths_test_c+paths_test_d+paths_test_e+paths_test_f+paths_test_auga+paths_test_augc\n\npath_label_train_a=os.path.join(data_dir,'training-a.csv')\npath_label_train_b=os.path.join(data_dir,'training-b.csv')\npath_label_train_e=os.path.join(data_dir,'training-e.csv')\npath_label_train_c=os.path.join(data_dir,'training-c.csv')\npath_label_train_d=os.path.join(data_dir,'training-d.csv')","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"45ef7b96-b4cb-46d5-a092-6eb10775cb3e","_uuid":"5aab8d2c6139e67da8cac46a41b02dd3b0c16c1a"},"cell_type":"markdown","source":"# Utility Functions"},{"metadata":{"collapsed":true,"_cell_guid":"87d7081d-aa4a-48b9-b1a4-575ceceb2eb3","_uuid":"aa19885280eef5dfed1f8378d668ea7f025a7925","trusted":true},"cell_type":"code","source":"def get_key(path):\n    # seperates the key of an image from the filepath\n    key=path.split(sep=os.sep)[-1]\n    return key\n\ndef get_data(paths_img,path_label=None,resize_dim=None):\n    '''reads images from the filepaths, resizes them (if given), and returns them in a numpy array\n    Args:\n        paths_img: image filepaths\n        path_label: pass image label filepaths while processing training data, defaults to None while processing testing data\n        resize_dim: if given, the image is resized to resize_dim x resize_dim (optional)\n    Returns:\n        X: group of images\n        y: categorical true labels\n    '''\n    X=[] # initialize empty list for resized images\n    for i,path in enumerate(paths_img):\n        img=cv2.imread(path,cv2.IMREAD_COLOR) # images loaded in color (BGR)\n        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n        if resize_dim is not None:\n            img=cv2.resize(img,(resize_dim,resize_dim),interpolation=cv2.INTER_AREA) # resize image to 28x28\n#         X.append(np.expand_dims(img,axis=2)) # expand image to 28x28x1 and append to the list.\n        X.append(img) # expand image to 28x28x1 and append to the list\n        # display progress\n        if i==len(paths_img)-1:\n            end='\\n'\n        else: end='\\r'\n        print('processed {}/{}'.format(i+1,len(paths_img)),end=end)\n        \n    X=np.array(X) # tranform list to numpy array\n    if  path_label is None:\n        return X\n    else:\n        df = pd.read_csv(path_label) # read labels\n        df=df.set_index('filename') \n        y_label=[df.loc[get_key(path)]['digit'] for path in  paths_img] # get the labels corresponding to the images\n        y=to_categorical(y_label,10) # transfrom integer value to categorical variable\n        return X, y\n\ndef imshow_group(X,y=None,y_pred=None,n_per_row=10):\n    '''helper function to visualize a group of images along with their categorical true labels (y) and prediction probabilities.\n    Args:\n        X: images\n        y: categorical true labels\n        y_pred: predicted class probabilities\n        n_per_row: number of images per row to be plotted\n    '''\n    n_sample=len(X)\n    img_dim=X.shape[1]\n    j=np.ceil(n_sample/n_per_row)\n    fig=plt.figure(figsize=(FIG_WIDTH,ROW_HEIGHT*j))\n    for i,img in enumerate(X):\n        plt.subplot(j,n_per_row,i+1)\n        plt.imshow(img)\n        if y is not None:\n                plt.title('true label: {}'.format(np.argmax(y[i])))\n        if y_pred is not None:\n            top_n=3 # top 3 predictions with highest probabilities\n            ind_sorted=np.argsort(y_pred[i])[::-1]\n            h=img_dim+4\n            for k in range(top_n):\n                string='pred: {} ({:.0f}%)\\n'.format(ind_sorted[k],y_pred[i,ind_sorted[k]]*100)\n                plt.text(img_dim/2, h, string, horizontalalignment='center',verticalalignment='center')\n                h+=4\n        plt.axis('off')\n    plt.show()\ndef create_submission(predictions,keys,path):\n    result = pd.DataFrame(\n        predictions,\n        columns=['label'],\n        index=keys\n        )\n    result.index.name='key'\n    result.to_csv(path, index=True)","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"541cbb22-5319-490a-b6a4-8999db770722","_uuid":"01fee24b540458889ebaa9d86b7646e5264e5b1e"},"cell_type":"markdown","source":"# Preprocess data"},{"metadata":{"trusted":true,"_uuid":"e4d65fdcac01f5d367ce863d79d22fbbf9b36b86","collapsed":true},"cell_type":"code","source":"X_train_a,y_train_a=get_data(paths_train_a,path_label_train_a,resize_dim=RESIZE_DIM)\nX_train_b,y_train_b=get_data(paths_train_b,path_label_train_b,resize_dim=RESIZE_DIM)\nX_train_c,y_train_c=get_data(paths_train_c,path_label_train_c,resize_dim=RESIZE_DIM)\nX_train_d,y_train_d=get_data(paths_train_d,path_label_train_d,resize_dim=RESIZE_DIM)\nX_train_e,y_train_e=get_data(paths_train_e,path_label_train_e,resize_dim=RESIZE_DIM)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d111deae34f1e29aca3417f5eaa47d0f06067ba","collapsed":true},"cell_type":"code","source":"X_train_all=np.concatenate((X_train_a,X_train_b,X_train_c,X_train_d,X_train_e),axis=0)\ny_train_all=np.concatenate((y_train_a,y_train_b,y_train_c,y_train_d,y_train_e),axis=0)\nX_train_all.shape, y_train_all.shape","execution_count":6,"outputs":[]},{"metadata":{"_cell_guid":"620a40d9-36f8-49fa-b96c-b823999daad0","_uuid":"1d06bb5aaa056f719a918be3206c3f6b2e738e0b","scrolled":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"X_test_a=get_data(paths_test_a,resize_dim=RESIZE_DIM)\nX_test_b=get_data(paths_test_b,resize_dim=RESIZE_DIM)\nX_test_c=get_data(paths_test_c,resize_dim=RESIZE_DIM)\nX_test_d=get_data(paths_test_d,resize_dim=RESIZE_DIM)\nX_test_e=get_data(paths_test_e,resize_dim=RESIZE_DIM)\nX_test_f=get_data(paths_test_f,resize_dim=RESIZE_DIM)\nX_test_auga=get_data(paths_test_auga,resize_dim=RESIZE_DIM)\nX_test_augc=get_data(paths_test_augc,resize_dim=RESIZE_DIM)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"59775980271bb7f31fea8f546f7e8189724f6d49"},"cell_type":"code","source":"X_test_all=np.concatenate((X_test_a,X_test_b,X_test_c,X_test_d,X_test_e,X_test_f,X_test_auga,X_test_augc))","execution_count":8,"outputs":[]},{"metadata":{"_cell_guid":"d32f9092-0d61-4a31-940a-c47bd4a7ab70","_uuid":"100fe511f70f708fe5a9a4a20a423d5cc5fc5d31"},"cell_type":"markdown","source":"Next, we are going to randomly choose 80% of the training data and use it to train our neural network. The remaining 20% images are going to be our validation data."},{"metadata":{"_cell_guid":"45550d4b-7b11-4277-b968-3cbc74161537","_uuid":"ec1470e959cf087a27d9ca3d349f2f5dd8687528","trusted":true,"collapsed":true},"cell_type":"code","source":"indices=list(range(len(X_train_all)))\nnp.random.seed(42)\nnp.random.shuffle(indices)\n\nind=int(len(indices)*0.80)\n# train data\nX_train=X_train_all[indices[:ind]] \ny_train=y_train_all[indices[:ind]]\n# validation data\nX_val=X_train_all[indices[-(len(indices)-ind):]] \ny_val=y_train_all[indices[-(len(indices)-ind):]]","execution_count":9,"outputs":[]},{"metadata":{"_cell_guid":"32382aae-4756-457e-af68-5fd94603ddfb","_uuid":"ba5d4e25fb97b4afcb84f85c8788da6244afadaf"},"cell_type":"markdown","source":"# Model"},{"metadata":{"_uuid":"f10aa302ee3a6839989ada764ba5345a43a12776"},"cell_type":"markdown","source":"We shall build a small model based on the classic [LeNet](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf) architecture. We shall use only three convolutional layers. Each convolution layer has rectified linear unit (ReLU) activation which is followed by a max pooling layer. The convolution layers are followed by two dense layers. "},{"metadata":{"_cell_guid":"1fae5204-6082-410a-a111-375880df9e70","_uuid":"8135539c275b5af142096a33acfba7cc30aa2f8f","trusted":true,"collapsed":true},"cell_type":"code","source":"def get_model():\n    input_layer=Input(shape=(RESIZE_DIM,RESIZE_DIM,3))\n    x=Conv2D(filters=8,kernel_size=(5,5),padding='valid', activation='relu')(input_layer)\n    x=MaxPool2D(pool_size=(2,2),strides=2,padding='valid')(x)\n    \n    x=Conv2D(filters=16,kernel_size=(3,3),padding='valid', activation='relu')(x)\n    x=MaxPool2D(pool_size=(2,2),strides=2,padding='valid')(x)\n    \n    x=Conv2D(filters=32,kernel_size=(3,3),padding='valid', activation='relu')(x)\n    x=MaxPool2D(pool_size=(2,2),strides=2,padding='valid')(x)\n    x=Flatten()(x)\n    x=Dense(units=64)(x)\n    x=Dense(units=10)(x)    \n    output_layer=Activation('softmax')(x)\n    model=Model(inputs=input_layer,outputs=output_layer)\n    model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')\n    return model\nmodel=get_model()\nmodel.summary()","execution_count":10,"outputs":[]},{"metadata":{"_cell_guid":"ee9607d4-40d3-449d-948d-ca743a6f9d77","_uuid":"0b0adac9af387df7adc0cf26954802305849396e"},"cell_type":"markdown","source":"# Train and Validate"},{"metadata":{"_cell_guid":"7b15bdc9-1794-4eda-9d48-f544be3e382c","_uuid":"f220f61fae1fae8c1cfb2f843300b489937b0090","trusted":true,"collapsed":true},"cell_type":"code","source":"path_model='model_simple_keras_starter.h5' # save model at this location after each epoch\nK.tensorflow_backend.clear_session() # destroys the current graph and builds a new one\nmodel=get_model() # create the model\nK.set_value(model.optimizer.lr, 1e-4) # set the learning rate\n# fit the model\nh=model.fit(x=X_train,     \n            y=y_train, \n            batch_size=64, \n            epochs=40, \n            verbose=1, \n            validation_data=(X_val,y_val),\n            shuffle=True,\n            callbacks=[\n                ModelCheckpoint(filepath=path_model),\n            ]\n            )","execution_count":21,"outputs":[]},{"metadata":{"_uuid":"79cdb9efb315d754ff01622339790165627e26df"},"cell_type":"markdown","source":"# Make Predictions on Test Set"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3a9be8aca2141ea5a8b597cb79bba180ca725555"},"cell_type":"code","source":"predictions_prob=model.predict(X_test_all) # get predictions for all the testing data","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1cdfc83f7f114b3b219794ba3147fed979849360"},"cell_type":"markdown","source":"Let's observe a few pedictions."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f161da71ffe8853fbbe24ba4b83ad08183a87590"},"cell_type":"code","source":"n_sample=200\nnp.random.seed(42)\nind=np.random.randint(0,len(X_test_all), size=n_sample)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"39f97b94480fed8d75c50ba1eea00a5f8f6b8fa9","collapsed":true},"cell_type":"code","source":"imshow_group(X=X_test_all[ind],y=None,y_pred=predictions_prob[ind])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1e585b35a251a3a927b85bb7800f7eebe2aa149a"},"cell_type":"markdown","source":"# Create Submission"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"127814729b7274f650f514ffa528fd6ffeb3ebcc"},"cell_type":"code","source":"labels=[np.argmax(pred) for pred in predictions_prob]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0755ede1693a11167d26c4c8035252226b3b797d"},"cell_type":"code","source":"keys=[get_key(path) for path in paths_test_all ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e505c28b44ccc5942280a9777ae2c0c19a1b487c","collapsed":true},"cell_type":"code","source":"create_submission(predictions=labels,keys=keys,path='submission_simple_keras_starter.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}