{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"e8d767d8-597d-30f3-a3f1-f9679debab79"},"source":"**Data Visualization**\n\n**Applying Machine Learning Techniques**\n\nwork in progress. suggestions and comments highly appreciated"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5e4cf7cb-cb50-a835-26a9-94f523a4cb4d"},"outputs":[],"source":"# numpy, pandas\nimport numpy as np \nimport pandas as pd \nimport datetime\nimport numpy as np\n\n# plots\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport matplotlib\nmatplotlib.style.use('ggplot')\n\n\n\n\n# machine learning\nfrom sklearn import preprocessing\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\nfrom subprocess import check_output\n\n# Supress unnecessary warnings so that presentation looks clean\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#Print all rows and columns. Dont hide any\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7943ee7c-ed0f-f189-550e-25ddb9356f2b"},"outputs":[],"source":"print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\ndf_ac= pd.read_csv('../input/accident.csv')\nimport sklearn.utils\ndf_ac = sklearn.utils.shuffle(df_ac)\n#print(df_ac.head(5))\n#print(df_ac.info())"},{"cell_type":"markdown","metadata":{"_cell_guid":"e87542b1-d0d1-ae9a-f1e3-899cf1f9a6d6"},"source":"## **Statewise accident** ##"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1f11832c-88dd-1561-7bd2-80a2b1775fbd"},"outputs":[],"source":"states = {1: 'AL', 2: 'AK', 4: 'AZ', 5: 'AR', \n          6: 'CA', 8: 'CO', 9: 'CT', 10: 'DE', \n          11: 'DC', 12: 'FL', 13: 'GA', 15: 'HI', \n          16: 'ID', 17: 'IL', 18: 'IN', 19: 'IA', 20: 'KS', \n          21: 'KY', 22: 'LA', 23: 'ME', 24: 'MD', \n          25: 'MA', 26: 'MI', 27: 'MN', \n          28:'MS', 29: 'MO', 30: 'MT', 31: 'NE', \n          32: 'NV', 33: 'NH', 34: 'NJ', 35: 'NM', \n          36: 'NY', 37: 'NC', 38: 'ND', 39: 'OH', \n          40: 'OK', 41: 'OR', 42: 'PN', 43: 'PR', \n          44: 'RI', 45: 'SC', 46: 'SD', 47: 'TN', \n          48: 'TX', 49: 'UT', 50: 'VT', 51: 'VA', 52: 'VI', \n          53: 'WA', 54: 'WV', 55: 'WI', 56: 'WY'}\n\n\nfig, axes = plt.subplots(nrows=4, ncols=1,figsize=(8, 8))\nfig.subplots_adjust(hspace=0.8)\n\ndf_ac['state']=df_ac['STATE'].apply(lambda x: states[x])\nTotal_ac=df_ac['state'].value_counts()\ndf_ac['state'].value_counts().plot(ax=axes[0],kind='bar',title='state-wise accidents')\n\n\ndf_drinking=pd.concat([df_ac['state'],df_ac['DRUNK_DR']],axis=1)\n#print(df_drinking.head())\n#print('\\n grouped \\n')\ndrk_state=df_drinking.groupby('state')\n#print(drk_state.sum().head())\ndrk_state.sum().sort_index(by='DRUNK_DR',ascending=False).plot(ax=axes[1],kind='bar',title='state-wise drunk drivers')\n\n\nTotal_ac.sort_index(ascending=True)\ndrk_break=pd.concat([Total_ac.sort_index(ascending=True),drk_state.sum()],axis=1)\ndrk_break.columns=['People_involved','Drunk_drivers']\n#print(drk_break.head())\n#print('\\n\\n')\ndrk_break['NoN Drinking individuals']= drk_break['People_involved']-drk_break['Drunk_drivers']\n#print(drk_break[['NoN Drinking individuals','Drunk_drivers']].head())\ndrk_break[['NoN Drinking individuals','Drunk_drivers']].sort_index(by='NoN Drinking individuals',ascending=False).plot.bar(ax=axes[2],stacked='True')\n\n\n\ndrk_break['Drunk_Dr_per_population']= drk_break['Drunk_drivers']/drk_break['People_involved']\ndrk_break.head()\ndrk_break[['Drunk_Dr_per_population']].sort_index(by='Drunk_Dr_per_population',ascending=False).plot(ax=axes[3],kind='bar')"},{"cell_type":"markdown","metadata":{"_cell_guid":"1401adc0-86de-d92a-61a4-875e129e2300"},"source":"This is super interesting drunk drivers per total individuals shows in Maine you have highest chance of having accidents due to drinking. and Texas who was leading the most amount of accidents are one of the least dangerous states in terms of drunk driving accidents."},{"cell_type":"markdown","metadata":{"_cell_guid":"6698bf7e-ba76-3d8c-9ff5-a4be6745c6e9"},"source":"----------\nLets see how month-wise accident data changes \n----------"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f20fa4d1-bdd3-dec8-35ab-5eea1ceb77c9"},"outputs":[],"source":"month = {1: '1jan', 2: '2feb', 3: '3mar', 4: '4april', \n          5: '5may', 6: '6june', 7: '7july', 8: '8aug', \n          9: '90sep', 10: '91oct',11: '92nov',12: '93dec'}\n\nfig, axes = plt.subplots(nrows=2, ncols=2,figsize=(9, 6))\nfig.subplots_adjust(hspace=.6)\n\n##### month breakdown\ndf_ac['month']=df_ac['MONTH'].apply(lambda x: month[x])\ndf_ac['month'].value_counts().sort_index(level='month').plot(ax=axes[0,0],kind='bar',title='Month-wise accident')\n\n### month day wise breakdown\ndf_ac['DAY'].value_counts().sort_index().plot(ax=axes[0,1],title='Day-wise accident')\n\n####### week day break down\nday = {1: '1_SAT', 2: '2_SUN', 3: '3_MON', 4: '4_TUE', \n          5: '5_WED', 6: '6_THU', 7: '7_FRI'}\ndf_ac['day_week']=df_ac['DAY_WEEK'].apply(lambda x: day[x])\ndf_ac['day_week'].value_counts().sort_index().plot(ax=axes[1,0],kind='bar',title='Week_Day-wise accident')\n\n#############Hourly Breakdown\ndf_ac=df_ac[df_ac.HOUR != 99]\n\ndf_ac['HOUR'].value_counts().sort_index().plot(ax=axes[1,1],kind='bar',title='Hour-wise accident')"},{"cell_type":"markdown","metadata":{"_cell_guid":"95a8e218-bb86-91d7-498b-403ec38c1cd5"},"source":"So Friday & Saturday are the most dangerous day of the week (as expected)\n5-9 PM is the most accident prone hours of the day. \n99: is unreported event."},{"cell_type":"markdown","metadata":{"_cell_guid":"31097a40-a02c-9385-bb33-5870c0efa9e5"},"source":"## **Let's see harmful environment status** ##"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d7fc5d41-5a54-107e-1f7e-ef5a93bcc61b"},"outputs":[],"source":"df_ac['HARM_EV'].value_counts().head()\nharm_ev= {12: 'SameRoadVehicle', 8: 'Pedestrian', 1: 'OverTurn', 42: 'Trees', \n          33: 'Curb', 34: 'Ditch', 35: 'Embankment'}\ndf_ac['harm_ev']=df_ac['HARM_EV'].apply(lambda x: harm_ev[x] if (x==12 or x==8 or x==1 or x==42 or x==33 or x==34 or x== 35)  else 'Other')\ndf_ac['harm_ev'].value_counts().plot(kind='pie',title='How harmful environment played role')"},{"cell_type":"markdown","metadata":{"_cell_guid":"6d55e667-fc1d-0247-43dc-f1cb0a41b1fa"},"source":"12 = Motor Vehicle in Transport on same roadway\n8= Pedestrian\n1= over turn\n42= Trees\n33=Curb\n34=Ditch\n35=Embankment"},{"cell_type":"markdown","metadata":{"_cell_guid":"5fea16b6-af13-d130-3f0b-06c2fecb6d52"},"source":"## **Decision Tree - Is the driver Drunk or Sober** ##"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0d261597-9c57-5f13-0568-37067cffaf1b"},"outputs":[],"source":"df_ml= df_ac[['state','MONTH','DAY_WEEK','DAY','HOUR','harm_ev','DRUNK_DR']]\ndf_ml['state']=df_ml['state'].fillna('TX')\ndf_ml['MONTH']=df_ml['MONTH'].fillna(0)\ndf_ml['DAY_WEEK']=df_ml['DAY_WEEK'].fillna(6)\ndf_ml['DAY']=df_ml['DAY'].fillna(3)\ndf_ml['HOUR']=df_ml['HOUR'].fillna(18)\ndf_ml['harm_ev']=df_ml['harm_ev'].fillna('Embankment')\ndf_ml['DRUNK_DR']=df_ml['DRUNK_DR'].fillna(0)\ndf_ml['harm_ev'].unique()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"48b7723f-1df3-7fdf-4a0b-56809aa8483d"},"outputs":[],"source":"df_ml['harm_ev'] = df_ml['harm_ev'].replace(['Embankment', 'SameRoadVehicle'], ['EM', 'SRV'])\nx=pd.get_dummies(df_ml['harm_ev'], prefix = 'harm_ev')\nx = pd.concat([x, pd.get_dummies(df_ml['state'], prefix ='state')], axis=1)\n#x = pd.concat([x, pd.get_dummies(df_ml['DRUNK_DR'], prefix ='DD')], axis=1)\nx = pd.concat([x, pd.get_dummies(df_ml['MONTH'], prefix ='MONTH')], axis=1)\nx = pd.concat([x, pd.get_dummies(df_ml['DAY_WEEK'], prefix ='Dw')], axis=1)\nx = pd.concat([x, pd.get_dummies(df_ml['DAY'], prefix ='DAY')], axis=1)\nx = pd.concat([x, pd.get_dummies(df_ml['HOUR'], prefix ='HOUR')], axis=1)\nx.head(3)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fd82d7c4-d6fc-6264-f160-55d0badae1dc"},"outputs":[],"source":"df_ml['DRUNK_DR']=df_ml['DRUNK_DR'].apply(lambda x: 0 if (x==0)  else 1)\ndf_ml['DRUNK_DR'].value_counts()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f8572731-ef2f-545f-f393-938d2932f0e4"},"outputs":[],"source":"from sklearn.tree import DecisionTreeClassifier, export_graphviz\nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nY = le.fit_transform(df_ml['DRUNK_DR'])\nle.inverse_transform([0, 1])\ndt = DecisionTreeClassifier(max_depth = 4)\ndt.fit(x.values, Y)\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d93b62bc-6aa1-845b-f55d-8ac66c0da5f3"},"outputs":[],"source":"from sklearn import cross_validation\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(scores)\nprint(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a3798737-b13c-feed-3904-f11f6e064451"},"outputs":[],"source":"print(pd.value_counts(Y))\nprint(\"Statistical Accuracy\")\nprint(23304/len(Y))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"84c6cbc2-d5f7-5b54-1881-98bc8bbb920b"},"outputs":[],"source":" s = []\n\nfor i in range(13):\n   s.append(0)\n\n\ndt = DecisionTreeClassifier(max_depth = 1,criterion='entropy')\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\ni=0\ns[i]=scores.mean()\ni=i+1\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n\ndt = DecisionTreeClassifier(max_depth = 2,criterion='entropy')\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()\ni=i+1\n\ndt = DecisionTreeClassifier(max_depth = 3,criterion='entropy')\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()\ni=i+1\n\ndt = DecisionTreeClassifier(max_depth = 4,criterion='entropy')\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()\ni=i+1\n\ndt = DecisionTreeClassifier(max_depth = 5,criterion='entropy')\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()\ni=i+1\n\ndt = DecisionTreeClassifier(max_depth = 6,criterion='entropy')\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()\ni=i+1\n\ndt = DecisionTreeClassifier(max_depth = 7,criterion='entropy')\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()\ni=i+1\n\ndt = DecisionTreeClassifier(max_depth = 8,criterion='entropy')\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()\ni=i+1\n\ndt = DecisionTreeClassifier(max_depth = 9,criterion='entropy')\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()\ni=i+1\n\ndt = DecisionTreeClassifier(max_depth = 10,criterion='entropy')\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()\ni=i+1\n\ndt = DecisionTreeClassifier(max_depth = 12,criterion='entropy')\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()\ni=i+1\n\ndt = DecisionTreeClassifier(max_depth = 14,criterion='entropy')\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()\ni=i+1\n\ndt = DecisionTreeClassifier(max_depth = 16,criterion='entropy')\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"54312529-2103-d78f-cadd-db138f1f65fc"},"outputs":[],"source":"n = [1,2,3,4,5,6,7,8,9,10,12,14,16]\n\nplt.plot(n,s, 'r',lw=3)\nplt.title('Accuracy vs Depth of Decision Tree with entropy as criterion')\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8cd14262-e314-fe66-14cf-64ec152e6211"},"outputs":[],"source":"s = []\n\nfor i in range(10):\n   s.append(0)\n\n\ndt = DecisionTreeClassifier(max_depth = 1)\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\ni=0\ns[i]=scores.mean()\ni=i+1\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n\ndt = DecisionTreeClassifier(max_depth = 2)\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()\ni=i+1\n\ndt = DecisionTreeClassifier(max_depth = 3)\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()\ni=i+1\n\ndt = DecisionTreeClassifier(max_depth = 4)\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()\ni=i+1\n\ndt = DecisionTreeClassifier(max_depth = 5)\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()\ni=i+1\n\ndt = DecisionTreeClassifier(max_depth = 6)\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()\ni=i+1\n\ndt = DecisionTreeClassifier(max_depth = 7)\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()\ni=i+1\n\ndt = DecisionTreeClassifier(max_depth = 8)\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()\ni=i+1\n\ndt = DecisionTreeClassifier(max_depth = 9)\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()\ni=i+1\n\ndt = DecisionTreeClassifier(max_depth = 10)\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"049fd05f-97d1-36d7-d184-e69ee75b02f1"},"outputs":[],"source":"plt.plot( s, 'r',lw=3)\nplt.title('Accuracy vs Depth of Decision Tree with information gain as leafing criterion')\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"62d85f99-f2a0-72d9-51d8-161ef559c9b1"},"outputs":[],"source":"df_ac['MAN_COLL'].value_counts()\n\nman_coll = {0:'NoCol',6:'angle',2:'headOn',1:'Rear',7:'sideswipe'}\n\ndf_ac['man_coll']=df_ac['MAN_COLL'].apply(lambda x: man_coll[x] if (x==0 or x==6 or x==2 or x==1 or x==7)  else 'NoCol')\ndf_ac['man_coll'].value_counts().plot(kind='pie',title='Manner of collisions')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b0963c6e-314f-4f77-cf9d-8144e6a265f7"},"outputs":[],"source":"x = pd.concat([x, pd.get_dummies(df_ac['man_coll'], prefix ='man_coll')], axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c8ad4bd4-2ee6-9265-526b-c3f084d9577b"},"outputs":[],"source":"s = []\nfor i in range(10):\n   s.append(0)\n\n\ndt = DecisionTreeClassifier(max_depth = 1)\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\ni=0\ns[i]=scores.mean()\ni=i+1\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n\ndt = DecisionTreeClassifier(max_depth = 2)\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()\ni=i+1\n\ndt = DecisionTreeClassifier(max_depth = 3)\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()\ni=i+1\n\ndt = DecisionTreeClassifier(max_depth = 4)\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()\ni=i+1\n\ndt = DecisionTreeClassifier(max_depth = 5)\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()\ni=i+1\n\ndt = DecisionTreeClassifier(max_depth = 6)\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()\ni=i+1\n\ndt = DecisionTreeClassifier(max_depth = 7)\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()\ni=i+1\n\ndt = DecisionTreeClassifier(max_depth = 8)\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()\ni=i+1\n\ndt = DecisionTreeClassifier(max_depth = 9)\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()\ni=i+1\n\ndt = DecisionTreeClassifier(max_depth = 10)\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1ee2121a-83c9-9fee-f583-6a2ce98c75a5"},"outputs":[],"source":"df_ac['WEATHER'].value_counts()\nweather = {1:'clear',10:'couldy',2:'rain',5:'fog',4:'snow',99:'unknown',3:'sleet',98:'unreported',8:'other',12:'drizzle',11:'blowingSnow',6:'crosswinds',7:'blowingSand'}\n\ndf_ac['weather']=df_ac['WEATHER'].apply(lambda x: weather[x] )\ndf_ac['weather'].value_counts().plot.bar(figsize=(8,4))\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0285e626-0fef-e69c-6d5f-654d6ece7bf1"},"outputs":[],"source":"x = pd.concat([x, pd.get_dummies(df_ac['weather'], prefix ='weather')], axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cd7cea6a-1488-3311-b3e6-0937bd222549"},"outputs":[],"source":"s = []\nfor i in range(10):\n   s.append(0)\n\n\ndt = DecisionTreeClassifier(max_depth = 1)\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\ni=0\ns[i]=scores.mean()\ni=i+1\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n\ndt = DecisionTreeClassifier(max_depth = 2)\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()\ni=i+1\n\ndt = DecisionTreeClassifier(max_depth = 3)\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()\ni=i+1\n\ndt = DecisionTreeClassifier(max_depth = 4)\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()\ni=i+1\n\ndt = DecisionTreeClassifier(max_depth = 5)\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()\ni=i+1\n\ndt = DecisionTreeClassifier(max_depth = 6)\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()\ni=i+1\n\ndt = DecisionTreeClassifier(max_depth = 7)\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()\ni=i+1\n\ndt = DecisionTreeClassifier(max_depth = 8)\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()\ni=i+1\n\ndt = DecisionTreeClassifier(max_depth = 9)\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()\ni=i+1\n\ndt = DecisionTreeClassifier(max_depth = 10)\nscores = cross_validation.cross_val_score(dt, x, Y, cv = 10)\nprint(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\ns[i]=scores.mean()\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bce9e2a0-47df-a760-2ec0-518e9cbdadc9"},"outputs":[],"source":"n=3000\n\nxx=x.iloc[0:n]\nlabel=df_ml['DRUNK_DR'].iloc[0:n]\n\nmsk = np.random.rand(len(xx)) < 0.8\ntrain_f=xx[msk]\ntest_f=xx[~msk]\ntrain_l=label[msk]\ntest_l=label[~msk]\n\nfrom sklearn.metrics import accuracy_score, log_loss\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC, LinearSVC, NuSVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n\nclassifiers = [\n    KNeighborsClassifier(3),\n    SVC(kernel=\"rbf\", C=0.025, probability=True),\n    #NuSVC(probability=True),\n    #DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    AdaBoostClassifier(),\n    GradientBoostingClassifier(),\n    GaussianNB(),\n    LinearDiscriminantAnalysis()]\n    #QuadraticDiscriminantAnalysis()\n\n# Logging for Visual Comparison\nlog_cols=[\"Classifier\", \"Accuracy\", \"Log Loss\"]\nlog = pd.DataFrame(columns=log_cols)\n\nfor clf in classifiers:\n    clf.fit(train_f, train_l)\n    name = clf.__class__.__name__\n    \n    print(\"=\"*30)\n    print(name)\n    \n    print('****Results****')\n    train_predictions = clf.predict(test_f)\n    acc = accuracy_score(test_l, train_predictions)\n    print(\"Accuracy: {:.4%}\".format(acc))\n    \n    train_predictions = clf.predict_proba(test_f)\n    ll = log_loss(test_l, train_predictions)\n    print(\"Log Loss: {}\".format(ll))\n    \n    log_entry = pd.DataFrame([[name, acc*100, ll]], columns=log_cols)\n    log = log.append(log_entry)\n    \nprint(\"=\"*30)\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c6cb7300-8642-c4c7-059c-b7a3b250c84d"},"outputs":[],"source":"import seaborn as sns\n#sns.set_color_codes(\"muted\")\nsns.barplot(x='Accuracy', y='Classifier', data=log)\n\nplt.xlabel('Accuracy %')\nplt.title('Classifier Accuracy')\nplt.show()\n\n#sns.set_color_codes(\"muted\")\nsns.barplot(x='Log Loss', y='Classifier', data=log)\n\nplt.xlabel('Log Loss')\nplt.title('Classifier Log Loss')\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"26bd6f50-7d40-d081-7249-0a896d7eafa1"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}