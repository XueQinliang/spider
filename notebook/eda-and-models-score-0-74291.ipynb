{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"d380e2ad-947b-d014-44cd-72cbaeeb2a0e"},"source":"This is a fun Halloween competition. We have some characteristics of monsters and the goal is to predict the type of monsters: ghouls, goblins or ghosts.\n\nAt first I do data exploration to get some insights. Then I try various models for prediction."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"af87edf5-f225-1037-4893-e15589fdaf4e"},"outputs":[],"source":"#Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set_style('whitegrid')\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.calibration import CalibratedClassifierCV\nimport xgboost as xgb\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import svm\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.naive_bayes import GaussianNB"},{"cell_type":"markdown","metadata":{"_cell_guid":"60d26383-6e00-0f96-c5e9-6c5089fd592d"},"source":"## Data exploration"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5dba8f0f-f47a-41ad-8af1-6aadbfd27fb4"},"outputs":[],"source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1f09d961-e78f-7f5e-43f8-5697ba33621b"},"outputs":[],"source":"train.info()"},{"cell_type":"markdown","metadata":{"_cell_guid":"d00a3977-5efc-4381-c137-f0ac349affee"},"source":"So there are 4 numerical variables and 1 categorical. And no missing values, which is nice!"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6b808a59-d41e-c422-95bc-a07b52433def"},"outputs":[],"source":"train.describe(include='all')"},{"cell_type":"markdown","metadata":{"_cell_guid":"69676445-d7a2-0175-dc8a-115494a8dcfc"},"source":"Numerical columns are either normalized or show a percentage, so no need to scale them."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"714c4080-d68e-193c-8ec3-5531b9d39936"},"outputs":[],"source":"train.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f7800826-4182-ffb4-bbf4-9cafe313f02d"},"outputs":[],"source":"plt.subplot(1,4,1)\ntrain.groupby('type').mean()['rotting_flesh'].plot(kind='bar',figsize=(7,4), color='r')\nplt.subplot(1,4,2)\ntrain.groupby('type').mean()['bone_length'].plot(kind='bar',figsize=(7,4), color='g')\nplt.subplot(1,4,3)\ntrain.groupby('type').mean()['hair_length'].plot(kind='bar',figsize=(7,4), color='y')\nplt.subplot(1,4,4)\ntrain.groupby('type').mean()['has_soul'].plot(kind='bar',figsize=(7,4), color='teal')"},{"cell_type":"markdown","metadata":{"_cell_guid":"aac1e55a-5548-21f7-0a67-8201c7d64744"},"source":"It seems that all numerical features may be useful."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aa607bdb-102a-d2ed-14ec-5bbef10a49d8"},"outputs":[],"source":"sns.factorplot(\"type\", col=\"color\", col_wrap=4, data=train, kind=\"count\", size=2.4, aspect=.8)"},{"cell_type":"markdown","metadata":{"_cell_guid":"ca9c9c9f-1ae8-54e5-6ad5-6dbd78da3f24"},"source":"Funny, but many colors are evenly distributes among the monsters. So they maybe nor very useful for analysis."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aac5ae96-e95b-ffdf-917d-edfa42e2fc3e"},"outputs":[],"source":"#The graphs look much better with higher figsize.\nfig, ax = plt.subplots(2, 2, figsize = (16, 12))\nsns.pointplot(x=\"color\", y=\"rotting_flesh\", hue=\"type\", data=train, ax = ax[0, 0])\nsns.pointplot(x=\"color\", y=\"bone_length\", hue=\"type\", data=train, ax = ax[0, 1])\nsns.pointplot(x=\"color\", y=\"hair_length\", hue=\"type\", data=train, ax = ax[1, 0])\nsns.pointplot(x=\"color\", y=\"has_soul\", hue=\"type\", data=train, ax = ax[1, 1])"},{"cell_type":"markdown","metadata":{"_cell_guid":"5675037d-69f6-ca76-3655-a1f93ec1eb69"},"source":"In most cases color won't \"help\" other variables to improve accuracy."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"76ec90a3-06d6-7bcf-1bc1-9b79f2e67ba4"},"outputs":[],"source":"sns.pairplot(train, hue='type')"},{"cell_type":"markdown","metadata":{"_cell_guid":"8b53746e-8c68-c03c-f304-776d7f013ec3"},"source":"This pairplot shows that data is distributed normally. And while most pairs are widely scattered (in relationship to the type), some of them show clusters: hair_length and has_soul, hair_length and bone_length. I decided to create new variables with multiplication of these columns and it worked great!"},{"cell_type":"markdown","metadata":{"_cell_guid":"4cb10a4f-63cb-3b98-86c4-86612b630f2e"},"source":"## Data preparation"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"43cc64c1-e0e0-6193-1ce8-a71e0d8ef3ef"},"outputs":[],"source":"train['hair_soul'] = train['hair_length'] * train['has_soul']\ntrain['hair_bone'] = train['hair_length'] * train['bone_length']\ntest['hair_soul'] = test['hair_length'] * test['has_soul']\ntest['hair_bone'] = test['hair_length'] * test['bone_length']\ntrain['hair_soul_bone'] = train['hair_length'] * train['has_soul'] * train['bone_length']\ntest['hair_soul_bone'] = test['hair_length'] * test['has_soul'] * test['bone_length']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"099fb0fe-a593-0857-b672-35da0eea7f56"},"outputs":[],"source":"#test_id will be used later, so save it\ntest_id = test['id']\ntrain.drop(['id'], axis=1, inplace=True)\ntest.drop(['id'], axis=1, inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5291ac0e-ef49-f524-c4d4-e59ab5995844"},"outputs":[],"source":"#Deal with 'color' column\ncol = 'color'\ndummies = pd.get_dummies(train[col], drop_first=False)\ndummies = dummies.add_prefix(\"{}#\".format(col))\ntrain.drop(col, axis=1, inplace=True)\ntrain = train.join(dummies)\ndummies = pd.get_dummies(test[col], drop_first=False)\ndummies = dummies.add_prefix(\"{}#\".format(col))\ntest.drop(col, axis=1, inplace=True)\ntest = test.join(dummies)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8dd366d9-1ced-1e73-d738-4e45af67f84e"},"outputs":[],"source":"X_train = train.drop('type', axis=1)\nle = LabelEncoder()\nY_train = le.fit_transform(train.type.values)\nX_test = test"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f9d2229e-f1b1-9988-20f7-6359d0a8558e"},"outputs":[],"source":"clf = RandomForestClassifier(n_estimators=200)\nclf = clf.fit(X_train, Y_train)\nindices = np.argsort(clf.feature_importances_)[::-1]\n\n# Print the feature ranking\nprint('Feature ranking:')\n\nfor f in range(X_train.shape[1]):\n    print('%d. feature %d %s (%f)' % (f + 1, indices[f], X_train.columns[indices[f]],\n                                      clf.feature_importances_[indices[f]]))"},{"cell_type":"markdown","metadata":{"_cell_guid":"1ef55766-2301-7a2d-adaa-f8d1c8b12367"},"source":"Graphs and model show that color has little impact, so I won't use it. In fact I tried using it, but the result got worse.\nAnd three features, which I created, seem to be important!"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fc9d1dcc-2a4a-15e2-722a-f174431b5a04"},"outputs":[],"source":"best_features=X_train.columns[indices[0:7]]\nX = X_train[best_features]\nXt = X_test[best_features]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"05e2fd94-1f90-41f1-59d0-c38fe16e869f"},"outputs":[],"source":"#Splitting data for validation\nXtrain, Xtest, ytrain, ytest = train_test_split(X, Y_train, test_size=0.20, random_state=36)"},{"cell_type":"markdown","metadata":{"_cell_guid":"79a5b6be-9527-9bce-ce03-c58add7e4178"},"source":"Tune the model. Normally you input all parameters and their potential values and run GridSearchCV. My PC isn't good enough so I divide parameters in two groups and repeatedly run two GridSearchCV until I'm satisfied with the result. This gives a balance between the quality and the speed."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9c06a887-13da-5c8b-b662-91dc48f61c1b"},"outputs":[],"source":"forest = RandomForestClassifier(max_depth = 100,                                \n                                min_samples_split =7,\n                                min_weight_fraction_leaf = 0.0,\n                                max_leaf_nodes = 60)\n\nparameter_grid = {'n_estimators' : [10, 20, 100, 150],\n                  'criterion' : ['gini', 'entropy'],\n                  'max_features' : ['auto', 'sqrt', 'log2', None]\n                 }\n\ngrid_search = GridSearchCV(forest, param_grid=parameter_grid, scoring='accuracy', cv=StratifiedKFold(5))\ngrid_search.fit(Xtrain, ytrain)\nprint('Best score: {}'.format(grid_search.best_score_))\nprint('Best parameters: {}'.format(grid_search.best_params_))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9e960059-9e6e-c8b3-317b-32cb80c1ae76"},"outputs":[],"source":"forest = RandomForestClassifier(n_estimators = 150,\n                                criterion = 'entropy',\n                                max_features = 'auto')\nparameter_grid = {\n                  'max_depth' : [None, 5, 20, 100],\n                  'min_samples_split' : [2, 5, 7],\n                  'min_weight_fraction_leaf' : [0.0, 0.1],\n                  'max_leaf_nodes' : [40, 60, 80],\n                 }\n\ngrid_search = GridSearchCV(forest, param_grid=parameter_grid, scoring='accuracy', cv=StratifiedKFold(5))\ngrid_search.fit(Xtrain, ytrain)\nprint('Best score: {}'.format(grid_search.best_score_))\nprint('Best parameters: {}'.format(grid_search.best_params_))"},{"cell_type":"markdown","metadata":{"_cell_guid":"c41995e6-2c18-9125-7dd4-c3af0c749201"},"source":"Calibrated classifier gives probabilities for each class, so to check the accuracy at first I chose the most probable class and convert it to values. Then I compare it to values of validation set."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"deb314e8-e014-1ded-0a99-279a5a1d4de3"},"outputs":[],"source":"#Optimal parameters\nclf = RandomForestClassifier(n_estimators=150, n_jobs=-1, criterion = 'entropy', max_features = 'auto',\n                             min_samples_split=7, min_weight_fraction_leaf=0.0,\n                             max_leaf_nodes=40, max_depth=20)\n#Calibration improves probability predictions\ncalibrated_clf = CalibratedClassifierCV(clf, method='sigmoid', cv=5)\ncalibrated_clf.fit(Xtrain, ytrain)\ny_val = calibrated_clf.predict_proba(Xtest)\n\nprint(\"Validation accuracy: \", sum(pd.DataFrame(y_val, columns=le.classes_).idxmax(axis=1).values\n                                   == le.inverse_transform(ytest))/len(ytest))"},{"cell_type":"markdown","metadata":{"_cell_guid":"2e07caf0-1d6e-4679-34b9-de13789e6aee"},"source":"I used the best parameters and validation accuracy is ~68-72%. Not bad. But let's try something else."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3863caca-078b-85d2-c4c7-8002ef34e2c8"},"outputs":[],"source":"svc = svm.SVC(kernel='linear')\nsvc.fit(Xtrain, ytrain)\ny_val_s = svc.predict(Xtest)\nprint(\"Validation accuracy: \", sum(le.inverse_transform(y_val_s)\n                                   == le.inverse_transform(ytest))/len(ytest))"},{"cell_type":"markdown","metadata":{"_cell_guid":"0d1f3c90-0f9f-9d13-657e-96ed2f72c27b"},"source":"Much better! Usually RandomForest requires a lot of data for good performance. It seems that in this case there was too little data for it."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"473e57bc-3055-5919-3cff-b156bdbcd72a"},"outputs":[],"source":"#The last model is logistic regression\nlogreg = LogisticRegression()\n\nparameter_grid = {'solver' : ['newton-cg', 'lbfgs'],\n                  'multi_class' : ['ovr', 'multinomial'],\n                  'C' : [0.005, 0.01, 1, 10, 100, 1000],\n                  'tol': [0.0001, 0.001, 0.005]\n                 }\n\ngrid_search = GridSearchCV(logreg, param_grid=parameter_grid, cv=StratifiedKFold(5))\ngrid_search.fit(Xtrain, ytrain)\nprint('Best score: {}'.format(grid_search.best_score_))\nprint('Best parameters: {}'.format(grid_search.best_params_))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"af1d8915-1556-4bf4-fed2-d9f489758c9f"},"outputs":[],"source":"log_reg = LogisticRegression(C = 1, tol = 0.0001, solver='newton-cg', multi_class='multinomial')\nlog_reg.fit(Xtrain, ytrain)\ny_val_l = log_reg.predict_proba(Xtest)\nprint(\"Validation accuracy: \", sum(pd.DataFrame(y_val_l, columns=le.classes_).idxmax(axis=1).values\n                                   == le.inverse_transform(ytest))/len(ytest))"},{"cell_type":"markdown","metadata":{"_cell_guid":"72769754-988f-4e96-0043-516fda73cad0"},"source":"It seems that regression is better. The reason? As far as I understand, the algorithms are similar, but with different loss function. And most importantly: SVC is a hard classifier and LR gives probabilities.\n\nAnd then I received an advise to try ensemble or voting. Let's see.\nVoting can be done manually or with sklearn classifier. For manual voting I need to make predictions for each classifier and to take the most common one. Advantage is that I may use any classifier I want, disadvantage is that I need to do it manually. Also, if some classifiers give predictions as classed and others as probability distribution, it complicates things.\nOr I can use sklearn.ensemble.VotingClassifier. Advantage is that it is easier to use. Disadvantage is that it may use only sklearn algorithms (or more precisely - algorithms with method \"get_param\") and only those which can give probability predictions (so no SVC and XGBooost). Well, SVC can be used if correct parameters are set.\nI tried both ways and got the same accuracy as a result."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"951a0c29-8307-7306-58c4-9c6aa880ec6e"},"outputs":[],"source":"clf = RandomForestClassifier(n_estimators=20, n_jobs=-1, criterion = 'gini', max_features = 'sqrt',\n                             min_samples_split=2, min_weight_fraction_leaf=0.0,\n                             max_leaf_nodes=40, max_depth=100)\n\ncalibrated_clf = CalibratedClassifierCV(clf, method='sigmoid', cv=5)\n\nlog_reg = LogisticRegression(C = 1, tol = 0.0001, solver='newton-cg', multi_class='multinomial')\n\ngnb = GaussianNB()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d7b23e67-5922-8f42-72bf-23605ebab88a"},"outputs":[],"source":"calibrated_clf1 = CalibratedClassifierCV(RandomForestClassifier())\n\nlog_reg1 = LogisticRegression()\n\ngnb1 = GaussianNB()"},{"cell_type":"markdown","metadata":{"_cell_guid":"9218f2e0-80cd-906b-dc5a-ee992070fe72"},"source":"As far as I can understand, while using hard voting, it is better to used unfitted estimators. Hard voting uses predicted class labels for majority rule voting. Soft voting predicts the class label based on the argmax of the sums of the predicted probalities, which is recommended for an ensemble of well-calibrated classifiers.\nAnd with soft voting we can use weights for models."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1045b9cf-6bb1-a1c5-e15a-df1153acc4e6"},"outputs":[],"source":"Vclf1 = VotingClassifier(estimators=[('LR', log_reg1), ('CRF', calibrated_clf1),\n                                     ('GNB', gnb1)], voting='hard')\nVclf = VotingClassifier(estimators=[('LR', log_reg), ('CRF', calibrated_clf),\n                                     ('GNB', gnb)], voting='soft', weights=[1,1,1])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7234b49d-893c-1e75-03a7-4b89d7992ebe"},"outputs":[],"source":"hard_predict = le.inverse_transform(Vclf1.fit(X, Y_train).predict(Xt))\nsoft_predict = le.inverse_transform(Vclf.fit(X, Y_train).predict(Xt))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d6011228-3b66-7c12-ca57-0e5bc67ffbf8"},"outputs":[],"source":"#Let's see the differences:\nfor i in range(len(hard_predict)):\n    if hard_predict[i] != soft_predict[i]:\n        print(i, hard_predict[i], soft_predict[i])"},{"cell_type":"markdown","metadata":{"_cell_guid":"eb4f7cf9-43c6-cbe9-4ef3-331f9dc02777"},"source":"There are differences, but both predictions give the same result on leaderboard. I think that some ensemble of voting classifiers could improve score. For example use different classifiers for several VotingClassifiers and them make a majority voting on these VotingClassifiers."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6c549039-a53e-b097-fbfb-f3a6bd6c83f8"},"outputs":[],"source":"submission = pd.DataFrame({'id':test_id, 'type':hard_predict})"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7e74b0d0-1fd4-0cdb-9cc8-593904fea2c4"},"outputs":[],"source":"submission.to_csv('GGG_submission.csv', index=False)"},{"cell_type":"markdown","metadata":{"_cell_guid":"6cb777b7-7fac-50af-2e58-78337498f985"},"source":"Previous solution gave me score of 0.73724. Current one - 0.74291."}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}