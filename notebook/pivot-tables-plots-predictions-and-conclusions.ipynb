{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"c48f2cb6-447f-07d7-0e9b-e90d13bffcdb"},"source":"**Plotting pivot tables and exploring data**\n--------------------------------------------"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0d91d9da-aa4b-7306-d042-279c5f9bbd07"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nfrom matplotlib import style\nimport seaborn as sns\nsns.set(style='ticks', palette='RdBu')\n#sns.set(style='ticks', palette='Set2')\nimport pandas as pd\nimport numpy as np\nimport time\nimport datetime \n%matplotlib inline\nimport matplotlib.pyplot as plt\npd.options.display.max_colwidth = 1000\nfrom time import gmtime, strftime\nTime_now = strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\nimport timeit\nstart = timeit.default_timer()\npd.options.display.max_rows = 100\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\ndf=pd.read_csv(\"../input/HR_comma_sep.csv\")\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"markdown","metadata":{"_cell_guid":"5884358b-7f58-cfbf-1ee5-df674d001177"},"source":"First we can simply describe the variables, and look at their means/standard deviations, and normal quintiles. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"84deca24-334c-1877-ca6d-8c7c4b832f28"},"outputs":[],"source":"df.columns = ['satisfaction_level', \n                  'last_evaluation', \n                  'number_project',\n                  'average_montly_hours', \n                  'time_spend_company', \n                  'Work_accident', \n                  'left',\n                  'promotion_last_5years', \n                  'department', \n                  'salary']\ndf.describe().T"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"19cd0695-c364-a917-ed93-73a237739052"},"outputs":[],"source":"df['dept_index'] = df['department']\n\ndepartment_groups = {'sales': 1, \n                     'marketing': 2, \n                     'product_mng': 3, \n                     'technical': 4, \n                     'IT': 5, \n                     'RandD': 6, \n                     'accounting': 7, \n                     'hr': 8, \n                     'support': 8, \n                     'management': 9 \n                    }\ndf['dept_index'] = df.department.map(department_groups)\nsalary_groups = {'low': 0, 'medium': 1, 'high': 2}\ndf['salary_index']=df['salary']\ndf.salary_index = df.salary.map(salary_groups)\n\n#\ndf.columns"},{"cell_type":"markdown","metadata":{"_cell_guid":"b163e82e-2509-878c-554d-26e2e6dd63e2"},"source":"Then we can plot a few pivot tables to look at the data and colormap them according to the values. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a6634d7a-4c25-6a8a-ac44-c90203315bc8"},"outputs":[],"source":"df_jobtype = pd.pivot_table(df,\n                        values = ['satisfaction_level', 'last_evaluation'],\n                        index = ['department'],\n                        columns = [],aggfunc=[np.mean], \n                        margins=True).fillna('')\n\ncm = sns.light_palette(\"green\", as_cmap=True)\ndf_jobtype.style.background_gradient(cmap=cm)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b36aae98-7d8b-9f3d-fc75-380343bba998"},"outputs":[],"source":"df_jobtype_salary = pd.pivot_table(df,\n                        values = ['satisfaction_level', 'last_evaluation'],\n                        index = ['department', 'salary'],\n                        columns = [],aggfunc=[np.mean], \n                        margins=True).fillna('')\ncm = sns.light_palette(\"green\", as_cmap=True)\ndf_jobtype_salary.style.background_gradient(cmap=cm)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4f88b684-1854-e89e-662c-94e360b88300"},"outputs":[],"source":"df_jobtype_salary_prom = pd.pivot_table(df,\n                        values = ['satisfaction_level', 'last_evaluation'],\n                        index = ['department','promotion_last_5years', 'salary'],\n                        columns = [],aggfunc=[np.mean], \n                        margins=True).fillna('')\n\ncm = sns.light_palette(\"green\", as_cmap=True)\ndf_jobtype_salary_prom.style.background_gradient(cmap=cm)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5de43de0-0d17-9071-9e80-2dcd48e70ffc"},"outputs":[],"source":"df_jobtype_prom = pd.pivot_table(df,\n                        values = ['satisfaction_level', 'last_evaluation'],\n                        index = ['department','promotion_last_5years'],\n                        columns = [],aggfunc=[np.mean], \n                        margins=True).fillna('')\n\ncm = sns.light_palette(\"green\", as_cmap=True)\ndf_jobtype_prom.style.background_gradient(cmap=cm)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"90d51710-81e5-eccd-87f2-167caf64bd6d"},"outputs":[],"source":"df_jobtype_salary_time = pd.pivot_table(df,\n                        values = ['satisfaction_level', 'last_evaluation'],\n                        index = ['department','time_spend_company', 'salary'],\n                        columns = [],aggfunc=[np.mean], \n                        margins=True).fillna('')\ncm = sns.light_palette(\"green\", as_cmap=True)\ndf_jobtype_salary_time.style.background_gradient(cmap=cm)"},{"cell_type":"markdown","metadata":{"_cell_guid":"891dfcb3-02ce-e082-7c74-9b8381b3dc5a"},"source":"We can now plot various plots and start seeing some trends in the data. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f4a15e06-8335-1f63-801f-1a1af1c9ed34"},"outputs":[],"source":"for i in set(df['department']):\n    aa= df[df['department'].isin([i])]\n    g = sns.factorplot(x='time_spend_company', y=\"satisfaction_level\",data=aa, \n                   saturation=1, kind=\"box\", col = 'left', row = 'department',\n                   ci=None, aspect=1, linewidth=1) "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a1b97303-cb42-909f-d224-3645a8035d6e"},"outputs":[],"source":"for i in set(df['department']):\n    aa= df[df['department'].isin([i])]\n    g = sns.factorplot(x='time_spend_company', y=\"satisfaction_level\",data=aa, \n                   saturation=1, kind=\"box\", col = 'salary', row='department', \n                   ci=None, aspect=1, linewidth=1) "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2122f940-35fb-5e8c-0ac8-d28c84a1600f"},"outputs":[],"source":"for i in set(df['department']):\n    aa= df[df['department'].isin([i])]\n    g = sns.factorplot(x='left', y=\"satisfaction_level\",data=aa, \n                   saturation=1, kind=\"box\", col = 'salary',row='department', \n                   ci=None, aspect=1, linewidth=1) "},{"cell_type":"markdown","metadata":{"_cell_guid":"0b7288a0-f4fb-0c3d-190f-f104ae957011"},"source":"We can now check how the various variables are correlated, and derive conclusions out of them. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ad60c2d2-6fcd-b58b-2496-4d5df3af0095"},"outputs":[],"source":"variable_correlations = df.corr()\nvariable_correlations"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"38308d1a-ebb3-364b-56b2-f1bec87b4078"},"outputs":[],"source":"def heat_map(corrs_mat):\n    sns.set(style=\"white\")\n    f, ax = plt.subplots(figsize=(11, 9))\n    mask = np.zeros_like(corrs_mat, dtype=np.bool)\n    mask[np.triu_indices_from(mask)] = True \n    # Generate a custom diverging colormap\n    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n    sns.heatmap(corrs_mat, mask=mask, cmap=cmap, ax=ax)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"deac9f50-aac3-6e37-709b-ff36cfbb9ebf"},"outputs":[],"source":"heat_map(variable_correlations)"},{"cell_type":"markdown","metadata":{"_cell_guid":"bf9850d7-0cd6-1013-d834-7de4b6d19ea7"},"source":"This shows a very high correlation between number of projects and average monthly hours. Therefore we should plot projects done vs various departments and their salaries. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d9bbf6a5-959c-48c7-8447-4b06b2856fb1"},"outputs":[],"source":"df_left = df[df['left']==1]\nreduced_variable_correlations = df_left.corr()\nreduced_variable_correlations\nheat_map(reduced_variable_correlations)"},{"cell_type":"markdown","metadata":{"_cell_guid":"509a21d6-ff03-717b-5da6-894a907fd633"},"source":"This shows a very high correlation between number of projects and average monthly hours. Therefore we should plot projects done vs various departments and their salaries. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a14f85a4-c78c-76c2-d648-e5257b049bdc"},"outputs":[],"source":"for i in set(df['department']):\n    aa= df[df['department'].isin([i])]\n    g = sns.factorplot(x='number_project', y=\"satisfaction_level\",data=aa, \n                   saturation=1, kind=\"box\", col = 'salary', row='department', \n                   ci=None, aspect=1, linewidth=1) "},{"cell_type":"markdown","metadata":{"_cell_guid":"cef60377-33bf-1cda-630e-6ff4987c997c"},"source":"It is now somewhat apparent that the sweet spot for number of projects done should be between 3 and 5. If employees don't get to work on any projects, they are not satisfied, and if they have to work on too many projects, they are again not satisfied. In fact, overworking them reduces the satisfaction very significantly. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"88d7ee8b-907c-7e1c-113f-76b89e54d489"},"outputs":[],"source":"for i in set(df['department']):\n    aa= df[df['department'].isin([i])]\n    g = sns.factorplot(x='number_project', y=\"average_montly_hours\",data=aa, \n                   saturation=1, kind=\"box\", col = 'left', row='department', \n                   ci=None, aspect=1, linewidth=1) "},{"cell_type":"markdown","metadata":{"_cell_guid":"96ee8b8c-c9e8-3e67-52a6-d7f59e671d39"},"source":"It seems that average monthly hours is a significant factor. The employees that left, were working a significantly more number of hours on an average compared to those who stayed. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"960761bd-b0b4-4333-4aa2-f7c5f389586b"},"outputs":[],"source":"for i in set(df['department']):\n    aa= df[df['department'].isin([i])]\n    g = sns.factorplot(x='number_project', y=\"average_montly_hours\",data=aa, \n                   saturation=1, kind=\"box\", col = 'promotion_last_5years', row='department', \n                   ci=None, aspect=1, linewidth=1) "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7f1acc80-b99b-c699-5cc7-f7465f240e55"},"outputs":[],"source":"df_small = df[['satisfaction_level', \n                   'last_evaluation', \n                   'number_project',\n                   'average_montly_hours', \n                   'time_spend_company']]\nsns.pairplot(df_small, hue=\"number_project\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"dca71dc5-3270-e4bd-fa67-7849fd1a5fba"},"source":"We can derive the same conclusions out of the pair plot as well. Wherever clusters exist, those clusters indicate a high correlation.  For example ~ those employees with very low satisfaction levels have very high number of hours, more than 5 projects, and because of this they have to spend a lot more hours than the normal. Although their last evaluations are high, the employees are not satisfied. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a7a6868c-3c18-5fc8-d989-e01a3f5b5008"},"outputs":[],"source":"#g = sns.PairGrid(df_small, diag_sharey=False)\n#g.map_lower(sns.kdeplot, cmap=\"Blues_d\")\n#g.map_upper(plt.scatter)\n#g.map_diag(sns.kdeplot, lw=3)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fad4ab86-ee19-fdbb-9bfe-61c1ed0397f2"},"outputs":[],"source":"df=pd.read_csv(\"../input/HR_comma_sep.csv\")\ndf.columns = ['satisfaction_level', \n                  'last_evaluation', \n                  'number_project',\n                  'average_montly_hours', \n                  'time_spend_company', \n                  'Work_accident', \n                  'left',\n                  'promotion_last_5years', \n                  'department', \n                  'salary']\nmod_df = df "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e9e1e6af-9767-e04d-0561-747afcf2d980"},"outputs":[],"source":"df.columns"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0fb9c80c-45ea-b336-3049-11e503bc099b"},"outputs":[],"source":"from sklearn.decomposition import PCA\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.feature_selection import RFECV, SelectKBest\n\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier\nfrom sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB, BernoulliNB\nfrom sklearn.neighbors import KNeighborsClassifier\n\nclassifiers = [('RandomForestClassifierG', RandomForestClassifier(n_jobs=-1, criterion='gini')),\n               ('RandomForestClassifierE', RandomForestClassifier(n_jobs=-1, criterion='entropy')),\n               ('AdaBoostClassifier', AdaBoostClassifier()),\n               ('ExtraTreesClassifier', ExtraTreesClassifier(n_jobs=-1)),\n               ('KNeighborsClassifier', KNeighborsClassifier(n_jobs=-1)),\n               ('DecisionTreeClassifier', DecisionTreeClassifier()),\n               ('ExtraTreeClassifier', ExtraTreeClassifier()),\n               ('LogisticRegression', LogisticRegression()),\n               ('GaussianNB', GaussianNB()),\n               ('BernoulliNB', BernoulliNB())\n              ]\nallscores = []\n\n\n\nsalary_groups = {'low': 0, 'medium': 1, 'high': 2}\n\ndepartment_groups = {'sales': 1, \n                     'marketing': 2, \n                     'product_mng': 3, \n                     'technical': 4, \n                     'IT': 5, \n                     'RandD': 6, \n                     'accounting': 7, \n                     'hr': 8, \n                     'support': 9, \n                     'management': 10 \n                    }\nmod_df.salary = mod_df.salary.map(salary_groups)\n\nmod_df['deptgrps'] = mod_df.department.map(department_groups)\n\nfor dept in mod_df.department.unique():\n    mod_df['dept_'+dept] = (mod_df.department == dept).astype(int)\nmod_df = mod_df.drop('department', axis=1)\n\nx, Y = mod_df.drop('left', axis=1), mod_df['left']\nfor name, classifier in classifiers:\n    scores = []\n    for i in range(3): # three runs\n        roc = cross_val_score(classifier, x, Y, scoring='roc_auc', cv=20)\n        scores.extend(list(roc))\n    scores = np.array(scores)\n    print(name, scores.mean())\n    new_data = [(name, score) for score in scores]\n    allscores.extend(new_data)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"03a234ee-db1a-288c-a4cb-dec41b8b8e3b"},"outputs":[],"source":"temp = pd.DataFrame(allscores, columns=['classifier', 'score'])\nsns.factorplot(x='classifier', \n               y=\"score\",data=temp, \n               saturation=1, \n               kind=\"bar\", \n               ci=None, \n               aspect=1, \n               linewidth=1) \nlocs, labels = plt.xticks()\nplt.setp(labels, rotation=90)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"413e1023-0a5a-d9f7-3981-2b8476a8f880"},"outputs":[],"source":"temp = pd.DataFrame(allscores, columns=['classifier', 'score'])\n#sns.violinplot('classifier', 'score', data=temp, inner=None, linewidth=0.3)\nsns.factorplot(x='classifier', \n               y=\"score\",\n               data=temp, \n               saturation=1, \n               kind=\"box\", \n               ci=None, \n               aspect=1, \n               linewidth=1)     \nlocs, labels = plt.xticks()\nplt.setp(labels, rotation=90)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"332b7bd3-6ef4-4f9f-73cc-000f19cdc8ac"},"outputs":[],"source":"df.columns"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0a4af5b7-b186-f393-a5ca-62333d85e8e1"},"outputs":[],"source":"x, Y = mod_df.drop('left', axis=1), mod_df['left']\n\nfor name, classifier in classifiers:\n    scores = []\n    for i in range(3): # three runs\n        roc = cross_val_score(classifier, x, Y, scoring='roc_auc', cv=20)\n        scores.extend(list(roc))\n    scores = np.array(scores)\n    print(name, scores.mean())\n    new_data = [(name, score) for score in scores]\n    allscores.extend(new_data)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9e5847ff-a697-a082-c052-627ae241e18c"},"outputs":[],"source":"reduced_variable_correlations = mod_df.corr()\nreduced_variable_correlations\nheat_map(reduced_variable_correlations)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"86d69456-30a2-f027-a3c7-8b260971d31f"},"outputs":[],"source":"mod_df_left = mod_df[mod_df['left']==1]\nreduced_variable_correlations = mod_df_left.corr()\nreduced_variable_correlations\nheat_map(reduced_variable_correlations)"},{"cell_type":"markdown","metadata":{"_cell_guid":"157ed745-40c7-1cc3-96f7-ebedb7127707"},"source":"We can see now, that by splitting things into various departments, one can see that the things are not common at all places. Some departments need more work on one aspect over the other. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4225f3f0-bb1a-bf2d-2fef-1d7ab0e79a30"},"outputs":[],"source":"x, Y = mod_df.drop('promotion_last_5years', axis=1), mod_df['promotion_last_5years']\nfor name, classifier in classifiers:\n    scores = []\n    for i in range(3): # three runs\n        roc = cross_val_score(classifier, x, Y, scoring='roc_auc', cv=20)\n        scores.extend(list(roc))\n    scores = np.array(scores)\n    print(name, scores.mean())\n    new_data = [(name, score) for score in scores]\n    allscores.extend(new_data)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"96801e9b-ef25-565c-efca-fad6e1b5c945"},"outputs":[],"source":"temp = pd.DataFrame(allscores, columns=['classifier', 'score'])\n#sns.violinplot('classifier', 'score', data=temp, inner=None, linewidth=0.3)\nsns.factorplot(x='classifier', \n               y=\"score\",\n               data=temp, \n               saturation=1, \n               kind=\"box\", \n               ci=None, \n               aspect=1, \n               linewidth=1)     \nlocs, labels = plt.xticks()\nplt.setp(labels, rotation=90)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"57106c9f-4dba-8090-fad5-9f0ecf97c7e1"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}