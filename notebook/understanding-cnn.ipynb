{"cells":[{"metadata":{"_uuid":"1d4388eed1ede2a3083c3419d184d4367d4fa34e"},"cell_type":"markdown","source":"## CNN\n\nA Convolutional Neural Network is a very special kind of multi layer neural network. The name convolutional neural network means that the network employs mathematical operation called convolution that combines imformation from 2 sources to produce a new set of information. CNN uses this convolution operation to extract relevant explanatory features for the input image. \n \n There are 3 main layers in simple CNN\n*  Convolution Layer\n*  Polling Layer\n*  Fully Connected Layer\n\nThe convolutional layer is the main type of layer in CNN, where each neuron is connected to a certain region of the input area called the **receptive field**.\n\nIn a typical CNN architecture, each convolutional layer is followed by a **Rectified Linear Unit (ReLU)** layer , then a **Pooling layer** then one or more convolutional layer (+ ReLU) and finally one or more **Fully Connected Layer**. The output from each convolution layer is a set of objects called** feature maps**, generated by a single kernel filter. Then the feature maps can be used to define a new input to the next layer.\n\n![](https://www.safaribooksonline.com/library/view/practical-convolutional-neural/9781788392303/assets/f6a1addd-d986-4e6a-b27b-388aa2bfd8f3.png)"},{"metadata":{"_uuid":"c8487497d291cee4e672a3a5da42f0a20bc0ac29"},"cell_type":"markdown","source":"### Why CNN?\n\n**FFN** are powerful, but one of their main disadavantage is that it **ignores the structure of the input**. Input data to the network has to be converted into a numeric 1D array. However for higher dimensional arrays like image, it gets difficult to deal with such conversion. It is essential to preserve the structure of images, as there are lot of hidden information stored inside, this is where a CNN comes into the picture. A **CNN considers the structure of the image** while processing them.\n\nLets consider Face Recognition problem. In the case of FNN we need to convert a face image into 1D vector. As you can see, in the below figure, there is no positional relationships between the different rows of images. This makes our classifier less sensitive towards positional changes. To overcome this issue we need to train the network with spatial context, this is where CNN comes in\n\n\n![](https://www.safaribooksonline.com/library/view/ensemble-machine-learning/9781788297752/assets/a1f5bcdc-ccc0-4201-889b-991fa63ef481.png)\n\nAnother disadvantage is MLP/FNN works fien for small images, but it break downs for larger images because of the huge number of parameters required. \n\nFor example, a 100 X 100 image has 10000 pixels, and if the first layers has just 1000 neurons, this means 10 million conenctions.\n\n![](https://www.safaribooksonline.com/library/view/practical-convolutional-neural/9781788392303/assets/685a8fc6-999c-4f76-92ef-0377bfa260f0.png)\n\nCNNs solve this problem using partially connected layers. Filters/kernels which are used in intermediate layers, shares same weights. Hence CNNs use less number of parameters than MLP\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport time\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"markdown","source":"## Convolutional Layer\nThe Main objective of convolution in relation to Convnet is to extract features from the input image. This layer does most of the computation in a ConvNet. Lets try to understand how this convolution works\n\n\n    * In mathematics, convolution is a mathematical operation on two functions that produces a third function¡ªthat is, the modified (convoluted) version of one of the original functions. The resulting function gives in integral of the pointwise multiplication of the two functions as a function of the amount that one of the original functions is translated. Interested readers can refer to this URL for more information: https://en.wikipedia.org/wiki/Convolution.\n    \n Convolution involves the multiplication of 2 functions, f and g, to produce a new modified function (  f * g ). For example Convolution between an image say f with a filter function , g will produce a new version of the image\n \n Lets start manually convolving  4 X 4 input with 3 X 3 filter. The first step in the convolution process is to take the element wise product of the filter and the local receptive field \n (first nine boxes) of the input\n \n ![](https://www.safaribooksonline.com/library/view/deep-learning-quick/9781788837996/assets/47bb2d29-6a4a-46d5-8193-51c49ee62817.jpg)\n \n Once first convolution operation is done, we will just slide the filter over one row and do the same operation until filter is slided through all the rows and columns. Convolution operation reduces to a feature map of size 2 X 2 matrix.\n \n  ![](https://www.safaribooksonline.com/library/view/deep-learning-quick/9781788837996/assets/1ffeca84-f312-4324-bb86-19417a50f596.jpg)\n    \nFilters slides over the width and height of the input volume, to produce a 2D activation that gives the reponses of that filter at every spatial position. These filter detect features like edges, blocks etc. Each dot product between filter and image chunk results in a single number. We will use multiple filters to extract different features from images.\n\n![](https://www.safaribooksonline.com/library/view/neural-network-programming/9781788390392/assets/7059df7a-658f-47ca-b8df-63dae005f5a7.jpg)\n\n\n\n\n\n    "},{"metadata":{"_uuid":"3b3f4daaa9dc212c88f910b99f35d8384256b143"},"cell_type":"markdown","source":"## Convolution operations in TensorFlow\n\n    conv2d(\n         input,\n         filter,\n         strides,\n         padding,\n         use_cudnn_on_gpu=True,\n         data_format='NHWC',\n         dilations=[1, 1, 1, 1],\n         name=None\n     )\n \n## Convolution layers in Keras\n\n    Conv2D(filters, kernel_size, strides, padding, activation='relu', input_shape)\n    \n## Convolution layer in Pytorch\n\n    torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)\n"},{"metadata":{"_uuid":"ccc421eae4ad0794db4480012a039ee46fa3f93a"},"cell_type":"markdown","source":"### Padding \n\nSingle Conv layer reduces the image of size 32 X 32 to activation map of size 28 X 28 which will be used as input to next layer. Subsequent Conve layer reduces the image size drastically which results in loss of information and vanishing gradient problem. To over come this padding comes into picture.\n\nPadding increases the size of a input data by appending/prepending constants around input data. In most of the cases , this constant is zero and it called Zero padding.\n\n**SAME padding ** The term SAME means that the output feature map has the same spatial dimensions as the input feature map. Tries to pad evenly left and right, but if the number of columns to be added is odd, it will add the extra column to the right.\n\n**VALID padding ** VALID means no padding and only drops the rightmost columns (or bottommost rows)\n\n### Strides\nThe strides causes a kernel to skip over pixels in an image and not include them in the output. The strides  determines how a convolution operation works with a kernel when a larger image and more complex kernel are used. As a convolution is sliding the kernel over the input, it is using the strides parameter to determine how it walks over the input, instead of going over every element of an input.\n\nLet F X F be the size of the filter, Conv layer with Stride 1 and Zero Padding (F -1) / 2 will preserve the size spatially\n"},{"metadata":{"trusted":true,"_uuid":"02da851eaef6ee349974178631813595d1eb2697"},"cell_type":"code","source":"sess = tf.InteractiveSession()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d8a0391a042773f26799ccd2fbe97db096d6137"},"cell_type":"code","source":"i = tf.constant([\n                 [1.0, 1.0, 1.0, 0.0, 0.0],\n                 [0.0, 0.0, 1.0, 1.0, 1.0],\n                 [0.0, 0.0, 1.0, 1.0, 0.0],\n                 [0.0, 0.0, 1.0, 0.0, 0.0]], dtype=tf.float32)\nk = tf.constant([\n                [1.0, 0.0, 1.0],\n                [0.0, 1.0, 0.0],\n                [1.0, 0.0, 1.0]\n        ], dtype=tf.float32)\n\nkernel = tf.reshape(k,[3,3,1,1], name = 'Kernel')\nimage = tf.reshape(i, [1,4,5,1], name = 'image')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"89b85c72022658357b69f5c22a098b039003d985"},"cell_type":"code","source":"res = tf.squeeze(tf.nn.conv2d(image, kernel, strides = [1,1,1,1], padding = \"VALID\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a5130ac120d0c3bfff19861692d0aee534f5067"},"cell_type":"code","source":"sess.run(res)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"76b989b2c6ecb1fdae0c7121d98a1d9595a23dc1"},"cell_type":"code","source":"res = tf.squeeze(tf.nn.conv2d(image, kernel, strides = [1,1,1,1], padding = \"SAME\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cffb219330d77c611376dd11f71dab149b5a4f79"},"cell_type":"code","source":"sess.run(res)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4ff9c1df97c31f14ff71632b07a1b014295f2092"},"cell_type":"markdown","source":"**Conv Layer In short**\n\n* Accepts a volume of size W1 X H1 X D1\n* Requires 4 major hyperparameters\n    * No. of filters K (usually K will be power of 2)\n    * Filter Spatial extent F\n    * Stride S\n    * Amount of Zero padding P\n* Produces a volume of size W2 X H2 X D2 where\n    * W2 = (W1 - F + 2P) / S + 1\n    * H2 =  (H1 - F + 2P) / S + 1\n* With Parameter sharing it introduces F * F * D1 weights per filter . So in total (F * F * D1) * K weights and K Bias"},{"metadata":{"_uuid":"4cd72b4dc0f5e8ad825c5351b266a5bde8a688f3"},"cell_type":"markdown","source":"## Activation Functions"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"657d6f60a84991ae62cd1e1c2a8a9d367cfa62eb"},"cell_type":"markdown","source":"## ReLU\n\nThe Rectified Linear Unit is the most commonly used activation function in deep learning models. The function returns 0 if it receives any negative input, but for any positive value  xx  it returns that value back. So it can be written as **f(x)=max(0,x) **.\n\n*Mathematical Notation*\n\nGraphically it looks like this\n\n![](https://i.imgur.com/gKA4kA9.jpg)\n\nIt's surprising that such a simple function (and one composed of two linear pieces) can allow your model to account for non-linearities and interactions so well. But the ReLU function works great in most applications, and it is very widely used as a result."},{"metadata":{"_uuid":"dad7ec198bf405c0085f6e6172acd52a1bf935c7"},"cell_type":"markdown","source":"## Pooling\n\nPooling layers help with overfitting and improve performance by reducing the size of the input tensor. Typically they are used to scale down the input, keeping important function.\n\n**Pooling meachanisms:**\n* Max -  max pooling uses the maximum value from each of a cluster of neurons at the prior layer.\n* Average - Average pooling uses the mean value from each of a cluster of neurons at the prior layer."},{"metadata":{"trusted":true,"_uuid":"4228cdd61554730889c70e8875541ce8dfe52055"},"cell_type":"code","source":"inp = tf.constant([\n    [\n     [[1.0], [0.2], [2.0]],\n     [[0.1], [1.2], [1.4]],\n     [[1.1], [0.4], [0.4]]\n    ] \n  ])\n\nkernel = [1, 2, 2, 1]\nmax_pool = tf.nn.max_pool(inp, kernel, [1,1,1,1], \"VALID\")\nsess.run(max_pool)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e6e5fb0a767900d6ef5aee6a74dce2980c10143"},"cell_type":"code","source":"avg_pool = tf.nn.avg_pool(inp, kernel, [1, 1, 1, 1], \"VALID\")\nsess.run(avg_pool)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1505370d6f0920c8f81c442e6b2e7d8c74ac72f0"},"cell_type":"markdown","source":"## Fully Connected Layer\n\n After several convolutional and max pooling layers, the high-level reasoning in the neural network is done via fully connected layers. Neurons in a fully connected layer have connections to all activations in the previous layer, as seen in regular neural networks. Their activations can hence be computed with a matrix multiplication followed by a bias offset."},{"metadata":{"_uuid":"e2b409f32572bb12a5d3a348ed257d7d84d338f6"},"cell_type":"markdown","source":"## CNN Model"},{"metadata":{"_uuid":"cf71bcbb94297c1ec51240f6d287c74815c307fe"},"cell_type":"markdown","source":"### Hyperparameters\n\n*one epoch = one forward pass and one backward pass of all the training examples*\n\n*batch size = the number of training examples in one forward/backward pass. The higher the batch size, the more memory space you'll need.*\n\n*The learning rate defines how quickly or slowly a network updates its parameters.*\n\n*Low learning rate slows down the learning process but converges smoothly. Larger learning rate speeds up the learning but may not converge. Usually a decaying Learning rate is preferred.*\n\n"},{"metadata":{"_uuid":"7b5eaf1ba78a994f00d122312abe8189ba718882"},"cell_type":"markdown","source":"**to be continued..**"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}