{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"69b3b67c-cf0e-6ea0-0b2f-89c525d0f1dc"},"source":"# This workbook will provide an in depth understanding of how Logistic regression works with the iris dataset"},{"cell_type":"markdown","metadata":{"_cell_guid":"b1447d68-23c2-3856-7613-7a5ecc4afe46"},"source":"# Import required packages"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"97af844c-daa3-cc32-9ce0-19414562bed9"},"outputs":[],"source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\n%matplotlib inline"},{"cell_type":"markdown","metadata":{"_cell_guid":"a9194d93-d9f1-89b5-8f2e-448908bc6afe"},"source":"# Loading dataset\n\n#### We will focus our analysis on 2D datasets. This means that, instead of trying to predict flower classes by using all 4 features, we will analyse separately the sepal and petal information.\n\n#### This is done for visualisation purposes which will enable us to better understand what the algorithm does when performing parameter tuning to it."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6e78bae2-9929-88cd-3b27-3e4c74143b0d"},"outputs":[],"source":"from sklearn import datasets\niris = datasets.load_iris()\n\nX1_sepal = iris.data[:,[0,1]]\nX2_petal = iris.data[:,[2,3]]\ny = iris.target\n\nprint(X1_sepal[1:5,:])\nprint(X2_petal[1:5,:])\nprint(y)  "},{"cell_type":"markdown","metadata":{"_cell_guid":"3192c4f6-2b78-c8fd-8a06-4dc025a261a0"},"source":"# Visualising the data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c249d904-4392-bae5-0251-cbe7915cf6a9"},"outputs":[],"source":"plt.figure(figsize=(15, 5))\n\nplt.subplot(1,2,1)\nplt.scatter(X1_sepal[:, 0], X1_sepal[:, 1], c=y)\nplt.xlabel('Sepal length')\nplt.ylabel('Sepal width')\n\nplt.subplot(1,2,2)\nplt.scatter(X2_petal[:, 0], X2_petal[:, 1], c=y)\nplt.xlabel('Petal length')\nplt.ylabel('Petal width')"},{"cell_type":"markdown","metadata":{"_cell_guid":"0e1cd5f0-649b-0690-652c-3db60006312e"},"source":"#### Create function used to plot decision regions"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"19fcd3be-5fbf-8fc4-1b59-abc0dc10d942"},"outputs":[],"source":"from matplotlib.colors import ListedColormap\n\ndef plot_decision_regions(X,y,classifier,test_idx=None,resolution=0.02):\n    \n    # Initialise the marker types and colors\n    markers = ('s','x','o','^','v')\n    colors = ('red','blue','lightgreen','gray','cyan')\n    color_Map = ListedColormap(colors[:len(np.unique(y))]) #we take the color mapping correspoding to the \n                                                            #amount of classes in the target data\n    \n    # Parameters for the graph and decision surface\n    x1_min = X[:,0].min() - 1\n    x1_max = X[:,0].max() + 1\n    x2_min = X[:,1].min() - 1\n    x2_max = X[:,1].max() + 1\n    xx1, xx2 = np.meshgrid(np.arange(x1_min,x1_max,resolution),\n                           np.arange(x2_min,x2_max,resolution))\n    \n    Z = classifier.predict(np.array([xx1.ravel(),xx2.ravel()]).T)\n    Z = Z.reshape(xx1.shape)\n    \n    plt.contour(xx1,xx2,Z,alpha=0.4,cmap = color_Map)\n    plt.xlim(xx1.min(),xx1.max())\n    plt.ylim(xx2.min(),xx2.max())\n    \n    # Plot samples\n    X_test, Y_test = X[test_idx,:], y[test_idx]\n    \n    for idx, cl in enumerate(np.unique(y)):\n        plt.scatter(x = X[y == cl, 0], y = X[y == cl, 1],\n                    alpha = 0.8, c = color_Map(idx),\n                    marker = markers[idx], label = cl\n                   )"},{"cell_type":"markdown","metadata":{"_cell_guid":"e379bc01-c1ef-5c6e-a5dc-68d9c3c17f21"},"source":"# Splitting and scaling the dataset"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"72556556-9a3e-daf2-d07c-83be09eab33d"},"outputs":[],"source":"from sklearn.cross_validation import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n#######################################################################\n## SPLITTING\n\n\nX_train_sepal, X_test_sepal, y_train_sepal, y_test_sepal = train_test_split(X1_sepal,y,test_size=0.3,random_state=0)\n\nprint(\"# training samples sepal: \", len(X_train_sepal))\nprint(\"# testing samples sepal: \", len(X_test_sepal))\n\nX_train_petal, X_test_petal, y_train_petal, y_test_petal = train_test_split(X2_petal,y,test_size=0.3,random_state=0)\n\nprint(\"# training samples petal: \", len(X_train_petal))\nprint(\"# testing samples petal: \", len(X_test_petal))\n\n#####################################################################\n## SCALING\n\nsc = StandardScaler()\nX_train_sepal_std = sc.fit_transform(X_train_sepal)\nX_test_sepal_std = sc.transform(X_test_sepal)\n\nsc = StandardScaler()\nX_train_petal_std = sc.fit_transform(X_train_petal)\nX_test_petal_std = sc.transform(X_test_petal)\n\n#####################################################################\n## COMBINING FOR FUTURE PLOTTING\n\nX_combined_sepal_standard = np.vstack((X_train_sepal_std,X_test_sepal_std))\nY_combined_sepal = np.hstack((y_train_sepal, y_test_sepal))\n\nX_combined_petal_standard = np.vstack((X_train_petal_std,X_test_petal_std))\nY_combined_petal = np.hstack((y_train_petal, y_test_petal))"},{"cell_type":"markdown","metadata":{"_cell_guid":"cadc28a1-8233-25f7-25e0-636fe59c04f8"},"source":"# Testing different parameters to understand how accuracies change.\n\n## Understanding how decision regions change when using different regularization values.\n\n#### Remember that we use paramter C as our regularization parameter. Parameter C = 1/¦Ë.\n\n#### Lambda (¦Ë) controls the trade-off between allowing the model to increase it's complexity as much as it wants with trying to keep it simple. For example, if ¦Ë is very low or 0, the model will have enough power to increase it's complexity (overfit) by assigning big values to the weights for each parameter. If, in the other hand, we increase the value of ¦Ë, the model will tend to underfit, as the model will become too simple.\n\n#### Parameter C will work the other way around. For small values of C, we increase the regularization strength which will create simple models which underfit the data. For big values of C, we low the power of regularization which imples the model is allowed to increase it's complexity, and therefore, overfit the data."},{"cell_type":"markdown","metadata":{"_cell_guid":"096daf1e-1ead-2a72-05fb-42de92a1f4a4"},"source":"### 1. Testing sepal data with different regularization values."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3f437e7b-6a84-2633-4708-068219f7e91c"},"outputs":[],"source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.learning_curve import validation_curve\n\nC_param_range = [0.001,0.01,0.1,1,10,100]\n\nsepal_acc_table = pd.DataFrame(columns = ['C_parameter','Accuracy'])\nsepal_acc_table['C_parameter'] = C_param_range\n\nplt.figure(figsize=(10, 10))\n\nj = 0\nfor i in C_param_range:\n    \n    # Apply logistic regression model to training data\n    lr = LogisticRegression(penalty = 'l2', C = i,random_state = 0)\n    lr.fit(X_train_sepal_std,y_train_sepal)\n    \n    # Predict using model\n    y_pred_sepal = lr.predict(X_test_sepal_std)\n    \n    # Saving accuracy score in table\n    sepal_acc_table.iloc[j,1] = accuracy_score(y_test_sepal,y_pred_sepal)\n    j += 1\n    \n    # Printing decision regions\n    plt.subplot(3,2,j)\n    plt.subplots_adjust(hspace = 0.4)\n    plot_decision_regions(X = X_combined_sepal_standard\n                      , y = Y_combined_sepal\n                      , classifier = lr\n                      , test_idx = range(105,150))\n    plt.xlabel('Sepal length')\n    plt.ylabel('Sepal width')\n    plt.title('C = %s'%i)"},{"cell_type":"markdown","metadata":{"_cell_guid":"de4c9733-ab5d-afd4-7776-60b98995523c"},"source":"### Comments on sepal model:\n\n#### As you can observe, there are very slight differences between the decision regions for this dataset. As logistic regression is linear, this algorithm can't change much the classification model as the data is not linearly separated."},{"cell_type":"markdown","metadata":{"_cell_guid":"391115f4-bf46-ada6-ba47-9828f836415a"},"source":"### 2. Testing petal data with different regularization values."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0c516bec-dcbd-f343-9f64-4fce28758418"},"outputs":[],"source":"petal_acc_table = pd.DataFrame(columns = ['C_parameter','Accuracy'])\npetal_acc_table['C_parameter'] = C_param_range\n\nplt.figure(figsize=(10, 10))\n\nj = 0\nfor i in C_param_range:\n    \n    # Apply logistic regression model to training data\n    lr = LogisticRegression(penalty = 'l2', C = i,random_state = 0)\n    lr.fit(X_train_petal_std,y_train_petal)\n    \n    # Predict using model\n    y_pred_petal = lr.predict(X_test_petal_std)\n    \n    # Saving accuracy score in table\n    petal_acc_table.iloc[j,1] = accuracy_score(y_test_petal,y_pred_petal)\n    j += 1\n    \n    # Printing decision regions\n    plt.subplot(3,2,j)\n    plt.subplots_adjust(hspace = 0.4)\n    plot_decision_regions(X = X_combined_petal_standard\n                      , y = Y_combined_petal\n                      , classifier = lr\n                      , test_idx = range(105,150))\n    plt.xlabel('Petal length')\n    plt.ylabel('Petal width')\n    plt.title('C = %s'%i)"},{"cell_type":"markdown","metadata":{"_cell_guid":"96948add-72e9-e2ad-bebc-7ba42298b5d2"},"source":"### Comments of petal\n\n#### Here, the effect of using different regularization values is quite obvious. As we mentioned before, small C values will increase the regularization strenght which implies the creation of simple models that tend to underfit the data. By using bigger C values, the model can increase it's complexity and adjust better to the data."},{"cell_type":"markdown","metadata":{"_cell_guid":"3b2f6b48-cad6-2236-df9d-cabb5ff2100d"},"source":"## Understanding which C parameters are the best to use.\n\n#### A valid question to raise is, which C values must we then use? \n\n#### There is a way to check which C values are best. The idea is to understand how each C value affects the accuracy of the training set and the testing set. Remember that our goal is always to create a model that can generalise to unseen data.\n\n#### The way to do this is to plot validation curves."},{"cell_type":"markdown","metadata":{"_cell_guid":"263c633e-eef2-d228-bc2a-480fa677f2fe"},"source":"### Use of validation curves for both datasets."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"eb39b8b0-1feb-7748-ea77-081b73f8fde3"},"outputs":[],"source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.learning_curve import validation_curve\n### 1. Use of validation curves for both datasets.\nC_param_range = [0.001,0.01,0.1,1,10,100,1000]\n\nplt.figure(figsize=(15, 10))\n\n# Apply logistic regression model to training data\nlr = LogisticRegression(penalty='l2',C = i,random_state = 0)\n\n# SEPAL Plot validation curve\ntrain_sepal_scores, test_sepal_scores = validation_curve(estimator=lr\n                                                            ,X=X_combined_sepal_standard\n                                                            ,y=Y_combined_sepal\n                                                            ,param_name='C'\n                                                            ,param_range=C_param_range\n                                                            )\n\ntrain_sepal_mean = np.mean(train_sepal_scores,axis=1)\ntrain_sepal_std = np.std(train_sepal_scores,axis=1)\ntest_sepal_mean = np.mean(test_sepal_scores,axis=1)\ntest_sepal_std = np.std(test_sepal_scores,axis=1)\n\nplt.subplot(2,2,1)\nplt.plot(C_param_range\n            ,train_sepal_mean\n            ,color='blue'\n            ,marker='o'\n            ,markersize=5\n            ,label='training accuracy')\n    \nplt.plot(C_param_range\n            ,test_sepal_mean\n            ,color='green'\n            ,marker='x'\n            ,markersize=5\n            ,label='test accuracy') \n    \nplt.xlabel('C_parameter')\nplt.ylabel('Accuracy')\nplt.legend(loc='lower right')\nplt.ylim([0.5,1])\n\n\n\n# PETAL Plot validation curve\ntrain_petal_scores, test_petal_scores = validation_curve(estimator=lr\n                                                            ,X=X_combined_petal_standard\n                                                            ,y=Y_combined_petal\n                                                            ,param_name='C'\n                                                            ,param_range=C_param_range\n                                                            )\n\n\ntrain_petal_mean = np.mean(train_petal_scores,axis=1)\ntrain_petal_std = np.std(train_petal_scores,axis=1)\ntest_petal_mean = np.mean(test_petal_scores,axis=1)\ntest_petal_std = np.std(test_petal_scores,axis=1)\n\nplt.subplot(2,2,2)\nplt.plot(C_param_range\n            ,train_petal_mean\n            ,color='blue'\n            ,marker='o'\n            ,markersize=5\n            ,label='training accuracy')\n    \nplt.plot(C_param_range\n            ,test_petal_mean\n            ,color='green'\n            ,marker='x'\n            ,markersize=5\n            ,label='test accuracy') \n    \nplt.xlabel('C_parameter')\nplt.ylabel('Accuracy')\nplt.legend(loc='lower right')\nplt.ylim([0.5,1])"},{"cell_type":"markdown","metadata":{"_cell_guid":"3707794b-4939-cf4e-13fd-97546db1acb7"},"source":"### Comment on validation curves:\n\n#### 1. As we saw for the validation curves, the sepal dataset has much lower accuracy than the petal one. \n#### 2. The petal dataset keeps increasing its training accuracy if you let the model be as complex as it likes.\n\n### So, which C do we use?\n\n#### You might have guessed it, but the idea is to choose that C which offers the smallest difference between the training and testing accuracy (remember we want to generalise our model to unseen data)."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"390dad8d-de4f-99f9-88dd-94f9178c1253"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}