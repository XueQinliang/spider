{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"816fec69-c9c7-10fb-f353-69ef8c840784"},"source":"Greedy layer-wise pretraining in Keras\n==========\n\nApparently this method has fallen out of favor, but it's a good Keras exercise. Also, the 20 minute time limit is pretty restrictive for the number of things that have to happen here, but it appears to be working.\n\nThe code is set up for three layers of autoencoders, followed by a classification task, but the third layer is commented out due to time. Thus **this model uses two layers of pretrained autoencoders, followed by a dense layer attached to a softmax**. Dropout is used for regularization and Batch Normalization is used to speed up training. If this published kernel works the way it did in interactive mode, the final accuracy should be in the mid to high 90s.\n\nEven if pretraining autoencoders is no longer considered a good idea, one useful trick shown in this script is how to take layers with trained weights, and \"copy\" them into different models using **get_weights()** and **set_weights()**.\n\nFor more on autoencoders in Keras, see The Keras Blog's [Building Autoencoders in Keras][1]\n\n  [1]: https://blog.keras.io/building-autoencoders-in-keras.html"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ee9f752d-7bf3-fee5-7411-64db1922714c"},"outputs":[],"source":"%env KERAS_BACKEND=theano\n%reset\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n \nimport keras\nimport keras.backend as K\nfrom keras.layers import Input, Convolution2D, Activation, MaxPooling2D, \\\n     Dense, BatchNormalization, Dropout\nfrom keras.layers.core import Flatten\nfrom keras.optimizers import SGD\nfrom keras.models import Model\nfrom keras.utils import np_utils\nfrom keras.constraints import maxnorm\nfrom keras.regularizers import l2\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.layers.normalization import BatchNormalization\n\nprint(keras.__version__)\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"},{"cell_type":"markdown","metadata":{"_cell_guid":"c6db01ee-ee2b-84fe-d4b6-3ac1f41f4ddf"},"source":"## Scaling\n\nScaling inputs to be between 0 and 1. That makes the decoding model simple, because we can pretend like we're working with a binary output.\n\n\nFrom the Theano docs: [binary_crossentropy][1]\n\n```\ncrossentropy(t,o) = -(t * log(o) + (1 - t) * log(1 - o)).\n```\n\n  [1]: http://deeplearning.net/software/theano/library/tensor/nnet/nnet.html#theano.tensor.nnet.nnet.binary_crossentropy"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e71b38df-370a-15d0-1ae4-ae720a77e245"},"outputs":[],"source":"N_train = 30000 # Out of 42000, to reduce processing time\ntrain = np.genfromtxt('../input/train.csv', delimiter = ',', skip_header = 1)\ntraining_inputs = train[0:N_train, 1:] / 255.0\ntraining_targets = np_utils.to_categorical(train[:, int(0)])[0:N_train]\n\nval_inputs = train[(N_train+1):42000, 1:] / 255.0\nval_targets = np_utils.to_categorical(train[:, int(0)])[(N_train+1):42000]\n\n#test = np.genfromtxt('../input/test.csv', delimiter = ',', skip_header = 1)\n#test_inputs = test[:, ] / 255.0"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d14475d6-c257-c5fe-44ea-b330ae58c43f"},"outputs":[],"source":"# For 2D data (e.g. image), ordering type \"tf\" assumes (rows, cols, channels)\n#  type \"th\" assumes (channels, rows, cols). See https://keras.io/backend/\nprint('We are using image ordering type', K.image_dim_ordering())\n\ntraining_inputs = training_inputs.reshape(training_inputs.shape[0], 784)\n#test_inputs = test_inputs.reshape(test_inputs.shape[0], 784)\nprint(training_inputs.shape)\nprint(val_inputs.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f44a1d19-f107-ba95-1f08-6274dc950da2"},"outputs":[],"source":"# Layer by layer pretraining Models\n\n# Layer 1\ninput_img = Input(shape = (784, ))\ndistorted_input1 = Dropout(.1)(input_img)\nencoded1 = Dense(800, activation = 'sigmoid')(distorted_input1)\nencoded1_bn = BatchNormalization()(encoded1)\ndecoded1 = Dense(784, activation = 'sigmoid')(encoded1_bn)\n\nautoencoder1 = Model(input = input_img, output = decoded1)\nencoder1 = Model(input = input_img, output = encoded1_bn)\n\n# Layer 2\nencoded1_input = Input(shape = (800,))\ndistorted_input2 = Dropout(.2)(encoded1_input)\nencoded2 = Dense(400, activation = 'sigmoid')(distorted_input2)\nencoded2_bn = BatchNormalization()(encoded2)\ndecoded2 = Dense(800, activation = 'sigmoid')(encoded2_bn)\n\nautoencoder2 = Model(input = encoded1_input, output = decoded2)\nencoder2 = Model(input = encoded1_input, output = encoded2_bn)\n\n# Layer 3 - which we won't end up fitting in the interest of time\nencoded2_input = Input(shape = (400,))\ndistorted_input3 = Dropout(.3)(encoded2_input)\nencoded3 = Dense(200, activation = 'sigmoid')(distorted_input3)\nencoded3_bn = BatchNormalization()(encoded3)\ndecoded3 = Dense(400, activation = 'sigmoid')(encoded3_bn)\n\nautoencoder3 = Model(input = encoded2_input, output = decoded3)\nencoder3 = Model(input = encoded2_input, output = encoded3_bn)\n\n# Deep Autoencoder\nencoded1_da = Dense(800, activation = 'sigmoid')(input_img)\nencoded1_da_bn = BatchNormalization()(encoded1_da)\nencoded2_da = Dense(400, activation = 'sigmoid')(encoded1_da_bn)\nencoded2_da_bn = BatchNormalization()(encoded2_da)\nencoded3_da = Dense(200, activation = 'sigmoid')(encoded2_da_bn)\nencoded3_da_bn = BatchNormalization()(encoded3_da)\ndecoded3_da = Dense(400, activation = 'sigmoid')(encoded3_da_bn)\ndecoded2_da = Dense(800, activation = 'sigmoid')(decoded3_da)\ndecoded1_da = Dense(784, activation = 'sigmoid')(decoded2_da)\n\ndeep_autoencoder = Model(input = input_img, output = decoded1_da)\n\n# Not as Deep Autoencoder\nnad_encoded1_da = Dense(800, activation = 'sigmoid')(input_img)\nnad_encoded1_da_bn = BatchNormalization()(nad_encoded1_da)\nnad_encoded2_da = Dense(400, activation = 'sigmoid')(nad_encoded1_da_bn)\nnad_encoded2_da_bn = BatchNormalization()(nad_encoded2_da)\nnad_decoded2_da = Dense(800, activation = 'sigmoid')(nad_encoded2_da_bn)\nnad_decoded1_da = Dense(784, activation = 'sigmoid')(nad_decoded2_da)\n\nnad_deep_autoencoder = Model(input = input_img, output = nad_decoded1_da)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"444064c5-1e69-dfe1-a207-30cb6dda5eac"},"outputs":[],"source":"sgd1 = SGD(lr = 5, decay = 0.5, momentum = .85, nesterov = True)\nsgd2 = SGD(lr = 5, decay = 0.5, momentum = .85, nesterov = True)\nsgd3 = SGD(lr = 5, decay = 0.5, momentum = .85, nesterov = True)\n\nautoencoder1.compile(loss='binary_crossentropy', optimizer = sgd1)\nautoencoder2.compile(loss='binary_crossentropy', optimizer = sgd2)\nautoencoder3.compile(loss='binary_crossentropy', optimizer = sgd3)\n\nencoder1.compile(loss='binary_crossentropy', optimizer = sgd1)\nencoder2.compile(loss='binary_crossentropy', optimizer = sgd1)\nencoder3.compile(loss='binary_crossentropy', optimizer = sgd1)\n\ndeep_autoencoder.compile(loss='binary_crossentropy', optimizer = sgd1)\nnad_deep_autoencoder.compile(loss='binary_crossentropy', optimizer = sgd1)\n\n# What will happen to the learnning rates under this decay schedule?\nlr = 5\nfor i in range(12):\n    lr = lr - lr * .15\n    print(lr)    "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"eeb7f99b-61fe-ea31-8c50-f5d8b62a85a8"},"outputs":[],"source":"autoencoder1.fit(training_inputs, training_inputs,\n                nb_epoch = 8, batch_size = 512,\n                validation_split = 0.30,\n                shuffle = True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ceb6f3aa-0364-76b1-7313-655064eee389"},"outputs":[],"source":"first_layer_code = encoder1.predict(training_inputs)\nprint(first_layer_code.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cc7abb88-27bd-bdc3-429e-26e5b321597c"},"outputs":[],"source":"autoencoder2.fit(first_layer_code, first_layer_code,\n                nb_epoch = 8, batch_size = 512,\n                validation_split = 0.25,\n                shuffle = True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"638391d5-20df-731f-9bb3-fe49e792f41c"},"outputs":[],"source":"#second_layer_code = encoder2.predict(first_layer_code)\n#print(second_layer_code.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e387eec3-8a45-e899-c592-21d430796bec"},"outputs":[],"source":"# Not enough time!!\n#autoencoder3.fit(second_layer_code, second_layer_code,\n#                nb_epoch = 8, batch_size = 512,\n#                validation_split = 0.30,\n#                shuffle = True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"782d2ad0-6825-404b-7591-197b88b0e7d2"},"outputs":[],"source":"# Setting the weights of the deep autoencoder\n#deep_autoencoder.layers[1].set_weights(autoencoder1.layers[2].get_weights()) # first dense layer\n#deep_autoencoder.layers[2].set_weights(autoencoder1.layers[3].get_weights()) # first bn layer\n#deep_autoencoder.layers[3].set_weights(autoencoder2.layers[2].get_weights()) # second dense layer\n#deep_autoencoder.layers[4].set_weights(autoencoder2.layers[3].get_weights()) # second bn layer\n#deep_autoencoder.layers[5].set_weights(autoencoder3.layers[2].get_weights()) # thrird dense layer\n#deep_autoencoder.layers[6].set_weights(autoencoder3.layers[3].get_weights()) # third bn layer\n#deep_autoencoder.layers[7].set_weights(autoencoder3.layers[4].get_weights()) # first decoder\n#deep_autoencoder.layers[8].set_weights(autoencoder2.layers[4].get_weights()) # second decoder\n#deep_autoencoder.layers[9].set_weights(autoencoder1.layers[4].get_weights()) # third decoder\n\n# Setting up the weights of the not-as-deep autoencoder\nnad_deep_autoencoder.layers[1].set_weights(autoencoder1.layers[2].get_weights()) # first dense layer\nnad_deep_autoencoder.layers[2].set_weights(autoencoder1.layers[3].get_weights()) # first bn layer\nnad_deep_autoencoder.layers[3].set_weights(autoencoder2.layers[2].get_weights()) # second dense layer\nnad_deep_autoencoder.layers[4].set_weights(autoencoder2.layers[3].get_weights()) # second bn layer\nnad_deep_autoencoder.layers[5].set_weights(autoencoder2.layers[4].get_weights()) # second decoder\nnad_deep_autoencoder.layers[6].set_weights(autoencoder1.layers[4].get_weights()) # third decoder"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8d3e7ea0-d13e-955e-64cd-5e108bfe1356"},"outputs":[],"source":"# you can see the degredation by uncommenting these one at a time and plotting\n#decoded_inputs = autoencoder1.predict(training_inputs[0:25, ])\ndecoded_inputs = nad_deep_autoencoder.predict(training_inputs[0:25,])\n#decoded_inputs = deep_autoencoder.predict(training_inputs[0:25,])\ndecoded_inputs.shape\n\nfig = plt.figure(figsize = (8, 8))\nfig.suptitle('Deep autoencoder reconstructions', fontsize=24, fontweight='bold')\n\nax1 = fig.add_subplot(231)\nplt.imshow(training_inputs[2].reshape(28, 28))\n\nax2 = fig.add_subplot(234)\nplt.imshow(decoded_inputs[2].reshape(28, 28))\n\nax3 = fig.add_subplot(232)\nplt.imshow(training_inputs[6].reshape(28, 28))\n\nax4 = fig.add_subplot(235)\nplt.imshow(decoded_inputs[6].reshape(28, 28))\n\nax5 = fig.add_subplot(233)\nplt.imshow(training_inputs[4].reshape(28, 28))\n\nax6 = fig.add_subplot(236)\nplt.imshow(decoded_inputs[4].reshape(28, 28))"},{"cell_type":"markdown","metadata":{"_cell_guid":"6423d112-d3db-3fea-6052-cb9c35747153"},"source":"## On to \"fine tuning\" for classification\nAlthough it will have to be more than fine tuning"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e63968e5-3bc2-9750-135e-1864bf6adef5"},"outputs":[],"source":"dense1 = Dense(500, activation = 'relu')(nad_decoded1_da)\ndense1_drop = Dropout(.3)(dense1)\n#dense1_bn = BatchNormalization()(dense1_drop)\ndense2 = Dense(10, activation = 'sigmoid')(dense1_drop)\n\nclassifier = Model(input = input_img, output = dense2)\nsgd4 = SGD(lr = .1, decay = 0.001, momentum = .95, nesterov = True)\nclassifier.compile(loss='categorical_crossentropy', optimizer = sgd4, metrics=['accuracy'])\n   \nclassifier.fit(training_inputs, training_targets,\n                nb_epoch = 6, batch_size = 600,\n                validation_split = 0.25,\n                shuffle = True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"809bac5f-e50c-09e5-3a0d-96d7cbefdcde"},"outputs":[],"source":"val_preds = classifier.predict(val_inputs)\npredictions = np.argmax(val_preds, axis = 1)\ntrue_digits = np.argmax(val_targets, axis = 1)\npredictions[0:25]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"38ef26e9-8c92-d396-ebbc-592e410e81f9"},"outputs":[],"source":"n_correct = np.sum(np.equal(predictions, true_digits).astype(int))\ntotal = float(len(predictions))\nprint(\"Validation Accuracy:\", round(n_correct / total, 3))"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}