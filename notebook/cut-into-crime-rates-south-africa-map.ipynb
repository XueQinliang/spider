{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"615e6bb8-6bb6-e0bf-22ab-ef923d4af186"},"source":"**Cut into crime rates (South Africa)**\n---------------------------------------\n\n**Ievgen Potapenko**,\nOctober-November 2016"},{"cell_type":"markdown","metadata":{"_cell_guid":"b0815e55-0cf9-e8f2-73ec-e4c81eea8329"},"source":"This notebook shows trend visualization for each crime category in the shape of 12 plots per each category:\n\n - Middle left plot shows nationwide dynamic. Also its title contains crime category for all 12 plots.\n - Middle right plot shows distribution of police stations with positive and negative trends.      \n - Upper five plots present five police station with best trends (decrease in crime rates per period)\n - Lower five plots present worst performing police stations (increase in crime rates per period).\n\nTrends were calculated by fitting time series into np.polyfit function(first order polynom was applied).\n\nAlso I've made judgmental allocation of crime categories to three severity groups (1st is worst, 3d is mildest). Severity is based on physical and/or psychological damage (potential damage) suffered by a person(s) from crime encounter.\n\nFor purpose of the notebook I added only most severe crimes. It can be easily change to produce charts for all categories."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c030d3ab-f6c9-1e7e-076b-c3beee0e3509"},"outputs":[],"source":"import numpy as np \nimport pandas as pd \nimport matplotlib as mpl\nfrom matplotlib import gridspec\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nimport seaborn as sns\nsns.set_style({'xtick.major.size': 0.5, 'ytick.major.size': 0.5})\nsns.set_context(\"paper\")\nmpl.rcParams['ytick.labelsize'] = 10\nmpl.rcParams['xtick.labelsize'] = 10\n\n# Import dataset ------------------------------------------------------------------- #\ndf = pd.read_csv('../input/SouthAfricaCrimeStats_v2.csv')\nsev_cat = ['Burglary at non-residential premises', 'Malicious damage to property',\n           'Theft of motor vehicle and motorcycle', 'Carjacking', 'Attempted murder',\n           'Burglary at residential premises', 'All theft not mentioned elsewhere',\n           'Murder', 'Common assault', 'Truck hijacking',\n           'Assault with the intent to inflict grievous bodily harm', 'Bank robbery',\n           'Stock-theft', 'Robbery at non-residential premises',\n           'Robbery with aggravating circumstances',\n           'Driving under the influence of alcohol or drugs',\n           'Theft out of or from motor vehicle', 'Drug-related crime',\n           'Illegal possession of firearms and ammunition', 'Arson',\n           'Robbery of cash in transit', 'Common robbery',\n           'Robbery at residential premises',\n           'Sexual offences as result of police action', 'Commercial crime',\n           'Sexual Offences', 'Shoplifting']\nsev_rate = [3, 3, 3, 3, 1, 3, 3, 1, 2, 3, 1, 2, 3, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 1, 3, 1, 3]\nsev_df = pd.DataFrame({'Category':sev_cat, 'Severity':sev_rate})\ndf = df.merge(sev_df)\ncategory_list = sorted(df['Category'].unique())\nheadings = list(df)\nyears = headings[3:-1]\n\n# Identifying slope for each crime category (nationwide) ------------------------------------------------------------------- #\ndf_cat_sum = df[['Category']+years].groupby('Category').sum()\ndf_cat_sum_T = df_cat_sum.transpose()\nslope_list = []\nfor i in category_list:\n    coeff, residual = np.polyfit(range(0,len(years),1),df_cat_sum_T[i],1)\n    slope_list+=[coeff]\ndf_cat_sum['Slope'] = slope_list\n\n# Station appearance dictionary ------------------------------------------------------------------- #\ndf_station_sum = df[['Station']+years].groupby('Station').sum().reset_index()\nst_list = sorted(df_station_sum['Station'].tolist())\nstation_appearance = {}\nfor x in st_list:\n    index = np.nonzero(df_station_sum.loc[df_station_sum['Station']==x, years].values.flatten())[0][0]\n    station_appearance[x]=index\n\nst_list_new = []\nfor x in st_list:\n    if station_appearance[x]==10:\n        st_list_new += [x]\n    else:\n        st_list_new\n\n# Get lists of crimes categories by severity ------------------------------------------------------------------- #\nsev1 = sev_df.loc[sev_df['Severity']==1, \"Category\"].tolist()\nsev2 = sev_df.loc[sev_df['Severity']==2, \"Category\"].tolist()\nsev3 = sev_df.loc[sev_df['Severity']==3, \"Category\"].tolist()\n\n# Visualization code ------------------------------------------------------------------- #\nfor i in sev1: # may be changed to \"category_list\" to include all crime categories\n    # dynamic of specific crime category by police stations\n    df_cat_station = df.loc[df['Category']==i,:]\n    station_slope_list = []\n    station_residual_list = []\n    for n in st_list:\n        if n not in st_list_new:\n            coeff, residual = np.polyfit(range(station_appearance[n],len(years),1),df_cat_station.loc[df_cat_station['Station']==n,years[station_appearance[n]:]].values.flatten(),1)\n        else:\n            coeff, residual = 0,0\n        station_slope_list+=[coeff] # fill in slope coefficient list\n        station_residual_list+=[residual] # fill in residual list\n    df_cat_station=df_cat_station.sort_values('Station',ascending=True)\n    df_cat_station['Slope'] = station_slope_list # add slope to dataframe\n    df_cat_station['Residual'] = station_residual_list # add residual to dataframe\n    df_stat_asc = df_cat_station.sort_values('Slope', ascending=True)\n    pd.DataFrame.to_csv(df_stat_asc,i+'.csv', index=None)\n\n    # graph of country scale dynamic of specific crime category\n    coeff_i, residual_i = np.polyfit(range(0,len(years),1),df_cat_sum_T[i],1)\n    trend_line = [coeff_i*x + residual_i for x in range(df_cat_sum_T[i].shape[0])]\n    x_pos = np.arange(len(years))\n    crime_instances = df_cat_sum_T[i]\n    fig = plt.figure(figsize=(20, 8))\n    gs = gridspec.GridSpec(3, 5)\n    ax1 = plt.subplot(gs[1,0:3])\n    ax1.plot(x_pos, trend_line, color='red', linestyle='--')\n    ax1.bar(x_pos, crime_instances, color = 'blue', alpha=0.7, align='center')\n    ax1.set_xticks(x_pos)\n    ax1.set_xticklabels(years, rotation=45)\n    ax1.get_yaxis().set_major_formatter(mpl.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n    ax1.set_ylabel('Crimes per period', size='large')\n    ax1.set_title(i+' (nationwide statistics)', fontsize=16, fontweight='bold')\n    ax1.set_ylim(ymin=0)\n    ax2 = plt.subplot(gs[1,3:])\n    ax2.hist(df_stat_asc.loc[df_stat_asc['Slope']<=0, 'Slope'],30, normed=1, histtype='stepfilled', color='red', alpha=0.8)\n    ax2.hist(df_stat_asc.loc[df_stat_asc['Slope']>0, 'Slope'],30, normed=1, histtype='stepfilled', color='green', alpha=0.8)\n    #ax2.spines['left'].set_position('zero')\n    ax2.set_title(\"Trend dynamics for all police stations\", fontsize=12, fontweight='bold')\n    ax2.set_ylabel('Quantity of stations', size='large')\n    ax2.set_xlabel('Negative/Positive slope', size='large')\n    \n\n    # set graphs of best performing police stations\n    bsl = df_stat_asc[0:5]['Station'].tolist() # list of stations with best trend\n    \n    ax3 = plt.subplot(gs[0,0])\n    ax4 = plt.subplot(gs[0,1])\n    ax5 = plt.subplot(gs[0,2])\n    ax6 = plt.subplot(gs[0,3])\n    ax7 = plt.subplot(gs[0,4])\n\n    dict_bs = {0:ax3, 1:ax4, 2:ax5, 3:ax6, 4:ax7}\n\n    for m in range(0,5):    \n        dict_bs[m] = plt.subplot(gs[0,m])\n        trend_line_bs = [df_stat_asc.loc[df_stat_asc['Station']== bsl[m], 'Slope'].values*x \n                         + df_stat_asc.loc[df_stat_asc['Station']== bsl[m], 'Residual'].values \n                         for x in range(station_appearance[bsl[m]],len(years),1)] # trend line for selected station\n        crime_instances_bs = df_stat_asc.loc[df_stat_asc['Station'] == bsl[m], years[station_appearance[bsl[m]]:]].values.flatten().tolist()\n        x_pos_bs = np.arange(len(years[station_appearance[bsl[m]]:]))\n        dict_bs[m].plot(x_pos_bs, trend_line_bs, color='red', linestyle='--')\n        dict_bs[m].bar(x_pos_bs, crime_instances_bs, align='center', color = 'green', alpha=0.7)\n        dict_bs[m].set_xticks(x_pos_bs)\n        dict_bs[m].set_xticklabels(['05-06','06-07','07-08','08-09','09-10','10-11','11-12','12-13','13-14','14-15','15-16'], fontsize=10, rotation=45)\n        dict_bs[m].get_yaxis().set_major_formatter(mpl.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n        dict_bs[m].set_ylabel('Crimes per period', size='large')\n        dict_bs[m].set_ylim(ymin=0)\n        title = ', '.join(df_stat_asc.loc[df_stat_asc['Station']== bsl[m], ['Station','Province']].values.flatten().tolist())\n        dict_bs[m].set_title(title, fontsize=12, fontweight='bold')\n\n\n    # set graphs of worst performing police stations\n    wsl = df_stat_asc[-5:]['Station'].tolist() # list of stations with worst trend\n    \n    ax8 = plt.subplot(gs[2,0])\n    ax9 = plt.subplot(gs[2,1])\n    ax10 = plt.subplot(gs[2,2])\n    ax11 = plt.subplot(gs[2,3])\n    ax12 = plt.subplot(gs[2,4])\n\n    dict_ws = {0:ax8, 1:ax9, 2:ax10, 3:ax11, 4:ax12}\n\n    for m in range(0,5):    \n        dict_ws[m] = plt.subplot(gs[2,m])\n        trend_line_ws = [df_stat_asc.loc[df_stat_asc['Station']== wsl[m], 'Slope'].values*x \n                         + df_stat_asc.loc[df_stat_asc['Station']== wsl[m], 'Residual'].values \n                         for x in range(station_appearance[wsl[m]],len(years),1)] # trend line for selected station\n        crime_instances_ws = df_stat_asc.loc[df_stat_asc['Station'] == wsl[m], years[station_appearance[wsl[m]]:]].values.flatten().tolist()\n        x_pos_ws = np.arange(len(years[station_appearance[wsl[m]]:]))\n        dict_ws[m].plot(x_pos_ws, trend_line_ws, color='black', linestyle='--')\n        dict_ws[m].bar(x_pos_ws, crime_instances_ws, align='center', color = 'red', alpha = 0.7)\n        dict_ws[m].set_xticks(x_pos_ws)\n        dict_ws[m].set_xticklabels(['05-06','06-07','07-08','08-09','09-10','10-11','11-12','12-13','13-14','14-15','15-16'], fontsize=10, rotation=45)\n        dict_ws[m].get_yaxis().set_major_formatter(mpl.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n        dict_ws[m].set_ylabel('Crimes per period', size='large')\n        dict_ws[m].set_ylim(ymin=0)\n        title = ', '.join(df_stat_asc.loc[df_stat_asc['Station']== wsl[m], ['Station','Province']].values.flatten().tolist())\n        dict_ws[m].set_title(title, fontsize=12, fontweight='bold')\n    plt.tight_layout()\n    plt.show()\n    print ('--------------------------------------------------------------------------')\n    print ('--------------------------------------------------------------------------') "},{"cell_type":"markdown","metadata":{"_cell_guid":"558db910-64f6-cb06-e77d-0c9c9fd78595"},"source":"Some of the police stations existed for few years only. The visualization was adjusted accordingly. But there is an issue with crime category that seems to be included in statistics only recently ('Sexual offences as the result of police actions'). From charts above it seems there was none of these before 2011, but it is more likely because of data absence. I am going to check this issue and amend the code if needed.\n\n----------\n\nWhy data for best/worst stations matters? Here are my thoughts:\n\nGood dynamic can be caused by:\n\n - Real improvement (decrease) in crime rates. In this case practice of best stations should be used in nation scale.\n - Statistical data is manipulated. Significant decreases, same rates each year and other strange data pattern may show there is a problem with the data on its way from initial crime record to national statistical records.\n - Crimes occur but are not registered. Spikes with following decreases may be an indicators.\n\nBad dynamic:\n\n - May appear because fair representation of crimes started from some point within 2005-2016.\n - Situation deteriorates and require staff changes/rotation/training/reinforcement and/or additional investments in police station infrastructure.\n\nAlso code produce \".csv\" files for each visualized category. Files contain database of stations sorted from best to worst. Thus deeper analysis can be made not only for the best/worst 5 stations.\n\n----------\n\nThis approach may have value only if police stations have significant freedom in self-management. If South Africa has strictly centralized police system then analysis by region is more appropriate."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4be9c582-b396-1c77-e49e-5dd299b6a2a4"},"outputs":[],"source":"import matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom matplotlib import gridspec\nfrom matplotlib.patches import Polygon\nfrom matplotlib.collections import PatchCollection\nfrom mpl_toolkits.basemap import Basemap\nimport shapefile as shp\n\n\n# Making SA crime heat map ------------------------------------------------------------------- #\n# Dataframe with crimes weighted by severity and time lapse\ndf_WS = df.copy()\nstation_l = [key for key in station_appearance]\nappearance_l = [station_appearance[key] for key in station_appearance]\nsa_df = pd.DataFrame({'Station':station_l, 'Years_active':appearance_l})\nsa_df['Years_active'] = sa_df['Years_active']*(-1)+11\npd.DataFrame.to_csv(sa_df,'sa_df.csv', index=None)\ndf_WS = df_WS.merge(sa_df)\npd.DataFrame.to_csv(df_WS,'df_WS.csv', index=None)\ntime_apathy_list = [0.7, 0.7, 0.7, 0.8, 0.8, 0.8, 0.9, 0.9, 1, 1, 1] # judgmental decreasing coefficients\nn=0\nfor i in years:\n    df_WS[i] = df_WS[i]/df_WS['Severity']/df_WS['Years_active']*time_apathy_list[n]\n    n+=1\ndf_WS['Crimes_11years'] = df_WS[years].sum(axis=1).apply(np.round)\ndf_WS = df_WS.drop(years, axis=1)\ndf_WS['Station'] = df_WS['Station'].str.upper()\ndf_WS_st = df_WS[['Station','Crimes_11years']].groupby('Station').sum() #as_index=False - may be an issue\npd.DataFrame.to_csv(df_WS,'df_WS_st.csv', index=None)\n\n# Create colormap (http://ramiro.org/notebook/basemap-choropleth/)\nnum_colors = 20\nvalues = df_WS_st['Crimes_11years'].values\ncm = plt.get_cmap('Reds')\nscheme = [cm(q/num_colors) for q in range(num_colors)]\nbins = np.linspace(values.min(), values.max(), num_colors)\ndf_WS_st['bin'] = np.digitize(values, bins) - 1\ndf_WS_st.sort_values('bin', ascending=False)\n\n# Read the shapefile (https://pypi.python.org/pypi/pyshp/, http://gis.stackexchange.com/questions/145015/is-it-possible-to-look-at-the-contents-of-shapefile-using-python-without-an-arcm)\nreader = shp.Reader('../input/Police_bounds')\n'''\nprint dict((d[0],d[1:]) for d in reader.fields[1:])\n{'DIP_DIR': ['N', 3, 0], 'DIP': ['N', 2, 0], 'TYPE': ['C', 10, 0]}\nfields = [field[0] for field in reader.fields[1:]]\nfor feature in reader.shapeRecords():\n    geom = feature.shape.__geo_interface__\n    atr = dict(zip(fields, feature.record))\n    print geom, atr\n''' # This produce lots of dictionary. Searching by name of any station it is possible to find that key for stations in any dictionary is 'COMPNT_NM'.\n\n\n# Thanks to these resources http://spatialreference.org/ref/esri/102024/, http://matplotlib.org/basemap/api/basemap_api.html\nfig = plt.figure(figsize=(22, 12))\n\nax = fig.add_subplot(111, axisbg='w', frame_on=False)\nfig.suptitle('South African crime rates map by police stations', fontsize=20, y=.95)\n\nm = Basemap(width=3000000,height=2000000,projection='lcc', resolution=None,lat_1=-32.,lat_2=-26,lat_0=-29,lon_0=24.7) \nm.shadedrelief()\nm.readshapefile('../input/Police_bounds', 'station', color='#444444', linewidth=.0000001)\n\nfor info, shape in zip(m.station_info, m.station):\n    name = info['COMPNT_NM']\n    if name not in df_WS_st.index:\n        color = '#dddddd'\n    else:\n        color = scheme[df_WS_st.ix[name]['bin'].astype(int)]\n\n    patches = [Polygon(np.array(shape), True)]\n    pc = PatchCollection(patches)\n    pc.set_facecolor(color)\n    ax.add_collection(pc)\n\nax_legend = fig.add_axes([0.25, 0.17, 0.5, 0.05])\ncmap = mpl.colors.ListedColormap(scheme)\ncb = mpl.colorbar.ColorbarBase(ax_legend, cmap=cmap, ticks=bins, boundaries=bins, orientation='horizontal')\ncb.ax.set_xticklabels([str(round(i)) for i in bins])\n\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"dbf7a384-acaf-373e-e24b-48c6c56282b6"},"source":"The map presents overall crime situation in South Africa. This is not just average data for 11 years. Following changes were made:\n\n 1. As was explained above I divided all crime categories for 3 groups. It was done because overall crime situation is much worse in case of heavy crimes. Being robbed is annoying but being murdered means game is over. Thus each crime stats was divided by its severity group. (Thus murder is divided by 1 and shoplifting is divided by 3).\n 2. Judgmental time decreasing coefficients were applied. Last 3 years have no diminishing factor, earlier periods have coefficient from 0.9 to 0.7. \n 3. Each crime rate per period was divided by number of years that specific police station operates.\n\nAfter amendments were done crime rates were summed by police stations. Then with help of many tutorials results were projected on map. It looks very similar to population density map (which is logical). You can find one on Wiki: https://en.wikipedia.org/wiki/South_Africa#/media/File:South_Africa_2011_population_density_map.svg\n\nAny comments and suggestions are welcomed. Also, thanks to KostyaBahshetsyan - his code helped a lot in many subtle details during this map plotting."}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}