{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"5e40d8a0-2148-6117-75c2-8c95967c1ef9"},"source":"# Scout Script\n\nWe scout out this dataset. Namely performing the following on it:\n\n-  WordCloud generation\n-  Topic Modeling\n-  Joke length plots\n-  Joke structure estimation\n\nFirst off we import some common tools"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"db4708a5-d638-7e7d-fcd1-c4375a91771a"},"outputs":[],"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\n%pylab inline\nfrom textblob import TextBlob\nfrom wordcloud import WordCloud\nimport sklearn\n# assert sklearn.__version__ == '0.18' # Make sure we are in the modern age\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom gensim.models import Word2Vec\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8a1810c0-972f-d577-0744-07a092422342"},"outputs":[],"source":"df = pd.read_csv('../input/jokes.csv')\ndf.info()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d599af85-bc27-91e3-8b42-c3fcb3f4207c"},"outputs":[],"source":"df.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"2b98d144-69f8-6593-5217-5173ff510b88"},"source":"## WordCloud!\n\nA word cloud of all the text present."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"57ba54b4-de11-8867-af33-652c61352f02"},"outputs":[],"source":"text = ' '.join(df.Question)\ncloud = WordCloud(background_color='white', width=1920, height=1080).generate(text)\nplt.figure(figsize=(32, 18))\nplt.axis('off')\nplt.imshow(cloud)\nplt.savefig('questions_wordcloud.png')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"24f82c2f-c62e-bc2e-76ab-9804170ef427"},"outputs":[],"source":"text = ' '.join(df.Answer)\ncloud = WordCloud(background_color='white', width=1920, height=1080).generate(text)\nplt.figure(figsize=(32, 18))\nplt.axis('off')\nplt.imshow(cloud)\nplt.savefig('answer_wordcloud.png')"},{"cell_type":"markdown","metadata":{"_cell_guid":"1b23f723-138a-e21b-f171-afcc2b1fbedc"},"source":"## Topic Models\n\nAs with any self respecting analysis on unlabeled text data, we perform some topic modeling here with Non Negative Matrix Factorization on the questions.\n\nThis lets us know about the different kinds of question joke categories."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1faac27b-1738-2380-81c0-de418bec37a3"},"outputs":[],"source":"# Some defaults\nmax_features=1000\nmax_df=0.95,  \nmin_df=2,\nmax_features=1000,\nstop_words='english'\n\nfrom nltk.corpus import stopwords\nstop = stopwords.words('english')\n\n# document-term matrix A\nvectorized = CountVectorizer(max_features=1000, max_df=0.95, min_df=2, stop_words='english')\n\na = vectorized.fit_transform(df.Question)\na.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"11ecde6b-c1e5-ef9d-6843-f51bf334ea1d"},"outputs":[],"source":"from sklearn.decomposition import NMF\nmodel = NMF(init=\"nndsvd\",\n            n_components=10,\n            max_iter=200)\n\n# Get W and H, the factors\nW = model.fit_transform(a)\nH = model.components_\n\nprint(\"W:\", W.shape)\nprint(\"H:\", H.shape)"},{"cell_type":"markdown","metadata":{"_cell_guid":"8ffaf679-e7a1-8e83-7a3c-c87d0a9dcfe4"},"source":"Get the list of all terms whose indices correspond to the columns of the document-term matrix."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9b45ff75-d682-2f6a-2225-c67f4a1d0b71"},"outputs":[],"source":"vectorizer = vectorized\n\nterms = [\"\"] * len(vectorizer.vocabulary_)\nfor term in vectorizer.vocabulary_.keys():\n    terms[vectorizer.vocabulary_[term]] = term\n    \n# Have a look that some of the terms\nterms[-5:]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"97da7c5b-787b-a0f8-8a09-17397517d5f8"},"outputs":[],"source":"for topic_index in range(H.shape[0]):  # H.shape[0] is k\n    top_indices = np.argsort(H[topic_index,:])[::-1][0:10]\n    term_ranking = [terms[i] for i in top_indices]\n    print(\"Topic {}: {}\".format(topic_index, \", \".join(term_ranking)))"},{"cell_type":"markdown","metadata":{"_cell_guid":"c956717b-4ad1-497a-b005-be5b04071764"},"source":"We can see some popular types of question jokes in there. To name a few that I have heard:\n\n- Cross the road\n- Change a lightbulb\n- What's the difference b/w A and B\n- My favourite joke"},{"cell_type":"markdown","metadata":{"_cell_guid":"de7b7756-6f25-eb6e-c699-47a272cb1494"},"source":"## Sentiment Analysis\n\nWe assign sentiment scores to the questions and answers."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c27d80ff-b320-ba3a-6e24-1c39721b3bcf"},"outputs":[],"source":"get_polarity = lambda x: TextBlob(x).sentiment.polarity\nget_subjectivity = lambda x: TextBlob(x).sentiment.subjectivity\n\ndf['q_polarity'] = df.Question.apply(get_polarity)\ndf['a_polarity'] = df.Answer.apply(get_polarity)\ndf['q_subjectivity'] = df.Question.apply(get_subjectivity)\ndf['a_subjectivity'] = df.Answer.apply(get_subjectivity)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"75a51240-0eb2-0e7b-38bd-9ea313efb176"},"outputs":[],"source":"plt.figure(figsize=(7, 4))\nsns.distplot(df.q_polarity , label='Question Polarity')\nsns.distplot(df.q_subjectivity , label='Question Subjectivity')\nsns.distplot(df.a_polarity , label='Answer Polarity')\nsns.distplot(df.a_subjectivity , label='Answer Subjectivity')\nsns.plt.legend()"},{"cell_type":"markdown","metadata":{"_cell_guid":"ccdb13c5-a612-c62a-2257-3fd08b0c9a3c"},"source":"Perhaps it's a joke is good if the sentiment changes while answering the question? Sadly there's no way to answer that because of the lack of a joke score/ upvote feature in this version of the dataset.\n\n# About the jokes themselves\n\nWhat can we say about the jokes themselves? Let's take a look at length first."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d1c34eef-736c-3945-ce9b-f728c4f93eab"},"outputs":[],"source":"daf = df.loc[df.Answer.str.len() < 150]  # There appear to be some outliers in the dataset\nsns.distplot(daf.Question.str.len(), label='Question Length')\nsns.distplot(daf.Answer.str.len(), label='Answer Length')\nsns.plt.legend()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6e0c44b3-42ba-ae33-36ab-ba0ee7b86d4e"},"outputs":[],"source":"# What are the outliers though?\n# The threshold has been chosen to keep in the spirit of the dataset\ndf.loc[df.Answer.str.len() > 400].shape[0]"},{"cell_type":"markdown","metadata":{"_cell_guid":"08d6edff-57ce-5a86-150b-a644a2a4e5e6"},"source":"We know that the answers are usually shorter than questions. Are there questions whose answers are shorter than them? What about the reverse?"},{"cell_type":"markdown","metadata":{"_cell_guid":"a6da98db-24b6-7fbe-a8bb-19b180f630e7"},"source":"Similar results hold. A better comparison of question length vs answer length would be a scatter plot. So far we have plotted the difference but what that loses is the exact lengths of the Q and A. 500 - 550 is the same as 10 - 60"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7765ca9e-e33b-8946-a51f-194251a5d5be"},"outputs":[],"source":"ql, al = 'Question Length', 'Answer Length'\ndf[ql] = df.Question.str.len()\ndf[al] = df.Answer.str.len()\ndaf = df.loc[df[al] < 250]\nsns.jointplot(x=ql, y=al, data=daf, kind='kde', space=0, color='g')"},{"cell_type":"markdown","metadata":{"_cell_guid":"dae61f60-7c87-ce91-e363-b1d69add9d90"},"source":"## Can we find structure in the jokes?\n\n[A paper](http://maroo.cs.umass.edu/getpdf.php?id=835) caught my eye. The next iteration of this script will be trying to follow that."}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}