{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"c36198e4-d422-213e-a222-db2c6bb16f16"},"source":"**DISCLAIMER:** This notebook will not help you better understand the competition. Kaggle Admin William Cukierski has already mentioned that they do not like it when people use this approach to gain a high leaderboard score. This creates confusion for outsiders and discourages new ML'ers from participating. Please, don't submit a perfect submission to the leaderboard. This notebook is for educational purposes only."},{"cell_type":"markdown","metadata":{"_cell_guid":"a1f95f31-dc9d-c73b-3824-b83dafde9d67"},"source":"Extracting knowledge using leaderboard submissions\n=========================================\nIn most Kaggle competitions, the test set is split into a public and private part. Scores reported on the leaderboard are based solely on the public part, meaning that it is not possible to obtain information about your performance on the data in the private part. This has the added effect that a perfect score on the leaderboard means you have created the perfect model. In the Data Science Bowl 2017, however, the test set is only small and the leaderboard score is determined on this whole test set. Final performance is based on a data set that will become available further into the competition. The combination of test set size and the reported scores being based on all of it mean that it is possible to find the labels of the cases in the test set. This is where [Oleg Trott](https://www.kaggle.com/olegtrott) comes in. He has obtained the number 1 spot on the leaderboard with a perfect log-loss of 0.00000 ([his post about this](https://www.kaggle.com/c/data-science-bowl-2017/forums/t/27800/my-perfect-score)).  His post sparked my interest and together with [Mark](https://markv.nl/blag/efficient-overfitting-of-training-data-kaggle-bowl) I thought of a way to accomplish the same. Let's get started!"},{"cell_type":"markdown","metadata":{"_cell_guid":"9704a416-2d1f-0e46-cb9e-38f47af158d6"},"source":"These imports speak for themselves."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a5ce4e77-0d07-3d6c-274b-e302c5eb9680"},"outputs":[],"source":"import numpy as np\nfrom sklearn.metrics import log_loss"},{"cell_type":"markdown","metadata":{"_cell_guid":"213aa4fa-7682-64f5-f326-a82fdadb4929"},"source":"Of course, we need to test our program on a list of \"true values\". Since we don't have access to the true test set labels (yet), we'll generate our own truth."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79de5319-c0c3-1641-2409-ef46e832d0d6"},"outputs":[],"source":"N = 198\ny_true = np.random.randint(2, size=N)"},{"cell_type":"markdown","metadata":{"_cell_guid":"10564628-d4b5-baeb-3fe9-7d7281048d44"},"source":"These functions are used to calculate the performance of our 'predictions' at this competitions metric: the logarithmic loss."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c01dae9d-1b2f-82d6-3b3c-db0d0f240873"},"outputs":[],"source":"def score_submission(pred, true):\n    pred = [np.max(np.min(x, 1-10**(-15)), 10**(-15)) for x in pred]\n    return log_loss(true, pred, labels=[0,1])\n\ndef score_val(val, true):\n    val = np.max(np.min(val, 1-10**(-15)), 10**(-15))\n    return log_loss([true], [val], labels=[0,1])"},{"cell_type":"markdown","metadata":{"_cell_guid":"c122614c-b1d4-2d2c-456f-e79df83fd00a"},"source":"The function `make_predict_at` is what we will use to generate the values in our submission. We will extract the labels for several samples at a time and is set with `n_predicts`. How many we can do at the same time depends on the amount of information we get from the leaderboard response and the maximal contribution of a single value. \n\nLets have a look at the edge cases, in which we are extremely certain about our predictions (0.0 or 1.0) and either wrong or right: "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6b69bada-5b9a-1c87-493c-6e87b4d6c35f"},"outputs":[],"source":"print(\"Correct:\", score_val(1,1)/N)\nprint(\"Wrong:\", score_val(1,0)/N)"},{"cell_type":"markdown","metadata":{"_cell_guid":"5d4b6a39-efe4-6c17-3bae-a34db2e9742b"},"source":"Kaggle returns the score rounded to 5 digits, meaning that the contribution of a single value to the log-loss lies in the range of [0.00000, 0.17444]. We want to be able to separate the score into contributions from each value, for which we will have 17445 values available (since we could increment by 0.00001 and still see how it changes the score). This is equivalent to ~14 bits of information, each of which we will use to keep a single value separate from the others.\n\nThe exponent in the predicted values cancels out the logarithm in the log-loss score, making it easier to work with the score in the next part."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bf31a747-2062-fbc3-be6f-716a03be2389"},"outputs":[],"source":"n_predicts = 15\ndef make_predict_at(n, n_predicts=10, N=N):\n    pred = np.ones(N)*0.5 \n    for i in range(n, n+n_predicts):\n        pred[i] = np.exp(-0.5**(i+2))\n    return pred"},{"cell_type":"markdown","metadata":{"_cell_guid":"2d21acd5-7208-8795-23d1-057f506ac9e8"},"source":"I removed the contribution of all 0.5's and multiplied by the number of values in the test set to get just the sum of logarithms."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1936058c-dfb2-0831-7cdf-e71fad29572f"},"outputs":[],"source":"pred = make_predict_at(0, n_predicts=n_predicts)\nscore = score_submission(pred, y_true)\nscore = score*198 - score_val(0.5, 0)*(198-n_predicts)"},{"cell_type":"markdown","metadata":{"_cell_guid":"50eb4c99-f882-b176-0dd4-692dcff7ff23"},"source":"The nested for-loops below calculates every possible score way that our predicted values can produce and keeps track of which sum is built out of either a 'correct' or 'wrong'. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"18537a97-d015-b262-40b1-f45bbaba771f"},"outputs":[],"source":"sums = [[0]]\ntrack_sum = [[]]\nfor i in range(n_predicts):\n    old_sums = sums\n    old_track = track_sum\n    sums = []\n    track_sum = []\n    for s,t in zip(old_sums, old_track):\n        sums.append(s-np.log(pred[i]))\n        sums.append(s-np.log(1-pred[i]))\n        \n        track_sum.append(t+[1])\n        track_sum.append(t+[0])"},{"cell_type":"markdown","metadata":{"_cell_guid":"5f272801-201a-99b5-8538-b4ee02bae4e7"},"source":"Calculating the absolute difference between the possible sums and the score we retrieved and sorting means that we will find our labels in the first entry of `sorted_sum`!"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a367b19c-ce47-a776-f1a4-d776c1273500"},"outputs":[],"source":"diff_sums = np.abs(sums-score)\nsorted_sum = sorted(zip(diff_sums, track_sum))\n\nprint(sorted_sum[0][1])\nprint(list(y_true[:n_predicts]))"},{"cell_type":"markdown","metadata":{"_cell_guid":"1fe04eba-6aac-be1c-83fd-4aba7f5fe270"},"source":"The code below repeats it 10 times, if you are not confident that this isn't a lucky shot ;)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"32156065-00a0-fe10-7e35-7105254080b6"},"outputs":[],"source":"for test_n in range(10):\n    y_true = np.random.randint(2, size=N)\n    \n    pred = make_predict_at(0, n_predicts=n_predicts)\n    score = score_submission(pred, y_true)\n    score = score*198 - score_val(0.5, 0)*(198-n_predicts)\n\n    sums = [[0]]\n    track_sum = [[]]\n    for i in range(n_predicts):\n        old_sums = sums\n        old_track = track_sum\n        sums = []\n        track_sum = []\n        for s,t in zip(old_sums, old_track):\n            sums.append(s-np.log(pred[i]))\n            sums.append(s-np.log(1-pred[i]))\n\n            track_sum.append(t+[1])\n            track_sum.append(t+[0])\n     \n    diff_sums = np.abs(sums-score)\n    sorted_sum = sorted(zip(diff_sums, track_sum))\n \n    print(test_n)\n    print(sorted_sum[0][1])\n    print(list(y_true[:n_predicts]))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6b97fbc4-0b1e-0abc-cf7d-b874ca5e0bec"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}