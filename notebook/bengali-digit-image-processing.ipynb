{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"_is_fork":false,"_change_revision":0,"language_info":{"version":"3.6.1","pygments_lexer":"ipython3","codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python","file_extension":".py","nbconvert_exporter":"python","name":"python"}},"nbformat_minor":0,"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"c8a717b8-f746-6a90-9520-c20228acaefa","_uuid":"5a3e5b52f4bf7980807bd54a2620c4f33eb98bc7"},"outputs":[],"source":"# INTRODUCTION\n\nThis notebook aims to take you through the basics of image processing - colormap schemes, image filtering and feature/edge detection","execution_count":null},{"cell_type":"code","metadata":{"_cell_guid":"a585eaa4-10ce-cec0-84ff-526a6a1cabb9","_uuid":"067a9b37afe5c97e837ac629b89b334e83136fe5","trusted":false},"outputs":[],"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport scipy.ndimage \nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nimport glob\nimport zipfile","execution_count":null},{"cell_type":"code","metadata":{"_cell_guid":"2983c6f9-d7d1-9681-604a-08a2aa5f10a6","_uuid":"76bb6076808459c140f2d9d9d1104f2e5c90d0a2","trusted":false},"outputs":[],"source":"import skimage","execution_count":null},{"cell_type":"markdown","metadata":{"_cell_guid":"7ab84061-cb1a-c0e1-84b6-ef789f3ca71b","_uuid":"03b153ef5364ce7e6e47a06643a077189fa30ba8"},"outputs":[],"source":"Let's take a look at what's in the data. To do this, we utilise the glob module and its associated method to help us read directly from the zip file. Furthermore since there are too many images in the zip file to extract all ( I tried and it cause an error in the notebook), I will look at only the first 25 images in the set as follows:","execution_count":null},{"cell_type":"code","metadata":{"_cell_guid":"e2a74a92-249f-2f0d-f8c2-744e9c84f9fa","_uuid":"0cc017b5c782b8602030177bd14696880f80cefb","trusted":false},"outputs":[],"source":"18# Create a new list to hold the names of the first 25 jpg images\nfilelist = ['BDRW_train_1/digit_0.jpg',\n 'BDRW_train_1/digit_1.jpg',\n 'BDRW_train_1/digit_10.jpg',\n 'BDRW_train_1/digit_100.jpg',\n 'BDRW_train_1/digit_1000.jpg',\n 'BDRW_train_1/digit_1001.jpg',\n 'BDRW_train_1/digit_1002.jpg',\n 'BDRW_train_1/digit_1003.jpg',\n 'BDRW_train_1/digit_1005.jpg',\n 'BDRW_train_1/digit_1006.jpg',\n 'BDRW_train_1/digit_1007.jpg',\n 'BDRW_train_1/digit_1008.jpg',\n 'BDRW_train_1/digit_1009.jpg',\n 'BDRW_train_1/digit_101.jpg',\n 'BDRW_train_1/digit_1011.jpg',\n 'BDRW_train_1/digit_1012.jpg',\n 'BDRW_train_1/digit_1013.jpg',\n 'BDRW_train_1/digit_1014.jpg',\n 'BDRW_train_1/digit_1015.jpg',\n 'BDRW_train_1/digit_1016.jpg',\n 'BDRW_train_1/digit_1017.jpg',\n 'BDRW_train_1/digit_1018.jpg',\n 'BDRW_train_1/digit_102.jpg',\n 'BDRW_train_1/digit_1020.jpg',\n 'BDRW_train_1/digit_1021.jpg']","execution_count":null},{"cell_type":"code","metadata":{"_cell_guid":"e9bf655e-72ed-efc4-28c7-4fc715d04fff","_uuid":"dc19df275ab6aa32c9ec4962ab63557c07f275bf","trusted":false},"outputs":[],"source":"z = zipfile.ZipFile('../input/BDRW_train/BDRW_train_1.zip', \"r\")\nfor name in z.namelist():\n    if name in filelist:\n        z.extract(name)","execution_count":null},{"cell_type":"code","metadata":{"_cell_guid":"276bd981-8653-180c-8c18-bcd51cd40a67","_uuid":"2d057553bffacb12db018e602b00bd05d391ef0d","trusted":false},"outputs":[],"source":"train = [f for f in glob.glob(\"BDRW_train_1/*\")]","execution_count":null},{"cell_type":"markdown","metadata":{"_cell_guid":"bf2fa4d5-b7e3-3ca9-0a1f-35f6363ac398","_uuid":"76f8b6fda310ada8dfea7c7f11a0eeacde858e46"},"outputs":[],"source":"# QUICK PEEK \n\nAll right, with that as a starter let's look at somemore digits to get an idea of what we might be dealing with. I will load in 16 images from the dataset ","execution_count":null},{"cell_type":"code","metadata":{"_cell_guid":"d9d3d953-ea0e-d449-46a6-a0d25cbbc7ac","_uuid":"e82ffe8410aa639b2c6f169d2d4f3764af793f17","trusted":false},"outputs":[],"source":"i = 0\nplt.figure(figsize=(7.5,7.5))\nfor k in train:\n    img = mpimg.imread(k)\n    plt.subplot(5,5,i+1); plt.imshow(img[:,:,0],cmap=plt.cm.inferno_r); plt.axis('off')\n    plt.title('ID = ' + str(i), fontsize=7)\n    i += 1\nplt.tight_layout()","execution_count":null},{"cell_type":"markdown","metadata":{"_cell_guid":"91f94577-eb12-75d3-acec-45e23bd57229","_uuid":"f5313c3b7067475f8054b35add52d224e9f58c76"},"outputs":[],"source":"# PLAYING WITH DIFFERENT COLORMAPS\n\nAll right, now that we have loaded in the image files ( the files are all of .jpg extensions), let's load in an image and play around with different colormaps as a starter ( something easy on the brain and pleasing visually). \n\nColormaps help one to project in image in different combinations and contrasts of colors. Choosing the right scheme does serve to portray the story of ones' plot in a more intuitive or visual manner. \n\nWe will use Matplotlib's colormaps in this notebook to visualise some of the Bengali digits in different variations of colors. For ease of convenience, I have chosen a particular Bengali digit for its nice color contrast and clearly defined edges - **BDRW_train_1/digit_1011.jpg**. \n\nFor more information about colormaps and how they affect human psychology, please check the links ","execution_count":null},{"cell_type":"code","metadata":{"_cell_guid":"c70ad42a-0ef8-a9fc-183e-1f20d1f9f2ea","_uuid":"b76f6b30827fda5542f4c8b1407f0903d89cb1bd","trusted":false},"outputs":[],"source":"","execution_count":null},{"cell_type":"code","metadata":{"_cell_guid":"1b9a7185-6bf2-7016-1eaf-8893c653ee4c","_uuid":"95b6f687cc48a4ff7925cfa2e0d5235ae8ce00c3","trusted":false},"outputs":[],"source":"# Try different Color schemes \n# Make sure we have our particular Bengali digit of interest by ensuring that we always call the right index\nfor index,name in enumerate(train):\n    if name == 'BDRW_train_1/digit_1011.jpg':\n        plt.figure(figsize=(4.5,4.5))\n        plt.subplot(441)\n        plt.imshow(mpimg.imread(train[index])[:,:,0],cmap=plt.cm.flag)\n        plt.title('flag', fontsize=8)\n        plt.axis('off')\n        \n        plt.subplot(442)\n        plt.imshow(mpimg.imread(train[index])[:,:,0],cmap=plt.cm.gnuplot_r)\n        plt.title('Gnuplot', fontsize=8)\n        plt.axis('off')\n        \n        plt.subplot(443)\n        plt.imshow(mpimg.imread(train[index])[:,:,0],cmap=plt.cm.Blues)\n        plt.title('Blues', fontsize=8)\n        plt.axis('off')\n        \n        plt.subplot(444)\n        plt.imshow(mpimg.imread(train[index])[:,:,0],cmap=plt.cm.prism_r)\n        plt.title('prism_r', fontsize=8)\n        plt.axis('off')\n        \n        plt.subplot(445)\n        plt.imshow(mpimg.imread(train[index])[:,:,0],cmap=plt.cm.cubehelix_r)\n        plt.title('Cubehelix', fontsize=8)\n        plt.axis('off')\n        \n        plt.subplot(446)\n        plt.imshow(mpimg.imread(train[index])[:,:,:])\n        plt.title('Original', fontsize=8)\n        plt.axis('off')\n        \n        plt.subplot(447)\n        plt.imshow(mpimg.imread(train[index])[:,:,0],cmap=plt.cm.nipy_spectral_r)\n        plt.title('Nipy_spectral_r', fontsize=8)\n        plt.axis('off')\n        \n        plt.subplot(448)\n        plt.imshow(mpimg.imread(train[index])[:,:,0],cmap=plt.cm.Accent)\n        plt.title('Accent', fontsize=8)\n        plt.axis('off')\n        \n        plt.subplot(449)\n        plt.imshow(mpimg.imread(train[index])[:,:,0],cmap=plt.cm.copper)\n        plt.title('copper', fontsize=8)\n        plt.axis('off')\n        \n        plt.subplot(4,4,10)\n        plt.imshow(mpimg.imread(train[index])[:,:,0],cmap=plt.cm.winter_r)\n        plt.title('winter_r', fontsize=8)\n        plt.axis('off')\n        \n        plt.subplot(4,4,11)\n        plt.imshow(mpimg.imread(train[index])[:,:,0],cmap=plt.cm.Paired_r)\n        plt.title('Paired_r', fontsize=8)\n        plt.axis('off')\n        \n        plt.subplot(4,4,12)\n        plt.imshow(mpimg.imread(train[index])[:,:,0],cmap=plt.cm.coolwarm)\n        plt.title('coolwarm', fontsize=8)\n        plt.axis('off')\n        \n        plt.subplot(4,4,13)\n        plt.imshow(mpimg.imread(train[index])[:,:,0],cmap=plt.cm.flag_r)\n        plt.title('flag_r', fontsize=8)\n        plt.axis('off')\n        \n        plt.subplot(4,4,14)\n        plt.imshow(mpimg.imread(train[index])[:,:,0],cmap=plt.cm.Set1)\n        plt.title('Set1', fontsize=8)\n        plt.axis('off')\n        \n        plt.subplot(4,4,15)\n        plt.imshow(mpimg.imread(train[index])[:,:,0],cmap=plt.cm.afmhot_r)\n        plt.title('afmhot_r', fontsize=8)\n        plt.axis('off')\n        \n        plt.subplot(4,4,16)\n        plt.imshow(mpimg.imread(train[index])[:,:,0],cmap=plt.cm.prism)\n        plt.title('prism', fontsize=8)\n        plt.axis('off')","execution_count":null},{"cell_type":"markdown","metadata":{"_cell_guid":"8907bcc9-59b9-4a6d-6567-d322ab5174ac","_uuid":"00ee59d955dd851a1c62e76a7630c50d39e4cc4d"},"outputs":[],"source":"# FILTERING \n\nIn this section, we will try out different techniques available for filtering of images. Thankfully the immensely powerful SciPy library already ships with many inbuilt filter methods available. In this notebook I will attempt to walkthrough most of these filters,. These filters are listed togther with their generic functions as below below\n\n**Smoothing & Blurring** : Gaussian, Uniform filters\n\n**Sharpening** : Maximum filter\n\n**Removing Noise** : Uniform filter\n\nNow onto the first group of filters, those that serve the purpose of blurring our images","execution_count":null},{"cell_type":"markdown","metadata":{"_cell_guid":"8cedd69b-894e-038d-017c-586406587dbb","_uuid":"c3b650cd830ad3233bcdb09b922f9aac1d408ee6"},"outputs":[],"source":"### Blurring\n\nUsing SciPy's multidimensional image processing package **ndimage**, this allows us to invoke our filters of interest - Gaussian and Uniform filters conveniently via the standard python method call","execution_count":null},{"cell_type":"code","metadata":{"_cell_guid":"8d0e6f0c-aadb-ad02-e6d4-f1cb59d89f6b","_uuid":"8899d50ae5ee7047562ea5db3b39cc079f2cf732","trusted":false},"outputs":[],"source":"for index,name in enumerate(train):\n    if name == 'BDRW_train_1/digit_1011.jpg':\n        plt.figure(figsize=(6,6))\n        \n        plt.subplot(131)\n        plt.imshow(mpimg.imread(train[index])[:,:,0], cmap=plt.cm.bone_r)\n        plt.title('No Filter', fontsize=10)\n        \n        plt.subplot(132)\n        plt.imshow(scipy.ndimage.uniform_filter(mpimg.imread(train[index])[:,:,0]),cmap=plt.cm.bone_r)\n        plt.title('Uniform Filter', fontsize=10)\n        \n        plt.subplot(133)\n        plt.imshow(scipy.ndimage.gaussian_filter(mpimg.imread(train[index])[:,:,0],2.5),cmap=plt.cm.bone_r)\n        plt.title('Gaussian Blurring', fontsize=10)\n        plt.tight_layout()","execution_count":null},{"cell_type":"markdown","metadata":{"_cell_guid":"c070d2cb-95ec-cf24-4740-33add3a9eb72","_uuid":"7ef71c4ed552e85990f0b45c619a9c2fd60cc079"},"outputs":[],"source":"### Sharpening\n\nMathematically, the idea behind the simplest image sharpening implementation is that of increasing the weightage of the edges of an image, therefore allowing the image to appear even sharper than its original","execution_count":null},{"cell_type":"code","metadata":{"_cell_guid":"3333b629-426b-44ca-78b6-7d210e0c2dda","_uuid":"298c78d48debe25bbca163d59635fd29e5a4d912","trusted":false},"outputs":[],"source":"for index,name in enumerate(train):\n    if name == 'BDRW_train_1/digit_1011.jpg':\n        plt.figure(figsize=(6,6))\n        \n        plt.subplot(131)\n        plt.imshow(mpimg.imread(train[index])[:,:,0], cmap=plt.cm.cubehelix_r)\n        plt.title('No Filter', fontsize=10)\n        \n        plt.subplot(132)\n        plt.imshow(scipy.ndimage.maximum_filter(mpimg.imread(train[index])[:,:,0],3.5), cmap=plt.cm.cubehelix_r)\n        plt.title('Maximum Filter', fontsize=10)\n        \n        plt.subplot(133)\n        img = mpimg.imread(train[index])[:,:,0]\n        alpha = 30\n        sharpened = img + alpha * (img - scipy.ndimage.gaussian_filter(mpimg.imread(train[index])[:,:,0],1))\n        plt.imshow(sharpened,cmap=plt.cm.cubehelix_r )\n        plt.title('Laplacian Filter', fontsize=10)\n        plt.tight_layout()","execution_count":null},{"cell_type":"markdown","metadata":{"_cell_guid":"c7650644-161d-789e-7e7c-d52c497b2c11","_uuid":"30078be6a05c633d6eac815d191b2a286ac6ed13"},"outputs":[],"source":"STILL NEED TO WORK ON LAPLACIAN FILTER!!","execution_count":null},{"cell_type":"markdown","metadata":{"_cell_guid":"8ad2266a-6e3e-7f29-be77-b85e5f3ee11a","_uuid":"7cb5507b277f75a3519f7a90260aa27ec2a8deff"},"outputs":[],"source":"**Denoising**\n\n","execution_count":null},{"cell_type":"code","metadata":{"_cell_guid":"26296831-0563-eceb-c2e9-3a354c5e6270","_uuid":"9c1ca13f6b53bc060532dc096569d8f80dc5c920","trusted":false},"outputs":[],"source":"for index,name in enumerate(train):\n    if name == 'BDRW_train_1/digit_1011.jpg':\n        plt.figure(figsize=(6,6))\n        \n        plt.subplot(131)\n        plt.imshow(mpimg.imread(train[index])[:,:,0], cmap=plt.cm.flag)\n        \n        plt.subplot(132)\n        plt.imshow(scipy.ndimage.median_filter(mpimg.imread(train[index])[:,:,0],3),cmap=plt.cm.flag)\n        \n        plt.subplot(133)\n        plt.imshow(skimage.filter.denoise_bilateral(mpimg.imread(train[index])[:,:,:]),cmap=plt.cm.flag)\n        plt.tight_layout()","execution_count":null},{"cell_type":"markdown","metadata":{"_cell_guid":"1f727099-d60a-e1e1-aef5-0e7f0cf44891","_uuid":"22761f550b9346504b1974f8c15ba08e98df8314"},"outputs":[],"source":"# MATHEMATICAL OPERATIONS\n\nSimple mathematical operations can also be performed on your images. For example selecting all elements in the image that are above (or below ) a certain threshold","execution_count":null},{"cell_type":"code","metadata":{"_cell_guid":"28c7685d-02dc-c7fc-5677-a1dbe8bc6827","_uuid":"60394ec038f66ea9b436135912a9db733375df36","trusted":false},"outputs":[],"source":"mpimg.imread(train[index])[:,:,0] < 65","execution_count":null},{"cell_type":"markdown","metadata":{"_cell_guid":"d25dff96-1d60-e500-0b4d-17ff5949dd65","_uuid":"c9795d3c62f1ccb77ec298744833210281b92279"},"outputs":[],"source":"Here's the evolution of how the image would look like if we moved this threshold","execution_count":null},{"cell_type":"code","metadata":{"_cell_guid":"251e41df-3065-06fa-3caf-a0a03aee947c","_uuid":"7a33b9a64ae29d85efca741771fae986dcad0e74","trusted":false},"outputs":[],"source":"for index,name in enumerate(train):\n    if name == 'BDRW_train_1/digit_1011.jpg':\n        plt.figure(figsize=(7,7))\n        \n        plt.subplot(141)\n        img = mpimg.imread(train[index])[:,:,0] > 60\n        plt.imshow(img, cmap=plt.cm.inferno_r)\n        plt.axis('off')\n        \n        plt.subplot(142)\n        img = mpimg.imread(train[index])[:,:,0] > 75\n        plt.imshow(img,cmap=plt.cm.inferno_r)\n        plt.axis('off')\n        \n        plt.subplot(143)\n        img = mpimg.imread(train[index])[:,:,0] > 100\n        plt.imshow(img,cmap=plt.cm.inferno_r)\n        plt.axis('off')\n        \n        plt.subplot(144)\n        img = mpimg.imread(train[index])[:,:,0] > 250\n        plt.imshow(img,cmap=plt.cm.inferno_r)\n        plt.axis('off')\n        plt.tight_layout()","execution_count":null},{"cell_type":"markdown","metadata":{"_cell_guid":"7c98dca7-4552-7e2e-0caa-9426e04c45af","_uuid":"5db3d35f7b77088f58511d6b108e6b799bec11fd"},"outputs":[],"source":"# FEATURE EXTRACTION","execution_count":null},{"cell_type":"markdown","metadata":{"_cell_guid":"f4e8c7ce-9d89-459a-2074-1cc35abac740","_uuid":"f5eb44f572a7998488d93e5599a37bae79089486"},"outputs":[],"source":"**Otsu Feature Extraction method**","execution_count":null},{"cell_type":"code","metadata":{"_cell_guid":"7275ccaa-c37e-e18d-0562-eb9087233bc2","_uuid":"1f2b99efa5dc3bc4d9114836d531fd241c3aa137","trusted":false},"outputs":[],"source":"# Import the relevant modules to call Otsu THresholding\nfrom skimage import data\nfrom skimage import filters","execution_count":null},{"cell_type":"code","metadata":{"_cell_guid":"b2bee196-d4d0-20e9-4bf0-df15ae050e2d","_uuid":"840040ab72fd12e8ad19677cd11c10c3407271ab","trusted":false},"outputs":[],"source":"img = mpimg.imread(train[index])[:,:,:]\nplt.figure(figsize=(4,4))\nval = filters.threshold_otsu(img)\nmask = img < val\n\nplt.subplot(121)\nplt.imshow(img)\n\nplt.subplot(122)\nplt.imshow(mask)\nplt.tight_layout()","execution_count":null},{"cell_type":"markdown","metadata":{"_cell_guid":"0a31befd-af68-3cf7-0126-28bafa0455ca","_uuid":"0a6f5c77d00420706b4be10e080732b6ef7ee828"},"outputs":[],"source":"# IMAGE SEPARATION ","execution_count":null},{"cell_type":"code","metadata":{"_cell_guid":"bfbbe145-45b5-5002-4f49-94ca90c394ad","_uuid":"ad5341f75e78de11f9e765812e01f5c47a36c016","trusted":false},"outputs":[],"source":"","execution_count":null},{"cell_type":"code","metadata":{"_cell_guid":"11c74a02-68b6-faa6-2bce-0dc25e6e2d70","_uuid":"cb6612e242d2ab0bef323526138fd7e51b08cd6f","trusted":false},"outputs":[],"source":"","execution_count":null}],"nbformat":4}