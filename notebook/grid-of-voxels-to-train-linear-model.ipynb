{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"ba3a22b1-abce-6b65-c898-b860b9a50483"},"source":"In this notebook we will use a grid of voxels along with its respective occupancy to build a vector that will serve as a global feature for representing the 3D data."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"adca534b-1ede-bb5c-c4d5-9845a5060bc3"},"outputs":[],"source":"sys.path.append(\"../input\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6da81f05-40fe-d33b-58da-bd172f086a2d"},"outputs":[],"source":"import h5py\nimport os\nimport numpy as np\nfrom IPython.display import Image\nfrom voxelgrid import VoxelGrid\nfrom matplotlib import pyplot as plt"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7e01740b-2491-1906-91fd-f2fcace70617"},"outputs":[],"source":"%matplotlib inline\nplt.rcParams['image.interpolation'] = None\nplt.rcParams['image.cmap'] = 'gray'"},{"cell_type":"markdown","metadata":{"_cell_guid":"76a5d46d-9abe-c2ce-9d12-178538575e20"},"source":"## Read data from HDF5 file"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"507f753a-44e4-163f-91ff-e12c0661b764"},"outputs":[],"source":"with h5py.File(\"../input/train_small.h5\", \"r\") as hf:    \n\n    a = hf[\"0\"]\n    b = hf[\"1\"]\n    \n    digit_a = (a[\"img\"][:], a[\"points\"][:], a.attrs[\"label\"]) \n    digit_b = (b[\"img\"][:], b[\"points\"][:], b.attrs[\"label\"]) \n\nplt.subplot(121)\nplt.title(\"DIGIT A: \" + str(digit_a[2]))\nplt.imshow(digit_a[0])\n\nplt.subplot(122)\nplt.title(\"DIGIT B: \" + str(digit_b[2]))\nplt.imshow(digit_b[0])"},{"cell_type":"markdown","metadata":{"_cell_guid":"ef312eaf-fbc6-801a-eca8-414433df70ce"},"source":"## Generate VoxelGrid"},{"cell_type":"markdown","metadata":{"_cell_guid":"1e359572-d6d1-d5ee-89cd-d211430093a8"},"source":"![VoxelGrid](https://media.githubusercontent.com/media/daavoo/3DMNIST/master/contrib/voxelgrid/data/voxelgrid.png)"},{"cell_type":"markdown","metadata":{"_cell_guid":"8c5a362f-d213-eca6-a3b4-1be2d63f91d1"},"source":"The VoxelGrid will fit an axis-aligned bounding box around the point cloud and then subdivide the box in segments along each corresponding axis.\n\nThe x_y_z argument indicates how many segments we want per axis.\n\nWe will split each axis in 8 voxels wich would be equivalent to use the 3th level of an Octree.\n\nThis will generate a total of 512 different voxels."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e0d4a30b-af98-4049-b005-751529f42131"},"outputs":[],"source":"a_voxelgrid = VoxelGrid(digit_a[1], x_y_z=[8, 8, 8])\nb_voxelgrid = VoxelGrid(digit_b[1], x_y_z=[8, 8, 8])"},{"cell_type":"markdown","metadata":{"_cell_guid":"691d0549-1636-5e37-33fb-43147f42607f"},"source":"This will generate an object with several attributes.\n\nIn the structure attribute we can find a 2D array where each row represents a point in the original point cloud and each column represents the n_voxel where it lies with respect to [x_axis, y_axis, z_axis, global]."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b418e67b-b5d8-4754-e1ea-a47b8e52206d"},"outputs":[],"source":"# point coordinates\ndigit_a[1][340]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8bb52c5e-7848-d3f4-f423-4e3233b06764"},"outputs":[],"source":"# n_voxel\na_voxelgrid.structure[340]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a3f08820-c33c-e26b-5bf9-7e022a36027d"},"outputs":[],"source":"digit_b[1][5200]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7058cb46-9b67-6c35-a1ce-dc6221a8569d"},"outputs":[],"source":"b_voxelgrid.structure[5200]"},{"cell_type":"markdown","metadata":{"_cell_guid":"b175a634-2665-e2a8-49d6-7650b65f397a"},"source":"## Visualize the VoxelGrid.structure"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8e1ac05b-d9b8-4014-d65b-d61c3e38d3e5"},"outputs":[],"source":"def plot_colorfull_hist(array):\n    cm = plt.cm.get_cmap('gist_rainbow')\n    n, bins, patches = plt.hist(array, bins=64)\n\n    bin_centers = 0.5 * (bins[:-1] + bins[1:])\n\n    # scale values to interval [0,1]\n    col = bin_centers - min(bin_centers)\n    col /= max(col)\n\n    for c, p in zip(col, patches):\n        plt.setp(p, 'facecolor', cm(c))\n    plt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79a8f0a4-8840-b833-9a77-501e169c5fc9"},"outputs":[],"source":"plt.figure(figsize=(10,5))\nplt.title(\"DIGIT: \" + str(digit_a[-1]))\nplt.xlabel(\"VOXEL\")\nplt.ylabel(\"POINTS INSIDE THE VOXEL\")\nplot_colorfull_hist(a_voxelgrid.structure[:,-1])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"87b30264-016f-8b83-b8a7-a2400a1f2c61"},"outputs":[],"source":"plt.figure(figsize=(10,5))\nplt.title(\"DIGIT: \" + str(digit_b[-1]))\nplt.xlabel(\"VOXEL\")\nplt.ylabel(\"POINTS INSIDE THE VOXEL\")\nplot_colorfull_hist(b_voxelgrid.structure[:,-1])"},{"cell_type":"markdown","metadata":{"_cell_guid":"df2bddb9-d4a8-33d7-bc03-a521982a05b3"},"source":"As we can see in the histograms there is a lot of empty voxels. \n\nThis is due to the use of a cuboid bounding box to ensure that the VoxelGrid will divide the cloud in a similar way even when the point clouds are oriented to different directions.\n\nWe can use the built-in function plot() to visualize the voxelgrid.\n\nThe function will display the voxelgrid sliced around the z-axis.\n\nYou might need a nice spatial vision capacity to visualize the point cloud."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cb187030-039d-7fe5-8bc1-e7c6afa728ad"},"outputs":[],"source":"a_voxelgrid.plot()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0b2e5d1b-5fbe-c624-3b2c-3cd50a6fbfb6"},"outputs":[],"source":"b_voxelgrid.plot()"},{"cell_type":"markdown","metadata":{"_cell_guid":"fc873ff9-b4d0-4123-24ca-34387091dd13"},"source":"Or even better we can save the voxelgrid's structure as scalar fields of the original point cloud and visualize it in any 3D software that supports point clouds and scalar fields (I like CloudCompare)."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bc444a5c-b883-a395-6888-803e30c8c771"},"outputs":[],"source":"# Uncomment if you run this locally\n#cloud_a = np.concatenate((digit_a[1], a_voxelgrid.structure), axis=1)\n#cloud_b = np.concatenate((digit_b[1], b_voxelgrid.structure), axis=1)\n\n#np.savetxt(\"data/\"+ str(digit_a[2]) + \".txt\", cloud_a)\n#np.savetxt(\"data/\"+ str(digit_b[2]) + \".txt\", cloud_b)"},{"cell_type":"markdown","metadata":{"_cell_guid":"031ce60f-1f72-6375-dbf9-31a4079ef852"},"source":"## Associate voxel along X axis"},{"cell_type":"markdown","metadata":{"_cell_guid":"2f85aae5-12c7-14c4-9213-7b2b889318a1"},"source":"![0_X](https://media.githubusercontent.com/media/daavoo/3DMNIST/master/contrib/voxelgrid/data/0_X.png)"},{"cell_type":"markdown","metadata":{"_cell_guid":"c33b2665-ff44-cbdb-4606-d440bbfbdc73"},"source":"## Associate voxel along Y axis"},{"cell_type":"markdown","metadata":{"_cell_guid":"951af298-d04e-f8c8-32de-234469e1e9d2"},"source":"![0_Y](https://media.githubusercontent.com/media/daavoo/3DMNIST/master/contrib/voxelgrid/data/0_Y.png)"},{"cell_type":"markdown","metadata":{"_cell_guid":"910bca9a-14fe-b972-2cd0-4bcc5115702b"},"source":"## Associate voxel along Z axis"},{"cell_type":"markdown","metadata":{"_cell_guid":"45acdbd5-f48b-57c3-7551-1a0beb53e021"},"source":"![0_Z](https://media.githubusercontent.com/media/daavoo/3DMNIST/master/contrib/voxelgrid/data/0_Z.png)"},{"cell_type":"markdown","metadata":{"_cell_guid":"f4748b57-c754-8e4f-12bc-3242278d7873"},"source":"## Global associate voxel"},{"cell_type":"markdown","metadata":{"_cell_guid":"51fdb411-84f3-b235-07a3-e396ba3ad482"},"source":"![0_N](https://media.githubusercontent.com/media/daavoo/3DMNIST/master/contrib/voxelgrid/data/0_N.png)"},{"cell_type":"markdown","metadata":{"_cell_guid":"a5a28400-ee7c-1eb9-c531-1487214a0a67"},"source":"![5_N](https://media.githubusercontent.com/media/daavoo/3DMNIST/master/contrib/voxelgrid/data/5_N.png)"},{"cell_type":"markdown","metadata":{"_cell_guid":"9ae2954f-c9a7-8967-134a-b9ce29734c7a"},"source":"## Generate the global feature vector for all the dataset"},{"cell_type":"markdown","metadata":{"_cell_guid":"bf665bf6-8e77-f9e3-9713-d1d3b2deb1fe"},"source":"As we see in the picture the voxel global is the feature that contains information about all the 3 axis combined.\n\nThe voxel global count is stored in the voxelgrid.vector attribute.\n\nThis vector holds the count of points that lie inside each of the global voxels."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a49de8e7-120c-e723-a7d1-4bb508d9becc"},"outputs":[],"source":"a_voxelgrid.vector"},{"cell_type":"markdown","metadata":{"_cell_guid":"e4df7467-71bc-2f7a-3dbb-534f52ef91b4"},"source":"We can use the voxelgrid.vector as a global feature for representing the 3D digits."},{"cell_type":"markdown","metadata":{"_cell_guid":"1010549d-8ed1-3b82-ee01-9503762ae6fb"},"source":"## Generate the vector for all the dataset"},{"cell_type":"markdown","metadata":{"_cell_guid":"123fa4e5-b4f1-8e65-77e3-828cecc71bf5"},"source":"Iterate over each HDF5 file to generate the array of vectors"},{"cell_type":"markdown","metadata":{"_cell_guid":"940955cf-c641-e4f5-b503-b00e704e19a4"},"source":"### Train"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8c7751ef-ec73-99b6-3030-be2db42fd135"},"outputs":[],"source":"with h5py.File(\"../input/train_small.h5\", \"r\") as hf:\n    size = len(hf.keys())\n    # tuple to store the vectors and labels\n    out = (np.zeros((size, 512), dtype=\"f\"), np.zeros(size, dtype=np.int8))\n    \n    for i in range(size):\n        if i % 200 == 0:\n            print(i, \"\\t processed\")\n        voxelgrid = VoxelGrid(hf[str(i)][\"points\"][:], x_y_z=[8, 8, 8])\n        # make the vector range 0-1\n        out[0][i] = voxelgrid.vector / np.max(voxelgrid.vector)\n        out[1][i] = hf[str(i)].attrs[\"label\"]\n    print(\"[DONE]\")\n    X_train, y_train = out"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"145df797-27ec-2d2e-d5e4-ea67486659b6"},"outputs":[],"source":"with h5py.File(\"../input/valid_small.h5\", \"r\") as hf:\n    size = len(hf.keys())\n    # tuple to store the vectors and labels\n    out = (np.zeros((size, 512), dtype=\"f\"), np.zeros(size, dtype=np.int8))\n    \n    for i in range(size):\n        if i % 200 == 0:\n            print(i, \"\\t processed\")\n        voxelgrid = VoxelGrid(hf[str(i)][\"points\"][:], x_y_z=[8, 8, 8])\n        # make the vector range 0-1\n        out[0][i] = voxelgrid.vector / np.max(voxelgrid.vector)\n        out[1][i] = hf[str(i)].attrs[\"label\"]\n    print(\"[DONE]\")\n    X_valid, y_valid = out"},{"cell_type":"markdown","metadata":{"_cell_guid":"09132849-c08f-5e2a-9d0d-449a16023b66"},"source":"## Save the new features"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"83b0a3b6-10f4-caf4-210b-3859a9a6012d"},"outputs":[],"source":"# Uncomment if you run this locally\n\n#np.savez_compressed(\"voxelgrid.npz\", X_train=train_set[0], y_train=train_set[1],\n#                    X_test=test_set[0], y_test=test_set[1], X_valid=valid_set[0],\n#                    y_valid=valid_set[1])\n"},{"cell_type":"markdown","metadata":{"_cell_guid":"39b850ef-16dd-e079-f45c-1cdbc96c12c5"},"source":"## Train a simple linear model"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e3ef7d9d-b5e6-331f-881c-42c5a40d9532"},"outputs":[],"source":"from sklearn.svm import LinearSVC"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f02834bb-37ec-68f7-66d1-e6bd863ba104"},"outputs":[],"source":"clf = LinearSVC()\nclf.fit(X_train, y_train)"},{"cell_type":"markdown","metadata":{"_cell_guid":"51ff5c98-a850-d630-71ac-99a5b49cb9aa"},"source":"## Validation Score"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d6222d4b-6dab-a840-dcb6-c6150bf6001f"},"outputs":[],"source":"print(\"Validation Score: \", clf.score(X_valid, y_valid))"},{"cell_type":"markdown","metadata":{"_cell_guid":"889098b5-b1ab-4854-c316-5979601363cf"},"source":"As we can see we get a relatively decent score for our first work with 3D data. However we must take in account that the data has been manually oriented and refined to make the problem simplier. \n\nCheck the kernell \"Data augmentation\" to learn how to generate a more realistic dataset from the original 3DMNIST with noise and random orientations."},{"cell_type":"markdown","metadata":{"_cell_guid":"92f64ddd-0ac0-e163-2948-d39d598552f1"},"source":"## Get the misclassified images and plot a sample"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4a9ebd8b-92c9-752a-ec47-dadbdcacc069"},"outputs":[],"source":"y_pred = clf.predict(X_valid)\nmiss = np.where(y_pred != y_valid)[0]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e288b22f-054e-7ce9-a668-a1c6a6677daf"},"outputs":[],"source":"# load images from HDF5 dataset\nwith h5py.File(\"../input/valid_small.h5\", \"r\") as hf:\n    wrong_pred = []\n    for i in miss:\n        wrong_pred.append((hf[str(i)][\"img\"][:], y_pred[i], y_valid[i]))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ec8965c3-2e91-9a76-20a2-0c6578e1b15c"},"outputs":[],"source":"fig, axes = plt.subplots(2, 4, figsize=(10,10))\n\nrandom_idx = np.random.randint(0, len(wrong_pred), 8)\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(wrong_pred[random_idx[i]][0])\n    ax.set_title(\"PREDICTION: \"+ str(wrong_pred[random_idx[i]][1]) + \"\\n\" +\n                \"TRUE: \" + str(wrong_pred[random_idx[i]][2]))\n    ax.set_xticks([])\n    ax.set_yticks([])"},{"cell_type":"markdown","metadata":{"_cell_guid":"87b5d3d0-dc92-673b-e134-a9f394da1fc1"},"source":"## Confusion Matrix"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8fe7c7da-0880-aec5-8b15-efd125112979"},"outputs":[],"source":"import seaborn as sn\nimport pandas as pd\nfrom sklearn.metrics import confusion_matrix\narray = confusion_matrix(y_valid, y_pred)\ndf_cm = pd.DataFrame(array, index = range(10),\n                  columns = range(10))\nplt.figure(figsize=(10,8))\nsn.heatmap(df_cm, annot=True)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}