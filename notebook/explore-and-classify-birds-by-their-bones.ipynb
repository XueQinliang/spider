{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"61cf3171-40ef-1d38-6b67-ec1679509167"},"source":"Explore the dataset and try some classification algorithm.\n----------------------------------------------------------"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ef75ddb1-cb1c-69f2-7b34-16f4cf577851"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.style.use(\"ggplot\")\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"19aaf69f-c4a7-1a02-e8f6-d50e2f300496"},"outputs":[],"source":"bird = pd.read_csv(\n    \"../input/bird.csv\", \n    dtype={\"id\": \"str\"}\n)\n\nbird.dropna(axis=0, how=\"any\", inplace=True)\n\nbird.shape"},{"cell_type":"markdown","metadata":{"_cell_guid":"b8371c70-8779-6ccd-2e08-2f4c854e4d3e"},"source":"Summary of the data."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"baeda003-5bb9-e60b-8a59-5fab30733ca4"},"outputs":[],"source":"bird.describe()"},{"cell_type":"markdown","metadata":{"_cell_guid":"e85aa780-f773-33d8-98df-a9409ee58af7"},"source":"Number of birds in each ecological group."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"73b7a0a6-71f7-f06f-1097-7ad2e1af948e"},"outputs":[],"source":"size_of_each_group = bird.groupby(\"type\").size()\n\nax = size_of_each_group.plot(\n    kind=\"bar\", \n    title=\"Number of birds in each ecological group\", \n    color=\"#00304e\",\n    figsize=((6, 4))\n)\n\nax.set_title(\"Number of birds in each ecological group\", fontsize=10)\n_ = ax.set_xlabel(\"Ecological Group\")\n\nfor x, y in zip(np.arange(0, len(size_of_each_group)), size_of_each_group):\n    _ = ax.annotate(\"{:d}\".format(y), xy=(x-(0.14 if len(str(y)) == 3 else 0.1), y-6), fontsize=10, color=\"#eeeeee\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"88b8e936-c244-832c-f267-e7c5ac26c3fa"},"outputs":[],"source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler(with_mean=False) # Do not centralize the features, keep them positive.\n\nbird_raw = bird.copy() # Make a copy of original data.\n\nfeature_columns = ['huml', 'humw', 'ulnal', 'ulnaw', 'feml', 'femw', 'tibl', 'tibw', 'tarl', 'tarw'] # numeric feature columns.\n\nbird[feature_columns] = scaler.fit_transform(bird_raw[feature_columns]) # standardlize the numeric features."},{"cell_type":"markdown","metadata":{"_cell_guid":"620df605-10f0-001e-07ee-8b69bd2dbe17"},"source":"The correlation matrix of 10 features."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"908bd037-8ea2-88a4-adec-5aec8639df31"},"outputs":[],"source":"corr = bird_raw[feature_columns].corr()\n\n_, ax = plt.subplots(figsize=(8, 7))\n\n# cmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n_ = sns.heatmap(\n    corr, \n    cmap=sns.light_palette(\"#00304e\", as_cmap=True), \n    square=True, \n    cbar=False, \n    ax=ax, \n    annot=True, \n    annot_kws={\"fontsize\": 8}\n)"},{"cell_type":"markdown","metadata":{"_cell_guid":"1354363f-7a11-d045-4c3f-c923598f5114"},"source":"We can see that these features are highly correlated. That's natural: big birds has longer and thicker bones than small birds no matter what kinds of birds they are.\n\nDraw scatter plots for 10 features."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"23801085-50f7-3a0f-4bc3-27865a966a6f"},"outputs":[],"source":"_ = sns.pairplot(\n    data=bird_raw, \n    kind=\"scatter\", \n    vars=feature_columns, \n    hue=\"type\", \n    diag_kind=\"hist\", \n    palette=sns.color_palette(\"Set1\", n_colors=6, desat=.5)\n)"},{"cell_type":"markdown","metadata":{"_cell_guid":"59ef04eb-6ccb-111f-1ad9-6bc4c0320733"},"source":"Most feature-pairs present strong linear relationship.  Next I do linear regressions of each kind of bones for each group of birds."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"334f9058-f41d-a968-496a-cf0fac5f51c5"},"outputs":[],"source":"g = sns.FacetGrid(bird_raw, col=\"type\")\n\nfor x, y, c in zip([\"huml\", \"ulnal\", \"feml\", \"tibl\", \"tarl\"], [\"humw\", \"ulnaw\", \"femw\", \"tibw\", \"tarw\"], sns.color_palette(\"Set1\", n_colors=6, desat=.5)):\n    _ = g.map(sns.regplot, x, y, scatter_kws={\"s\": 12, \"alpha\": 0.4}, line_kws={\"lw\": 1}, color=c)\n\n_ = g.add_legend()"},{"cell_type":"markdown","metadata":{"_cell_guid":"a603d6c9-7f69-8dec-b520-bd47a196e920"},"source":"More steep the line, more rapid diameters change with respect to lengths. That means more steep the line, more robust the birds of that ecological group.\n\nThe box-plots of each kind of bones."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"827de9fd-1e3d-f3f6-5a66-f78e425a1956"},"outputs":[],"source":"_, axes = plt.subplots(nrows=4, ncols=3, figsize=(15, 20))\n\nfor f, ax in zip(feature_columns, axes.ravel()):\n    _ = sns.boxplot(\n        data=bird_raw, \n        y=f, \n        x='type', \n        ax=ax, \n        palette=sns.color_palette(\"Set1\", n_colors=6, desat=.5)\n    )\n\n_ = axes[3, 1].annotate(\"No Data\", xy=(.4, .48))\n_ = axes[3, 2].annotate(\"No Data\", xy=(.4, .48))"},{"cell_type":"markdown","metadata":{"_cell_guid":"230cc569-63de-30fd-80e6-0b2866ccc85a"},"source":"Compute the ratios of limbs and hinds of all birds, and plot them."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b7a49a90-5ade-1e8f-2c2a-4c191faf064c"},"outputs":[],"source":"limb_hind_ratio = pd.DataFrame(\n    {\"ratio\": (bird_raw.huml + bird_raw.ulnal) / (bird_raw.feml + bird_raw.tibl + bird_raw.tarl), \n     \"type\": bird_raw.type})\n\n_, axes = plt.subplots(nrows=2, ncols=3,  figsize=(12, 8))\n\nfor t, ax, c in zip(limb_hind_ratio.type.unique(), axes.ravel(), sns.color_palette(\"Set1\", n_colors=6, desat=.5)):\n    _ = sns.distplot(\n        limb_hind_ratio.loc[limb_hind_ratio.type == t, 'ratio'], \n        rug=True, \n        axlabel=t, \n        bins=20, \n        ax=ax, \n        color=c\n    )"},{"cell_type":"markdown","metadata":{"_cell_guid":"5556f318-7855-5d68-cb83-6f240c9cf10e"},"source":"## Principle Components Analysis ##"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e9971a57-44d3-5e67-430d-7fc91a5d1491"},"outputs":[],"source":"from sklearn.decomposition import PCA\n\npca = PCA()\npca.fit(bird[feature_columns])\n\nexplained_variance = pd.DataFrame({\"evr\": pca.explained_variance_ratio_, \"evrc\": pca.explained_variance_ratio_.cumsum()}, \n                                  index=pd.Index([\"pc{:d}\".format(i) for i in np.arange(1, len(feature_columns) + 1)], name=\"principle components\"))\n\n_, ax = plt.subplots(figsize=(8, 4))\n_ = explained_variance.evrc.plot(kind=\"line\", color=\"#ee7621\", ax=ax, linestyle=\"-\", marker=\"h\")\n_ = explained_variance.evr.plot(kind=\"bar\", ax=ax, color=\"#00304e\", alpha=0.8)\n_ = ax.set_title(\"Explained Variance Ratio of Principle Components\", fontsize=10)\n_ = ax.set_ylim([0.0, 1.1])\n\nfor x, y in zip(np.arange(0, len(explained_variance.evrc)), explained_variance.evrc):\n    _ = ax.annotate(\"{:.1f}%\".format(y * 100.0), xy=(x-0.2, y+0.03), fontsize=7)\n\nfor x, y in zip(np.arange(1, len(explained_variance.evr)), explained_variance.evr[1:]):\n    _ = ax.annotate(\"{:.1f}%\".format(y * 100.0), xy=(x-0.15, y+0.02), fontsize=7)"},{"cell_type":"markdown","metadata":{"_cell_guid":"1cf6fd1e-d09b-0281-1c4a-25fdbcf2eb76"},"source":"We see that first principle component take almost all variance. This means our dataset is nearly 1-dimension. Not surprising, birds are all \"bird-shaped\", size of all their bones change almost synchronously.\n\nScatter the principle components."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fa2f55c0-eee0-0e14-d8e8-ba7267649779"},"outputs":[],"source":"pc_df = pd.DataFrame(\n    pca.transform(bird[feature_columns]), \n    columns=[\"pc{:d}\".format(i) for i in np.arange(1, len(feature_columns) + 1)]\n)\n\npc_df[\"type\"] = bird.type\n\n_ = sns.pairplot(\n    data=pc_df, \n    vars=[\"pc{:d}\".format(i) for i in np.arange(1, 6)], \n    hue=\"type\", \n    diag_kind=\"kde\", \n    palette=sns.color_palette(\"Set1\", n_colors=6, desat=.5)\n)"},{"cell_type":"markdown","metadata":{"_cell_guid":"26a196b0-8113-946b-6dad-f8d6ae1b807b"},"source":"How about the robustness of the bones. Let's define the robustness of a bone is the ratio of its diameter and length."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9a9c5567-3ade-9539-7ea6-c21ec8e775c1"},"outputs":[],"source":"robust = pd.DataFrame({\n        \"humr\": bird_raw.humw / bird_raw.huml, \n        \"ulnar\": bird_raw.ulnaw / bird_raw.ulnal,\n        \"femr\": bird_raw.femw / bird_raw.feml,\n        \"tibr\": bird_raw.tibw / bird_raw.tibl,\n        \"tarr\": bird_raw.tarw / bird_raw.tarl,\n        \"type\": bird_raw.type}\n)\n\n_, axes = plt.subplots(nrows=3, ncols=2, figsize=(8, 12))\n\nfor f, ax in zip([\"humr\", \"ulnar\", \"femr\", \"tibr\", \"tarr\"], axes.ravel()):\n    _ = sns.boxplot(\n        data=robust, \n        y=f, \n        x='type', \n        ax=ax, \n        palette=sns.color_palette(\"Set1\", n_colors=6, desat=.5)\n    )\n    \n    if f == \"tibr\":\n        ax.set_ylim((0.0, 0.1))\n\n_ = axes[2, 1].annotate(\"No Data\", xy=(.42, .5), fontsize=8)"},{"cell_type":"markdown","metadata":{"_cell_guid":"b8fa72b1-9ff9-4d68-b35b-7518a86b2dee"},"source":"Add these new features to original dataset."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1dd7ddbe-a25e-3cda-8064-95b4ae5fbde0"},"outputs":[],"source":"bird_extended = pd.concat([bird_raw, robust[[\"humr\", \"ulnar\", \"femr\", \"tibr\", \"tarr\"]], limb_hind_ratio[\"ratio\"]], axis=1)\n\nfeature_columns_extended = [\"huml\", \"humw\", \"ulnal\", \"ulnaw\", \"feml\", \"femw\", \"tibl\", \"tibw\", \"tarl\", \"tarw\", \"humr\", \"ulnar\", \"femr\", \"tibr\", \"tarr\", \"ratio\"]\n\nbird_extended[feature_columns_extended] = scaler.fit_transform(bird_extended[feature_columns_extended])"},{"cell_type":"markdown","metadata":{"_cell_guid":"f980c7c7-46b7-81b6-bd79-8207f5363f1c"},"source":"Now compute features' chi2 significances."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6501a47d-aa6d-7ded-5007-913878e050c0"},"outputs":[],"source":"from sklearn.feature_selection import chi2\n\nchi2_result = chi2(bird_extended[feature_columns_extended], bird_extended.type)\nchi2_result = pd.DataFrame({\"feature\": feature_columns_extended, \"chi2_statics\": chi2_result[0], \"p_values\": chi2_result[1]})\nchi2_result.sort_values(by=\"p_values\", ascending=False, inplace=True)\nchi2_result.set_index(keys=\"feature\", inplace=True)\n\nax = chi2_result[\"p_values\"].plot(kind=\"barh\", logx=True, color=\"#00304e\")\n\n_ = ax.annotate(\"{:3.2f}\".format(chi2_result.chi2_statics[chi2_result.shape[0] - 1]), xy=(chi2_result.p_values[chi2_result.shape[0] - 1], len(feature_columns_extended) - 1), xytext=(0, -3), textcoords=\"offset pixels\", fontsize=8, color=\"#00304e\")\nfor y, x, c in zip(np.arange(0, len(feature_columns_extended) - 1), chi2_result.p_values[:-1], chi2_result.chi2_statics[:-1]):\n    _ = ax.annotate(\"{:3.2f}\".format(c), xy=(x, y), xytext=(-35, -3), textcoords=\"offset pixels\", fontsize=8, color=\"#eeeeee\")\n\n_ = ax.set_xlabel(\"p-value (chi2 value)\")\n_ = ax.set_title(\"chi2 values and p-values of features\", fontsize=10)"},{"cell_type":"markdown","metadata":{"_cell_guid":"717278e5-e38f-c5b5-14f2-299463ccd92f"},"source":"More large the chi2 value (*more small the p-value*), more significant the feature (*to be different in different groups*)"},{"cell_type":"markdown","metadata":{"_cell_guid":"f645d991-9dd4-ca73-bcf8-389bfc3a1fa5"},"source":"Try classification\n------------------"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"074047f0-a88f-6004-50ed-3a03f737fee2"},"outputs":[],"source":"from sklearn.model_selection import train_test_split\n\ntrain_f, test_f, train_l, test_l = train_test_split(bird_extended[feature_columns_extended], bird_extended.type, train_size=0.6)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3ab27fcb-dd4f-d551-e587-34776f97a085"},"outputs":[],"source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\n\n\nlr = LogisticRegression()\nparams = {\n    \"penalty\": [\"l1\", \"l2\"],\n    \"C\": [0.1, 1.0, 5.0, 10.0],\n    \"class_weight\": [None, \"balanced\"],\n    #\"multi_class\": [\"ovr\", \"multinomial\"]\n}\n\ngs = GridSearchCV(estimator=lr, param_grid=params, scoring=\"accuracy\", cv=5, refit=True)\n_ = gs.fit(train_f, train_l)"},{"cell_type":"markdown","metadata":{"_cell_guid":"0635bb9f-60b9-0467-c14c-0274c49d9f36"},"source":"Best params found by grid search."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e44017a4-d840-b369-21a3-960b44397149"},"outputs":[],"source":"print(gs.best_params_)"},{"cell_type":"markdown","metadata":{"_cell_guid":"f08216c0-eadd-f9f8-c16f-f32ff83b2811"},"source":"Classification metrics."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9a296f6b-51c0-5cfb-a7da-caa1fada627d"},"outputs":[],"source":"from sklearn.metrics import confusion_matrix, classification_report\npredict_l = gs.predict(test_f)\n\nprint(classification_report(test_l, predict_l))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6b72b02f-3624-e150-ef90-6feee9caebab"},"outputs":[],"source":"cm = confusion_matrix(test_l, predict_l)\n_ = sns.heatmap(\n    cm, \n    square=True, \n    xticklabels=[\"P\", \"R\", \"SO\", \"SW\", \"T\", \"W\"], \n    annot=True, \n    annot_kws={\"fontsize\": 8}, \n    yticklabels=[\"P\", \"R\", \"SO\", \"SW\", \"T\", \"W\"], \n    cbar=False, \n    cmap=sns.light_palette(\"#00304e\", as_cmap=True)\n).set(xlabel = \"predicted type\", ylabel = \"true type\", title = \"Confusion Matrix\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"adf5056a-473e-b6eb-8b8a-bdcdac9b72ca"},"outputs":[],"source":"from sklearn.metrics import accuracy_score\n\nprint(\"Accuracy: {:.3f}\".format(accuracy_score(y_true=test_l, y_pred=predict_l)))"},{"cell_type":"markdown","metadata":{"_cell_guid":"220d9ff6-0bc9-7e74-3d7d-b70b5f3e875e"},"source":"Features' weights (*absolute values*)."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f1551321-f46f-a7c3-b668-7c646eed4bfc"},"outputs":[],"source":"_, ax = plt.subplots(nrows=1, ncols=1, figsize=(16, 8))\n_ = sns.heatmap(\n    abs(gs.best_estimator_.coef_), \n    ax=ax, \n    square=True, \n    xticklabels=feature_columns_extended, \n    annot=True, \n    annot_kws={\"fontsize\": 10}, \n    yticklabels=gs.best_estimator_.classes_, \n    cbar=True\n    cmap=sns.light_palette(\"#00304e\", as_cmap=True)\n).set(xlabel = \"Features\", ylabel = \"Ecological Group\", title = \"Absolute Feature Weights\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"ce887f6c-ce98-55bf-7385-6c2a610f4e93"},"source":"Try random forest algorithm."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"abe6cec6-1493-f70a-ec18-5e61ce91047c"},"outputs":[],"source":"from sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier()\n\nparams = {\n    \"n_estimators\": [5, 10, 20, 50],\n    \"criterion\": [\"gini\", \"entropy\"],\n    \"max_depth\": [5, 10, 15],\n    \"class_weight\": [None, \"balanced\"]\n}\n\nrfc_gs = GridSearchCV(estimator=rfc, param_grid=params, scoring=\"accuracy\", cv=5, refit=True)\n_ = rfc_gs.fit(train_f, train_l)"},{"cell_type":"markdown","metadata":{"_cell_guid":"2f2526bf-109d-9c17-152d-cea03e6ed8a3"},"source":"Metrics."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f8a6c247-2c20-1632-93b2-ace7565b7823"},"outputs":[],"source":"predict_l = rfc_gs.predict(test_f)\n\nprint(classification_report(test_l, predict_l))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"de8a5201-fbdf-62ff-1d30-5e1d618f5333"},"outputs":[],"source":"cm = confusion_matrix(test_l, predict_l)\n_ = sns.heatmap(\n    cm, \n    square = True, \n    xticklabels = [\"P\", \"R\", \"SO\", \"SW\", \"T\", \"W\"], \n    annot = True, \n    annot_kws = {\"fontsize\": 8}, \n    yticklabels = [\"P\", \"R\", \"SO\", \"SW\", \"T\", \"W\"], \n    cbar = False, \n    cmap=sns.light_palette(\"#00304e\", as_cmap=True)\n).set(xlabel = \"Predicted Ecological Group\", ylabel = \"Real Ecological Group\", title = \"Confusion Matrix\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"2336cbb9-a0b0-f314-5437-857ca2d098c9"},"source":"Accuracy."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"98cd9ce2-c0fe-839a-2b3b-54715d807336"},"outputs":[],"source":"print(\"Accuracy: {:.3f}\".format(accuracy_score(y_true=test_l, y_pred=predict_l)))"},{"cell_type":"markdown","metadata":{"_cell_guid":"0e381a60-1fd1-fa0b-ec6a-50b201831717"},"source":"Features' importances"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c87c6446-ae25-348f-fdb7-e481842063a6"},"outputs":[],"source":"feature_importances = pd.DataFrame(\n    {\n        \"importance\": rfc_gs.best_estimator_.feature_importances_\n    }, \n    index=pd.Index(feature_columns_extended, name=\"feature\")\n).sort_values(by=\"importance\")\n\nax = feature_importances.plot(kind=\"barh\", color=\"#00304e\", legend=False)\n\nfor y, x in zip(np.arange(0, feature_importances.shape[0]), feature_importances.importance):\n    _ = ax.annotate(\"{:.3f}\".format(x), xy=(x-0.009, y-0.1), fontsize=8, color=\"#eeeeee\")\n\n\n_ = ax.set_xlabel(\"importance\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"ba6bd0be-d27b-a98b-40ec-8bb0cb245a2c"},"source":"The two classifiers perform poorly on wading birds. The recall is low. From charts (scatter/box-plot)  we see that wading birds is difficult to tell from other kids of birds. We scatter wading birds and others here."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c2ca75d8-7030-0d44-bebd-f34e4c95b03d"},"outputs":[],"source":"bird_raw[\"is_w\"] = bird_raw.type == \"W\"\n\n_ = sns.pairplot(\n    data=bird_raw, \n    kind=\"scatter\", \n    vars=feature_columns, \n    hue=\"is_w\", \n    diag_kind=\"hist\", \n    palette=sns.color_palette(\"Set1\", n_colors=6, desat=.5)\n)"},{"cell_type":"markdown","metadata":{"_cell_guid":"73cc36c2-0d44-f3ab-1fd7-bf03ea17bd63"},"source":"Use a support vector machine to tell wading birds from others."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"efacf49c-cf82-27ed-80bd-e3d4ac86b685"},"outputs":[],"source":"from sklearn.svm import SVC\nfrom sklearn.metrics import roc_curve, accuracy_score, precision_score, recall_score, auc, precision_recall_curve\n\n# use extended feature set.\nbird_extended[\"is_w\"] = (bird_extended.type == \"W\").astype(\"int32\")\n\n# parameter grid\nparams = {\n    'C': [1, 10, 100],\n    'kernel': ['poly', 'rbf'],\n    'degree': [2, 4, 6],\n    'gamma': ['auto', 1, 5, 10]\n}\n\n# SVM for separate ghoul from others.\nsvc = SVC(probability=True)\n\n# split the train and test set.\ntrain_features, test_features, train_labels, test_labels = train_test_split(bird_extended[feature_columns_extended], bird_extended.is_w,\n                                                                            train_size=0.6)\n# grid search.\ngs = GridSearchCV(estimator=svc, param_grid=params, cv=3, refit=True, scoring='recall')\ngs.fit(train_features, train_labels)\nsvc = gs.best_estimator_\n\nprint('\\nBest parameters:')\nfor param_name, param_value in gs.best_params_.items():\n    print('{}:\\t{}'.format(param_name, str(param_value)))\n\nprint('\\nBest score (recall): {:.3f}'.format(gs.best_score_))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ecd879c9-938a-d5a9-5577-efd86cc9b97d"},"outputs":[],"source":"# merics.\npredict_labels = gs.predict(test_features)\npredict_proba = gs.predict_proba(test_features)\nfpr, rc, th = roc_curve(test_labels, predict_proba[:, 1])\nprecision, recall, threshold = precision_recall_curve(test_labels, predict_proba[:, 1])\nroc_auc = auc(fpr, rc)\n\nprint('\\nMetrics: Accuracy: {:.3f}, Precision: {:.3f}, Recall: {:.3f}, AUC: {:.3f}'.format(accuracy_score(test_labels, predict_labels), precision_score(test_labels, predict_labels), recall_score(test_labels, predict_labels), roc_auc))\nprint('\\nClassification Report:')\nprint(classification_report(test_labels, predict_labels, target_names=['no wading birds', 'wading birds']))\n\n# draw some charts.\nfig = plt.figure(figsize=(16, 4))\nax = fig.add_subplot(131)\nax.set_xlabel('False Positive Rate')\nax.set_ylabel('Recall')\nax.set_title('ROC Curve')\nax.plot(fpr, rc, 'b')\nax.plot([0.0, 1.0], [0.0, 1.0], 'r--')\nax.text(0.80, 0.05, 'auc: {:.2f}'.format(roc_auc))\n\nax = fig.add_subplot(132)\nax.set_xlabel('Threshold')\nax.set_ylabel('Precision & Recall')\nax.set_title('Precsion & Recall')\nax.set_xlim([threshold.min(), threshold.max()])\nax.set_ylim([0.0, 1.0])\nax.plot(threshold, precision[:-1], 'b', label='Precision')\nax.plot(threshold, recall[:-1], 'r', label='Recall')\n_ = ax.legend(loc='best')\n\nts = np.arange(0, 1.02, 0.02)\naccuracy = []\nfor t in ts:\n    predict_label = (predict_proba[:, 1] >= t).astype(np.int)\n    accuracy.append(accuracy_score(test_labels, predict_label))\n\nax = fig.add_subplot(133)\nax.set_xlabel(\"Threshold\")\nax.set_ylabel(\"Accuracy\")\nax.set_ylim([0.0, 1.0])\nax.set_title('Accuracy')\nax.plot([0.0, 1.0], [0.5, 0.5], 'r--')\nax.plot(ts, accuracy, 'b')\n\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"9a47e512-546e-3cba-f9ac-430da7527df6"},"source":"Because the number of positive instances and negative instances are unequal (*64:349*), high accuracy is not as a good news as we may think. From the metric chart we see the recall curve falls down steeply meanwhile the precision curve keeps low. It is a difficult unbalanced two-class classification. \n\n**To Be Continued ...** "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c208f5bf-2f4e-f46e-d74e-a7db08a88551"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}