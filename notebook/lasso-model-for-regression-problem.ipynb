{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0,"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6c1b5539-1759-e753-6dae-41f655ad31eb","_active":false},"outputs":[],"source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import Lasso\nfrom sklearn.ensemble import RandomForestRegressor\n%matplotlib inline","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4966d147-a568-0ce2-d84e-6dd84b2c62eb","_active":false},"outputs":[],"source":"train = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a8af6127-0180-983a-8ffd-ec18d569bbb8","_active":false},"outputs":[],"source":"p_poly_val = np.polyfit(train['OverallQual'], train['SalePrice'], 3)\n\nall_data = pd.concat((train.loc[:,'MSSubClass':'SaleCondition'],\n                      test.loc[:,'MSSubClass':'SaleCondition']), ignore_index=True)","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"7ffbc4c8-bf8e-b7ad-8a31-7cd41bfbb1fa","_active":false},"source":"## Imputation of missing values ##","execution_count":null,"outputs":[],"execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"41f21588-54a2-cccf-ebfb-b82f22818d08","_active":false},"outputs":[],"source":"#warnings.simplefilter('ignore', np.RankWarning)\n# I have no idea how to do it better. Probably, it is better to do nothing\nx = all_data.loc[np.logical_not(all_data[\"LotFrontage\"].isnull()), \"LotArea\"]\ny = all_data.loc[np.logical_not(all_data[\"LotFrontage\"].isnull()), \"LotFrontage\"]\n# plt.scatter(x, y)\nt = (x <= 25000) & (y <= 150)\np = np.polyfit(x[t], y[t], 1)\nall_data.loc[all_data['LotFrontage'].isnull(), 'LotFrontage'] = np.polyval(p, all_data.loc[all_data['LotFrontage'].isnull(), 'LotArea'])","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"adad1d8c-1f3a-cc8d-eebd-d0f97110a7da","_active":false},"source":"There are many features were NaN should be considered as absence of such property. In other cases I replace NaN with most common value","execution_count":null,"outputs":[],"execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3bfae950-1716-ccdd-1fe7-c01a0f07cfd3","_active":false},"outputs":[],"source":"all_data = all_data.fillna({\n    'Alley' : 'NoAlley',\n    'MasVnrType': 'None',\n    'FireplaceQu': 'NoFireplace',\n    'GarageType': 'NoGarage',\n    'GarageFinish': 'NoGarage',\n    'GarageQual': 'NoGarage',\n    'GarageCond': 'NoGarage',\n    'BsmtFullBath': 0,\n    'BsmtHalfBath': 0,\n    'BsmtQual' : 'NoBsmt',\n    'BsmtCond' : 'NoBsmt',\n    'BsmtExposure' : 'NoBsmt',\n    'BsmtFinType1' : 'NoBsmt',\n    'BsmtFinType2' : 'NoBsmt',\n    'KitchenQual' : 'TA',\n    'MSZoning' : 'RL',\n    'Utilities' : 'AllPub',\n    'Exterior1st' : 'VinylSd',\n    'Exterior2nd'   : 'VinylSd',\n    'Functional' : 'Typ',\n    'PoolQC' : 'NoPool',\n    'Fence' : 'NoFence',\n    'MiscFeature' : 'None',\n    'Electrical' : 'SBrkr'\n     \n})\n\n\nall_data.loc[all_data.SaleCondition.isnull(), 'SaleCondition'] = 'Normal'\nall_data.loc[all_data.SaleCondition.isnull(), 'SaleType'] = 'WD'\nall_data.loc[all_data.MasVnrType == 'None', 'MasVnrArea'] = 0\nall_data.loc[all_data.BsmtFinType1=='NoBsmt', 'BsmtFinSF1'] = 0\nall_data.loc[all_data.BsmtFinType2=='NoBsmt', 'BsmtFinSF2'] = 0\nall_data.loc[all_data.BsmtFinSF1.isnull(), 'BsmtFinSF1'] = all_data.BsmtFinSF1.median()\nall_data.loc[all_data.BsmtQual=='NoBsmt', 'BsmtUnfSF'] = 0\nall_data.loc[all_data.BsmtUnfSF.isnull(), 'BsmtUnfSF'] = all_data.BsmtUnfSF.median()\nall_data.loc[all_data.BsmtQual=='NoBsmt', 'TotalBsmtSF'] = 0\n\n# only one is null and it has type Detchd\nall_data.loc[all_data['GarageArea'].isnull(), 'GarageArea'] = all_data.loc[all_data['GarageType']=='Detchd', 'GarageArea'].mean()\nall_data.loc[all_data['GarageCars'].isnull(), 'GarageCars'] = all_data.loc[all_data['GarageType']=='Detchd', 'GarageCars'].median()","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"9bb00740-bde7-a678-c29f-fb1e2709105b","_active":false},"source":"## Normalization ##","execution_count":null,"outputs":[],"execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f706c097-313b-d53e-908d-2d02a10868c4","_active":false},"outputs":[],"source":"# where we have order we will use numeric\nall_data = all_data.replace({'Utilities': {'AllPub': 1, 'NoSeWa': 0, 'NoSewr': 0, 'ELO': 0},\n                             'Street': {'Pave': 1, 'Grvl': 0 },\n                             'FireplaceQu': {'Ex': 5, \n                                            'Gd': 4, \n                                            'TA': 3, \n                                            'Fa': 2,\n                                            'Po': 1,\n                                            'NoFireplace': 0 \n                                            },\n                             'Fence': {'GdPrv': 2, \n                                       'GdWo': 2, \n                                       'MnPrv': 1, \n                                       'MnWw': 1,\n                                       'NoFence': 0},\n                             'ExterQual': {'Ex': 5, \n                                            'Gd': 4, \n                                            'TA': 3, \n                                            'Fa': 2,\n                                            'Po': 1\n                                            },\n                             'ExterCond': {'Ex': 5, \n                                            'Gd': 4, \n                                            'TA': 3, \n                                            'Fa': 2,\n                                            'Po': 1\n                                            },\n                             'BsmtQual': {'Ex': 5, \n                                            'Gd': 4, \n                                            'TA': 3, \n                                            'Fa': 2,\n                                            'Po': 1,\n                                            'NoBsmt': 0},\n                             'BsmtExposure': {'Gd': 3, \n                                            'Av': 2, \n                                            'Mn': 1,\n                                            'No': 0,\n                                            'NoBsmt': 0},\n                             'BsmtCond': {'Ex': 5, \n                                            'Gd': 4, \n                                            'TA': 3, \n                                            'Fa': 2,\n                                            'Po': 1,\n                                            'NoBsmt': 0},\n                             'GarageQual': {'Ex': 5, \n                                            'Gd': 4, \n                                            'TA': 3, \n                                            'Fa': 2,\n                                            'Po': 1,\n                                            'NoGarage': 0},\n                             'GarageCond': {'Ex': 5, \n                                            'Gd': 4, \n                                            'TA': 3, \n                                            'Fa': 2,\n                                            'Po': 1,\n                                            'NoGarage': 0},\n                             'KitchenQual': {'Ex': 5, \n                                            'Gd': 4, \n                                            'TA': 3, \n                                            'Fa': 2,\n                                            'Po': 1},\n                             'Functional': {'Typ': 0,\n                                            'Min1': 1,\n                                            'Min2': 1,\n                                            'Mod': 2,\n                                            'Maj1': 3,\n                                            'Maj2': 4,\n                                            'Sev': 5,\n                                            'Sal': 6}                             \n                            })","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a22c83af-1b99-80c5-c9e0-ae3b98fc8277","_active":false},"outputs":[],"source":"all_data = all_data.replace({'CentralAir': {'Y': 1, \n                                            'N': 0}})\nall_data = all_data.replace({'PavedDrive': {'Y': 1, \n                                            'P': 0,\n                                            'N': 0}})\n\nnewer_dwelling = all_data.MSSubClass.replace({20: 1, \n                                            30: 0, \n                                            40: 0, \n                                            45: 0,\n                                            50: 0, \n                                            60: 1,\n                                            70: 0,\n                                            75: 0,\n                                            80: 0,\n                                            85: 0,\n                                            90: 0,\n                                           120: 1,\n                                           150: 0,\n                                           160: 0,\n                                           180: 0,\n                                           190: 0})\nnewer_dwelling.name = 'newer_dwelling'","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fcc7f095-ba43-0377-66bc-8ebdfbb18e31","_active":false},"outputs":[],"source":"all_data = all_data.replace({'MSSubClass': {20: 'SubClass_20', \n                                            30: 'SubClass_30', \n                                            40: 'SubClass_40', \n                                            45: 'SubClass_45',\n                                            50: 'SubClass_50', \n                                            60: 'SubClass_60',\n                                            70: 'SubClass_70',\n                                            75: 'SubClass_75',\n                                            80: 'SubClass_80',\n                                            85: 'SubClass_85',\n                                            90: 'SubClass_90',\n                                           120: 'SubClass_120',\n                                           150: 'SubClass_150',\n                                           160: 'SubClass_160',\n                                           180: 'SubClass_180',\n                                           190: 'SubClass_190'}})","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4245cfd6-86f6-4590-fbf3-3f292f3f0495","_active":false},"outputs":[],"source":"# The idea is good quality should rise price, poor quality - reduce price\noverall_poor_qu = all_data.OverallQual.copy()\noverall_poor_qu = 5 - overall_poor_qu\noverall_poor_qu[overall_poor_qu<0] = 0\noverall_poor_qu.name = 'overall_poor_qu'\n\noverall_good_qu = all_data.OverallQual.copy()\noverall_good_qu = overall_good_qu - 5\noverall_good_qu[overall_good_qu<0] = 0\noverall_good_qu.name = 'overall_good_qu'\n\noverall_poor_cond = all_data.OverallCond.copy()\noverall_poor_cond = 5 - overall_poor_cond\noverall_poor_cond[overall_poor_cond<0] = 0\noverall_poor_cond.name = 'overall_poor_cond'\n\noverall_good_cond = all_data.OverallCond.copy()\noverall_good_cond = overall_good_cond - 5\noverall_good_cond[overall_good_cond<0] = 0\noverall_good_cond.name = 'overall_good_cond'\n\nexter_poor_qu = all_data.ExterQual.copy()\nexter_poor_qu[exter_poor_qu<3] = 1\nexter_poor_qu[exter_poor_qu>=3] = 0\nexter_poor_qu.name = 'exter_poor_qu'\n\nexter_good_qu = all_data.ExterQual.copy()\nexter_good_qu[exter_good_qu<=3] = 0\nexter_good_qu[exter_good_qu>3] = 1\nexter_good_qu.name = 'exter_good_qu'\n\nexter_poor_cond = all_data.ExterCond.copy()\nexter_poor_cond[exter_poor_cond<3] = 1\nexter_poor_cond[exter_poor_cond>=3] = 0\nexter_poor_cond.name = 'exter_poor_cond'\n\nexter_good_cond = all_data.ExterCond.copy()\nexter_good_cond[exter_good_cond<=3] = 0\nexter_good_cond[exter_good_cond>3] = 1\nexter_good_cond.name = 'exter_good_cond'\n\nbsmt_poor_cond = all_data.BsmtCond.copy()\nbsmt_poor_cond[bsmt_poor_cond<3] = 1\nbsmt_poor_cond[bsmt_poor_cond>=3] = 0\nbsmt_poor_cond.name = 'bsmt_poor_cond'\n\nbsmt_good_cond = all_data.BsmtCond.copy()\nbsmt_good_cond[bsmt_good_cond<=3] = 0\nbsmt_good_cond[bsmt_good_cond>3] = 1\nbsmt_good_cond.name = 'bsmt_good_cond'\n\ngarage_poor_qu = all_data.GarageQual.copy()\ngarage_poor_qu[garage_poor_qu<3] = 1\ngarage_poor_qu[garage_poor_qu>=3] = 0\ngarage_poor_qu.name = 'garage_poor_qu'\n\ngarage_good_qu = all_data.GarageQual.copy()\ngarage_good_qu[garage_good_qu<=3] = 0\ngarage_good_qu[garage_good_qu>3] = 1\ngarage_good_qu.name = 'garage_good_qu'\n\ngarage_poor_cond = all_data.GarageCond.copy()\ngarage_poor_cond[garage_poor_cond<3] = 1\ngarage_poor_cond[garage_poor_cond>=3] = 0\ngarage_poor_cond.name = 'garage_poor_cond'\n\ngarage_good_cond = all_data.GarageCond.copy()\ngarage_good_cond[garage_good_cond<=3] = 0\ngarage_good_cond[garage_good_cond>3] = 1\ngarage_good_cond.name = 'garage_good_cond'\n\nkitchen_poor_qu = all_data.KitchenQual.copy()\nkitchen_poor_qu[kitchen_poor_qu<3] = 1\nkitchen_poor_qu[kitchen_poor_qu>=3] = 0\nkitchen_poor_qu.name = 'kitchen_poor_qu'\n\nkitchen_good_qu = all_data.KitchenQual.copy()\nkitchen_good_qu[kitchen_good_qu<=3] = 0\nkitchen_good_qu[kitchen_good_qu>3] = 1\nkitchen_good_qu.name = 'kitchen_good_qu'\n\nqu_list = pd.concat((overall_poor_qu, overall_good_qu, overall_poor_cond, overall_good_cond, exter_poor_qu,\n                     exter_good_qu, exter_poor_cond, exter_good_cond, bsmt_poor_cond, bsmt_good_cond, garage_poor_qu,\n                     garage_good_qu, garage_poor_cond, garage_good_cond, kitchen_poor_qu, kitchen_good_qu), axis=1)\n\nbad_heating = all_data.HeatingQC.replace({'Ex': 0, \n                                          'Gd': 0, \n                                          'TA': 0, \n                                          'Fa': 1,\n                                          'Po': 1})\nbad_heating.name = 'bad_heating'\n                                          \nMasVnrType_Any = all_data.MasVnrType.replace({'BrkCmn': 1,\n                                              'BrkFace': 1,\n                                              'CBlock': 1,\n                                              'Stone': 1,\n                                              'None': 0})\nMasVnrType_Any.name = 'MasVnrType_Any'\n\nSaleCondition_PriceDown = all_data.SaleCondition.replace({'Abnorml': 1,\n                                                          'Alloca': 1,\n                                                          'AdjLand': 1,\n                                                          'Family': 1,\n                                                          'Normal': 0,\n                                                          'Partial': 0})\nSaleCondition_PriceDown.name = 'SaleCondition_PriceDown'\n\nNeighborhood_Good = pd.DataFrame(np.zeros((all_data.shape[0],1)), columns=['Neighborhood_Good'])\nNeighborhood_Good[all_data.Neighborhood=='NridgHt'] = 1\nNeighborhood_Good[all_data.Neighborhood=='Crawfor'] = 1\nNeighborhood_Good[all_data.Neighborhood=='StoneBr'] = 1\nNeighborhood_Good[all_data.Neighborhood=='Somerst'] = 1\nNeighborhood_Good[all_data.Neighborhood=='NoRidge'] = 1\n\n# do smth with BsmtFinType1, BsmtFinType2","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"8cbb3844-4bef-bbad-3d78-6f834300d110","_active":false},"source":"I have no idea what to do with Exterior1st, Exterior2nd, RoofMatl, Condition1, Condition2, BldgType. I'll try convert them into some kind of price brackets","execution_count":null,"outputs":[],"execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f0fdf976-c5bb-fe0b-3ffe-511197bf11b4","_active":false},"outputs":[],"source":"from sklearn.svm import SVC\nsvm = SVC(C=100, gamma=0.0001, kernel='rbf')\n# price categories\npc = pd.Series(np.zeros(train.shape[0]))\npc[:] = 'pc1'\npc[train.SalePrice >= 150000] = 'pc2'\npc[train.SalePrice >= 220000] = 'pc3'\ncolumns_for_pc = ['Exterior1st', 'Exterior2nd', 'RoofMatl', 'Condition1', 'Condition2', 'BldgType']\nX_t = pd.get_dummies(train.loc[:, columns_for_pc], sparse=True)\nsvm.fit(X_t, pc)\npc_pred = svm.predict(X_t)","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b7ecdeae-937b-a58d-befc-4d2b638e1041","_active":false},"outputs":[],"source":"p = train.SalePrice/100000\n#plt.hist(p[pc_pred=='pc1'])\n#plt.hist(p[pc_pred=='pc2'])\n#plt.hist(p[pc_pred=='pc3'])","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b444fe09-fd4b-28e9-a08d-6080f8e9ea1d","_active":false},"outputs":[],"source":"price_category = pd.DataFrame(np.zeros((all_data.shape[0],1)), columns=['pc'])\nX_t = pd.get_dummies(all_data.loc[:, columns_for_pc], sparse=True)\npc_pred = svm.predict(X_t)\nprice_category[pc_pred=='pc2'] = 1\nprice_category[pc_pred=='pc3'] = 2\nprice_category = price_category.to_sparse()","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"df571648-bb68-1eed-ad9f-e924911f4dbf","_active":false},"outputs":[],"source":"# Monthes with the lagest number of deals may be significant\nseason = all_data.MoSold.replace( {1: 0, \n                                   2: 0, \n                                   3: 0, \n                                   4: 1,\n                                   5: 1, \n                                   6: 1,\n                                   7: 1,\n                                   8: 0,\n                                   9: 0,\n                                  10: 0,\n                                  11: 0,\n                                  12: 0})\nseason.name = 'season'\n\n# Numer month is not significant\nall_data = all_data.replace({'MoSold': {1: 'Yan', \n                                        2: 'Feb', \n                                        3: 'Mar', \n                                        4: 'Apr',\n                                        5: 'May', \n                                        6: 'Jun',\n                                        7: 'Jul',\n                                        8: 'Avg',\n                                        9: 'Sep',\n                                        10: 'Oct',\n                                        11: 'Nov',\n                                        12: 'Dec'}})","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7428a0fe-0695-1709-fbee-e57148f7eb39","_active":false},"outputs":[],"source":"#all_data = all_data.replace({'CentralAir': {'Y': 1, \n#                                            'N': 0}})\n#all_data = all_data.replace({'PavedDrive': {'Y': 1, \n #                                           'P': 0,\n#                                           'N': 0}})","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4a4b1ece-a80f-0071-8020-522e9c75fa26","_active":false},"outputs":[],"source":"reconstruct = pd.DataFrame(np.zeros((all_data.shape[0],1)), columns=['Reconstruct'])\nreconstruct[all_data.YrSold < all_data.YearRemodAdd] = 1\nreconstruct = reconstruct.to_sparse()\n\nrecon_after_buy = pd.DataFrame(np.zeros((all_data.shape[0],1)), columns=['ReconstructAfterBuy'])\nrecon_after_buy[all_data.YearRemodAdd >= all_data.YrSold] = 1\nrecon_after_buy = recon_after_buy.to_sparse()\n\nbuild_eq_buy = pd.DataFrame(np.zeros((all_data.shape[0],1)), columns=['Build.eq.Buy'])\nbuild_eq_buy[all_data.YearBuilt >= all_data.YrSold] = 1\nbuild_eq_buy = build_eq_buy.to_sparse()","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4aac1977-9a4c-0dfe-8abc-737cb0c945cb","_active":false},"outputs":[],"source":"# I hope this will help\nall_data.YrSold = 2010 - all_data.YrSold","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"54ee71df-fdcd-00df-6adf-f76453daacdf","_active":false},"outputs":[],"source":"year_map = pd.concat(pd.Series('YearGroup' + str(i+1), index=range(1871+i*20,1891+i*20)) for i in range(0, 7))\nall_data.GarageYrBlt = all_data.GarageYrBlt.map(year_map)\nall_data.loc[all_data['GarageYrBlt'].isnull(), 'GarageYrBlt'] = 'NoGarage'","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"060e746d-16fb-1d41-468a-584b1c5b1cb3","_active":false},"outputs":[],"source":"all_data.YearBuilt = all_data.YearBuilt.map(year_map)\nall_data.YearRemodAdd = all_data.YearRemodAdd.map(year_map)","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"6ebb4194-80fb-a91d-e153-cd38688b4a1d","_active":false},"source":"Scaling numeric data","execution_count":null,"outputs":[],"execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2b153f12-8081-ebe4-e503-3c55c8350618","_active":false},"outputs":[],"source":"numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\nt = all_data[numeric_feats].quantile(.75)\nuse_75_scater = t[t != 0].index\nall_data[use_75_scater] = all_data[use_75_scater]/all_data[use_75_scater].quantile(.75)","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"89aace43-ac8c-3c7d-eaf7-c6d85adec796","_active":false},"outputs":[],"source":"t = ['LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', \n     '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', \n     'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal']\n\nall_data.loc[:, t] = np.log1p(all_data.loc[:, t])","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"063dfaf9-7f49-5c62-655b-8c35d5d2f19e","_active":false},"source":"## Preparing for sklearn##","execution_count":null,"outputs":[],"execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"83da8155-1385-dce5-9e8b-4630ef12ff61","_active":false},"outputs":[],"source":"# all classes in sklearn requires numeric data only\n# transform categorical variable into binary\n#X = pd.get_dummies(all_data, sparse=True)\nX = pd.get_dummies(all_data)\nX = X.fillna(X.median())\n#X = X.fillna(0)\n\nall_data.fillna(all_data.median())\n\nX[\"IsRegularLotShape\"] = (all_data[\"LotShape\"] == \"Reg\") * 1\nX[\"IsLandLevel\"] = (all_data[\"LandContour\"] == \"Lvl\") * 1\n\n# Most land slopes are gentle; treat the others as \"not gentle\".\nX[\"IsLandSlopeGentle\"] = (all_data[\"LandSlope\"] == \"Gtl\") * 1\n\n# Most properties use standard circuit breakers.\nX[\"IsElectricalSBrkr\"] = (all_data[\"Electrical\"] == \"SBrkr\") * 1\n\n# About 2/3rd have an attached garage.\nX[\"IsGarageDetached\"] = (all_data[\"GarageType\"] == \"Detchd\") * 1\n\n# Most have a paved drive. Treat dirt/gravel and partial pavement\n# as \"not paved\".\n#X[\"IsPavedDrive\"] = (all_data[\"PavedDrive\"] == \"Y\") * 1\n\n# The only interesting \"misc. feature\" is the presence of a shed.\nX[\"HasShed\"] = (all_data[\"MiscFeature\"] == \"Shed\") * 1.  \n\n# If YearRemodAdd != YearBuilt, then a remodeling took place at some point.\nX[\"Remodeled\"] = (all_data[\"YearRemodAdd\"] != all_data[\"YearBuilt\"]) * 1\n    \n# Did a remodeling happen in the year the house was sold?\nX[\"RecentRemodel\"] = (all_data[\"YearRemodAdd\"] == all_data[\"YrSold\"]) * 1\n    \n# Was this house sold in the year it was built?\nX[\"VeryNewHouse\"] = (all_data[\"YearBuilt\"] == all_data[\"YrSold\"]) * 1\n\n\n\nX[\"Has2ndFloor\"] = (all_data[\"2ndFlrSF\"] == 0) * 1\nX[\"HasMasVnr\"] = (all_data[\"MasVnrArea\"] == 0) * 1\nX[\"HasWoodDeck\"] = (all_data[\"WoodDeckSF\"] == 0) * 1\nX[\"HasOpenPorch\"] = (all_data[\"OpenPorchSF\"] == 0) * 1\nX[\"HasEnclosedPorch\"] = (all_data[\"EnclosedPorch\"] == 0) * 1\nX[\"Has3SsnPorch\"] = (all_data[\"3SsnPorch\"] == 0) * 1\nX[\"HasScreenPorch\"] = (all_data[\"ScreenPorch\"] == 0) * 1","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a64a33b1-9cd0-986a-bc12-76b30a69f912","_active":false},"outputs":[],"source":"X = X.drop('RoofMatl_ClyTile', axis=1) # only one is not zero\nX = X.drop('Condition2_PosN', axis=1) # only two is not zero\nX = X.drop('MSZoning_C (all)', axis=1)\nX = X.drop('MSSubClass_SubClass_160', axis=1)\n\n# this features definitely couse overfitting\n\ndrop_cols = [\n                \"Exterior1st_ImStucc\", \"Exterior1st_Stone\",\n                \"Exterior2nd_Other\",\"HouseStyle_2.5Fin\", \n            \n                \"RoofMatl_Membran\", \"RoofMatl_Metal\", \"RoofMatl_Roll\",\n                \"Condition2_RRAe\", \"Condition2_RRAn\", \"Condition2_RRNn\",\n                \"Heating_Floor\", \"Heating_OthW\",\n\n                \"Electrical_Mix\", \n                \"MiscFeature_TenC\",\n                #\"GarageQual_Ex\", \n                \"PoolQC_Fa\"\n            ]\n#X.drop(drop_cols, axis=1, inplace=True)","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4c3e142c-018d-484d-1b49-997d671a8b12","_active":false},"outputs":[],"source":"# add new features\nX = pd.concat((X, newer_dwelling, season, reconstruct, recon_after_buy,\n               qu_list, bad_heating, MasVnrType_Any, price_category, build_eq_buy), axis=1)\n\n#fK1 = pd.DataFrame(np.zeros((all_data.shape[0],1), dtype=float), columns=['fK1'])\n##fK1 = all_data.1stFlrSF - all_data.GrLivArea\n##fK1 = all_data.GrLivArea_KitchenQual - all_data.GrLivArea\n#fK1 = all_data.KitchenQual\n#fK1 = fK1.to_sparse()\n\n#X = pd.concat((X, fK1), axis = 1)","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"a3d8ee03-439b-1fe1-0170-2948e08f2fb2","_active":false},"source":"Next step is guess what new feachers we need to intoduse to make the model better. I'll make a lot of feachers and model wiil choose","execution_count":null,"outputs":[],"execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ab19a761-2876-11c8-3fdb-9fbe703872e3","_active":false},"outputs":[],"source":"from itertools import product, chain\n\ndef poly(X):\n    areas = ['LotArea',  'GrLivArea' ,'TotalBsmtSF', 'GarageArea', 'BsmtUnfSF']\n    # t = [s for s in X.axes[1].get_values() if s not in areas]\n    t = chain(qu_list.axes[1].get_values(), \n              ['OverallQual', 'OverallCond', 'ExterQual', 'ExterCond', 'BsmtCond', 'GarageQual', 'GarageCond',\n               'KitchenQual',\n               'HeatingQC', 'bad_heating', 'MasVnrType_Any', 'SaleCondition_PriceDown', 'Reconstruct',\n               'ReconstructAfterBuy', 'Build.eq.Buy'])\n    for a, t in product(areas, t):\n        x = X.loc[:, [a, t]].prod(1)\n        x.name = a + '_' + t\n        yield x\n        \ndef poly1(X):\n    areas = ['LotArea',  'GrLivArea' \n            , 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'WoodDeckSF', 'OpenPorchSF'\n             , 'LowQualFinSF', 'PoolArea'\n            ]#,'TotalBsmtSF']\n    t = chain(qu_list.axes[1].get_values(), \n              ['OverallQual', 'OverallCond', 'ExterQual', 'ExterCond', \n            #   'BsmtCond', \n            #   'GarageQual', 'GarageCond',\n               'KitchenQual',\n               'HeatingQC', 'bad_heating', 'MasVnrType_Any', 'SaleCondition_PriceDown', 'Reconstruct',\n               'ReconstructAfterBuy', 'Build.eq.Buy'])\n    for a, t in product(areas, t):\n        x = X.loc[:, [a, t]].prod(1)\n        x.name = a + '_' + t\n        yield x\n        \ndef polyGarage(X):\n    areas = ['GarageArea']\n    t = chain(qu_list.axes[1].get_values(), \n              ['GarageQual', 'GarageCond'])\n    for a, t in product(areas, t):\n        x = X.loc[:, [a, t]].prod(1)\n        x.name = a + '_' + t\n        yield x\n        \ndef polyBmst(X):\n    areas = [ 'BsmtUnfSF', 'TotalBsmtSF']\n    t = chain(qu_list.axes[1].get_values(), \n              ['OverallQual', 'OverallCond', 'ExterQual', 'ExterCond', 'BsmtCond', \n               'HeatingQC', 'bad_heating', 'MasVnrType_Any', 'SaleCondition_PriceDown', 'Reconstruct',\n               'ReconstructAfterBuy', 'Build.eq.Buy'])\n    for a, t in product(areas, t):\n        x = X.loc[:, [a, t]].prod(1)\n        x.name = a + '_' + t\n        yield x\n        \n\ndef polyCat(X):\n    areas = ['OverallQual', 'OverallCond', 'ExterQual', 'ExterCond', 'BsmtCond',\n             'GarageQual', 'GarageCond',\n               'KitchenQual',\n               #'HeatingQC', \n               'bad_heating', 'MasVnrType_Any', 'SaleCondition_PriceDown', 'Reconstruct',\n               'ReconstructAfterBuy', 'Build.eq.Buy'\n            , 'CentralAir', 'PavedDrive']\n    # t = [s for s in X.axes[1].get_values() if s not in areas]\n    t = chain(qu_list.axes[1].get_values(), \n              ['OverallQual', 'OverallCond', 'ExterQual', 'ExterCond', 'BsmtCond',\n               'GarageQual', 'GarageCond',\n               'KitchenQual',\n               #'HeatingQC',\n               'bad_heating', 'MasVnrType_Any', 'SaleCondition_PriceDown', 'Reconstruct',\n               'ReconstructAfterBuy', 'Build.eq.Buy'\n              , 'CentralAir', 'PavedDrive'])\n    for a, t in product(areas, t):\n        if a == t:\n            continue\n        x = X.loc[:, [a, t]].prod(1)\n        x.name = a + '_AND_' + t\n        yield x\n        \n#XP = pd.concat(poly(X), axis=1)\n#X = pd.concat((X, XP), axis=1)\n\nXP = pd.concat(poly(X), axis=1)\nX = pd.concat((X, XP), axis=1)\n#XP = pd.concat(polyGarage(X), axis=1)\n#X = pd.concat((X, XP), axis=1)\n#XP = pd.concat(polyBmst(X), axis=1)\n#X = pd.concat((X, XP), axis=1)\n#XP = pd.concat(polyCat(X), axis=1)\n#X = pd.concat((X, XP), axis=1)","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cbdd91b4-6ea3-d1bd-3f13-8b92f9265048","_active":false},"outputs":[],"source":"#X = X.drop('BsmtUnfSF_GarageCond', axis = 1)\n\nX_train = X[:train.shape[0]]\nX_test = X[train.shape[0]:]","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b4560804-7a54-6f1f-6781-1b173b55e5cd","_active":false},"outputs":[],"source":"# the model has become really big\nX_train.shape","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b9faea74-013d-0813-9715-44d11b6665ff","_active":false},"outputs":[],"source":"y = np.log1p(train.SalePrice)","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4be5d5c6-91c1-3f5f-c548-82014a276284","_active":false},"outputs":[],"source":"# this come from iterational model improvment. I was trying to understand why the model gives to the two points much better price\n#x_plot = X_train.loc[X_train['SaleCondition_Partial']==1, 'GrLivArea']\n#y_plot = y[X_train['SaleCondition_Partial']==1]\n#plt.scatter(x_plot, y_plot)","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7b9a32b8-a62d-08c0-523c-d70b8dd23140","_active":false},"outputs":[],"source":"outliers_id = np.array([524, 1299])\n\noutliers_id = outliers_id - 1 # id starts with 1, index starts with 0\nX_train = X_train.drop(outliers_id)\ny = y.drop(outliers_id)\n# There are difinetly more outliers\n\nprint(len(X_train))\n\n#y = y[X_train['1stFlrSF'] / X_train['GrLivArea'] > 1.1]\n#X_train = X_train[X_train['1stFlrSF'] / X_train['GrLivArea'] > 1.1]\n\n\n#y = y[X_train['GrLivArea'] / X_train['GrLivArea_KitchenQual'] > 1.3]\n#tX_train = X_train[X_train['GrLivArea'] / X_train['GrLivArea_KitchenQual'] > 1.3]\n#X_train = tX_train\n\nprint(len(X_train))\nprint(len(y))","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1d04b984-f245-56ed-7fd0-5aff233d4e2e","_active":false},"outputs":[],"source":"from sklearn.cross_validation import cross_val_score\nfrom sklearn.metrics import make_scorer, mean_squared_error\n\ndef rmsle(y, y_pred):\n     #return np.sqrt((( (np.log1p(y_pred*price_scale)- np.log1p(y*price_scale)) )**2).mean())\n        return np.sqrt((( (np.log1p(y_pred)- np.log1p(y)) )**2).mean())\n\n# scorer = make_scorer(rmsle, False)\nscorer = make_scorer(mean_squared_error, False)\n\ndef rmse_cv(model, X, y):\n     return (cross_val_score(model, X, y, scoring=scorer, cv = 20)).mean()\n    #return (train_test_split(model, X, y, scoring=scorer, cv = 20)).mean()","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"66d40c8e-cf67-3810-965a-814f140e69c3","_active":false},"source":"## Learning ##\nThe model is sparse with n_features > n_samples. Likely it's linear.  It is classic case to use the Lasso model","execution_count":null,"outputs":[],"execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"af3513a4-b20d-2ed7-705c-c9a57d9d042a","_active":false},"outputs":[],"source":"from sklearn.linear_model import ElasticNet\n\n#pIdx = np.random.permutation(len(y)) \n\n#ratios = [0.4, 0.5,0.6,0.7,0.8,0.9,0.95,0.98, 1.0]\n#alphas = [1e-4, 1.5e-4, 2e-4,  2.25e-4, 2.5e-4, 2.75e-4, 3e-4, 3.5e-4, 4e-4, 5e-4, 7e-4, 1e-3]\n#cv_lasso = [rmse_cv(Lasso(alpha = alpha, max_iter=50000), X_train[pIdx], y[pIdx]) for alpha in alphas]\n#pd.Series(cv_lasso, index = alphas).plot()","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"c1e2a969-b462-9393-5be4-09d042567cef","_active":false},"source":"Choose alpha with better score","execution_count":null,"outputs":[],"execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"93eddc21-2573-06ac-7487-d3ad7180941b","_active":false},"outputs":[],"source":"from sklearn.cross_validation import train_test_split\nfrom sklearn import linear_model\nfrom sklearn.linear_model import RandomizedLasso\nfrom sklearn.kernel_ridge import KernelRidge\n\n\n\n\n#xtrain, xtest, ytrain, ytest = train_test_split(X_train, y, train_size = 0.8, random_state = 96)\nxtrain = X_train\nytrain = y\nxtest = X_train.copy()\nytest = y.copy()\n\n\nxtrainC1 = xtrain[xtrain['1stFlrSF'] / xtrain['GrLivArea'] > 1.1]\nytrainC1 = ytrain[xtrain['1stFlrSF'] / xtrain['GrLivArea'] > 1.1]\nxtrainC2 = xtrain[xtrain['1stFlrSF'] / xtrain['GrLivArea'] <= 1.1]\nytrainC2 = ytrain[xtrain['1stFlrSF'] / xtrain['GrLivArea'] <= 1.1]\n\n#print(len(xtrainC1))\n#print(len(xtrain))\n#ytrainC1 = ytrainC1.append(ytrain)\n#xtrainC1 = xtrainC1.append(xtrain)\n#print(len(xtrainC1))\n#for i in range(2):\n#    ytrainC1 = ytrainC1.append(ytrain[xtrain['1stFlrSF'] / xtrain['GrLivArea'] > 1.1])\n#    xtrainC1 = xtrainC1.append(xtrain[xtrain['1stFlrSF'] / xtrain['GrLivArea'] > 1.1])\n#print(len(xtrainC1))\n    \n    \n#ytrain = ytrain.append(ytrain[xtrain['1stFlrSF'] / xtrain['GrLivArea'] > 1.1])\n#xtrain = xtrain.append(xtrain[xtrain['1stFlrSF'] / xtrain['GrLivArea'] > 1.1])\n#ytrain = ytrain.append(ytrain[xtrain['1stFlrSF'] / xtrain['GrLivArea'] > 1.1])\n#xtrain = xtrain.append(xtrain[xtrain['1stFlrSF'] / xtrain['GrLivArea'] > 1.1])\n\nprint(len(xtest))\n#ytrain = ytrain[xtrain['SaleType_New'] == True]\n#xtrain = xtrain[xtrain['SaleType_New'] == True]\n#ytest = ytest[xtest['SaleType_New'] == True]\n#xtest = xtest[xtest['SaleType_New'] == True]\n#ytest = ytest[y]\n\n#MinY = min(xtrain['GrLivArea'])\n#MaxY = max(xtrain['GrLivArea'])\n#MidY = (MinY + MaxY) / 2\n#ytrain = ytrain[xtrain['GrLivArea'] > MidY]\n#xtrain = xtrain[xtrain['GrLivArea'] > MidY]\n#ytest = ytest[xtest['GrLivArea'] > MidY]\n#xtest = xtest[xtest['GrLivArea'] > MidY]\n\nMinY = min(ytrain)\nMaxY = max(ytrain)\nprint(MinY,MaxY)\nMinY=10.54\nMaxY=13.53\nMidY = (MinY + MaxY) / 2\nMidY1 = MinY + (MaxY - MinY) * 0.55\nxtrainP = xtrain[ytrain > MidY]\nytrainP = ytrain[ytrain > MidY]\n#xtrain = xtrain[ytrain > MidY]\n#ytrain = ytrain[ytrain > MidY]\n#xtest = xtest[ytest > MidY]\n#ytest = ytest[ytest > MidY]\n\n#print(min(ytrain), max(ytrain), min(ytest), max(ytest))\n\n#model_lasso_P = Lasso(alpha=3e-4, max_iter=50000).fit(xtrainP, ytrainP)\n\n#print(len(xtest))\n#print(xtest['OverallQual'])\n\n#initXT = xtrain\n#initYT = ytrain\n#ytrain = ytrain[xtrain['1stFlrSF'] / xtrain['GrLivArea'] > 1.1]\n#xtrain = xtrain[xtrain['1stFlrSF'] / xtrain['GrLivArea'] > 1.1]\n#ytest = ytest[xtest['1stFlrSF'] / xtest['GrLivArea'] > 1.1]\n#xtest = xtest[xtest['1stFlrSF'] / xtest['GrLivArea'] > 1.1]\n\n#model_lasso = Lasso(alpha=5e-4, max_iter=50000).fit(X_train, y)\n\n#xtLen = int(len(xtrain) * 0.995)\n#xtLen1 = int(len(xtrain) * 0.005)\n#xtrain_k1 = xtrain[:xtLen]\n#ytrain_k1 = ytrain[:xtLen]\n#xtrain_k2 = xtrain[xtLen1:]\n#ytrain_k2 = ytrain[xtLen1:]\n\nmodel_lasso = Lasso(alpha=3e-4, max_iter=50000).fit(xtrain, ytrain)\n#model_lasso = ElasticNet(alpha=3e-4, max_iter=50000, l1_ratio= 0.6).fit(xtrain, ytrain)\n\n#model_lasso = Lasso(alpha=2.5e-4, max_iter=50000).fit(xtrain, ytrain)\n#model_lasso_1 = Lasso(alpha=2.8e-4, max_iter=50000).fit(xtrain_k1, ytrain_k1)\n#model_lasso_2 = Lasso(alpha=3.1e-4, max_iter=50000).fit(xtrain_k2, ytrain_k2)\n\n#model_lasso_1 = Lasso(alpha=2.6e-4, max_iter=50000, selection = 'random').fit(xtrain, ytrain)\n#model_lasso_2 = Lasso(alpha=2.8e-4, max_iter=50000, selection = 'random').fit(xtrain, ytrain)\n#model_lasso_3 = Lasso(alpha=3.15e-4, max_iter=50000, selection = 'random').fit(xtrain, ytrain)\n#model_lasso_4 = Lasso(alpha=3.3e-4, max_iter=50000, selection = 'random').fit(xtrain, ytrain)\n#model_lasso_5 = Lasso(alpha=1e-4, max_iter=50000).fit(xtrain, ytrain)\n#model_lasso_6 = Lasso(alpha=5e-4, max_iter=50000).fit(xtrain, ytrain)\n\n#model_lassoC1 = model_lasso\n#model_lassoC1 = Lasso(alpha=3e-4, max_iter=50000).fit(xtrainC1, ytrainC1)\n#model_lassoC2 = Lasso(alpha=6e-4, max_iter=50000).fit(xtrainC2, ytrainC2)\n\n#model_lasso = RandomizedLasso(alpha=5e-4, max_iter=50000).fit(xtrain, ytrain)\n#model_lasso = Lasso(alpha=4e-4, max_iter=50000).fit(xtrain, ytrain)\n#model_lasso = Lasso(alpha=7.5e-4, max_iter=50000).fit(xtrain, ytrain)\n\n\n#model_lasso = linear_model.LogisticRegression().fit(xtrain, ytrain)\n#model_lasso = KernelRidge(alpha=5e-4).fit(xtrain, ytrain)\n\nMinL = min(X_train['GrLivArea'])\nMaxL = max(X_train['GrLivArea'])\n\nprint(len(xtrain))\n\n#xtrain1 = list()\n#xtrain2 = list()\n#ytrain1 = list()\n#ytrain2 = list()\n\n#xtrain1 = np.array([])\n#xtrain2 = np.array([])\n#ytrain1 = np.array([])\n#ytrain2 = np.array([])\n\n#for i in range(len(xtrain)):\n #   if xtrain['GrLivArea'][i] < MinL + (MaxL - MinL) * 0.5:\n#      np.append(xtrain1, xtrain[:][i])\n   #     np.append(ytrain1, ytrain[:][i])\n# else:\n#        np.append(xtrain2, xtrain[:][i])\n #       np.append(ytrain2, ytrain[:][i])\n        \n#print(len(xtrain1))\n#print(len(xtrain2))\n        \n#print(len(xtrain['GrLivArea']  > MinL + (MaxL - MinL) * 0.5))\n\n#model_lasso1 = Lasso(alpha=5e-4, max_iter=50000).fit(xtrain, ytrain)\n\n#x_plot = X_train.loc[:, 'GrLivArea_KitchenQual']\n#y_plot = X_train.loc[:, 'GrLivArea']\n##y_plot = X_train.loc[:, '1stFlrSF']\n#plt.scatter(x_plot, y_plot)","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"27a3f809-5300-758d-f379-0c9ccaf988b5","_active":false},"source":"## Getting results##","execution_count":null,"outputs":[],"execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"09ab72bf-82c6-f2b1-3818-668fef834c62","_active":true,"collapsed":false},"outputs":[],"source":"coef = pd.Series(model_lasso.coef_, index = X_train.columns).sort_values()\n#imp_coef = pd.concat([coef.head(10), coef.tail(10)])\n#imp_coef.plot(kind = \"barh\")\n#plt.title(\"Coefficients in the Model\")\nimp_coef = pd.concat([coef.head(23)])\nimp_coef.plot(kind = \"barh\")\nplt.title(\"Coefficients in the Model         Up\")\n","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"9aefbc31-64a7-9461-8ba0-7a72841589c0","_active":false},"source":"Some features still look suspicious. May be, we need to exlude them like RoofMatl_ClyTile and others","execution_count":null,"outputs":[],"execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f036759b-2fd7-80e5-ecd1-f3facb725451","_active":false,"collapsed":false},"outputs":[],"source":"imp_coef = pd.concat([coef.tail(23)])\nimp_coef.plot(kind = \"barh\")\nplt.title(\"Coefficients in the Model         Down\")\n\n# This is a good way to see how model predict data\nimport xgboost\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom numpy import inf\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#ELASTIC NET\nclf2 = ElasticNet(alpha=0.0005, l1_ratio=0.9)\nclf2.fit(xtrain, ytrain)\nelas_preds = np.expm1(clf2.predict(xtrain))\n\n#XGBOOST\nclf3=xgboost.XGBRegressor(colsample_bytree=0.4,\n                 gamma=0.045,                 \n                 learning_rate=0.07,\n                 max_depth=20,\n                 min_child_weight=1.5,\n                 n_estimators=3000,                                                                    \n                 reg_alpha=0.65,\n                 reg_lambda=0.45,\n                 subsample=0.95)\n\nclf3.fit(xtrain, ytrain)\nxgb_preds = np.expm1(clf3.predict(xtrain))\n\n\n\n#p_pred = np.expm1(model_lasso.predict(xtrain))\np_pred = (np.expm1(model_lasso.predict(xtrain)) \n          #+ np.expm1(model_lasso_1.predict(xtrain)) + np.expm1(model_lasso_2.predict(xtrain))\n          #+ np.expm1(model_lasso_3.predict(xtrain)) + np.expm1(model_lasso_4.predict(xtrain))\n         # + np.expm1(model_lasso_5.predict(xtrain)) + np.expm1(model_lasso_6.predict(xtrain))\n          ) / 1\n\nlasso_preds = p_pred\n\nWK1 = 0.51\nWK2 = 0.24\nWK3 = 0.26\n\n#WK1 = 0.57\n#WK2 = 0.21\n#WK3 = 0.23\n\np_pred = WK1*lasso_preds + WK2*xgb_preds+WK3*elas_preds\n\n#MinY = min(p_pred)\n#MaxY = max(p_pred)\n#MidY = (MinY + MaxY) / 2\n#xtrainP = xtrain[p_pred < MidY]\n#ytrainP = ytrain[p_pred < MidY]\n#print(len(xtrain))\n#rint(len(xtrainP))\n#xtest = xtest[ytest > MidY]\n#ytest = ytest[ytest > MidY]\n\n#idx = 0\n#for index, it in xtrain.iterrows():\n#    if ytrain[index].item() > np.expm1(MidY):\n#    #if p_pred[idx] > np.expm1(MidY):\n#    #if p_pred[idx] > MidY:\n#        p_pred[idx] = np.expm1(model_lasso_P.predict(it))\n#    idx = idx + 1\n\n\n#idx = 0\n#for index, it in xtrain.iterrows():\n#    if it['1stFlrSF'] / it['GrLivArea'] > 1.1:\n#        p_pred[idx] = np.expm1(model_lassoC1.predict(it))\n#    else:\n#        p_pred[idx] = np.expm1(model_lasso.predict(it))\n#    idx = idx + 1\n\nresid = np.expm1(ytrain) - p_pred\n\nX_train_new = X_train\n#X_train_new['GrLivArea']=0\n\nclf = RandomForestRegressor(n_estimators=300, n_jobs=-1, max_features = 0.9,\n                               max_depth = 9, min_samples_split = 25, min_samples_leaf = 10,\n random_state = 36\n                          )\n\n#clfC1 = RandomForestRegressor(n_estimators=300, n_jobs=-1, max_features = 0.9,\n #                              max_depth = 9, min_samples_split = 25, min_samples_leaf = 10,\n# random_state = 36\n #                         )\n\n#clf = MLPRegressor(hidden_layer_sizes = (50, 30), solver = 'adam', random_state = 35,\n#                   alpha = 0.0001, max_iter = 500, activation = 'logistic',\n #                 learning_rate_init = 0.001, batch_size = 40)\n\n#clf = ExtraTreesRegressor(n_estimators=500, max_depth = 6 ,# max_features = 0.5,\n #                          min_samples_split = 25, min_samples_leaf = 10,\n#random_state = 36\n #                        )\n\n#clf = xgboost.XGBRegressor(n_estimators=10, max_depth = 8, colsample_bytree = 0.5,\n##clf = xgboost.XGBRegressor(n_estimators=100, max_depth = 5, colsample_bytree = 0.5,\n #                          min_child_weight = 20, gamma = 0.5, subsample = 0.96,\n#                     #reg_lambda = 0.9, reg_alpha = 0.8, missing = 0,\n  #                seed = 36)\n    \n#clf = SVR(kernel='rbf', C=0.5)\n\n#resid1 = resid[xtrain['OverallQual'] < 1.25]\n#xtrain1 = xtrain[xtrain['OverallQual'] < 1.25]\n\n#xtrain_SY = xtrain.copy()\n#xtrain_SY[\"s1Y\"] = np.log1p(p_pred)\n\nclf.fit(xtrain, resid) \n#clf.fit(xtrain1, resid1) \nprint(\"End train\")\n\nnew_pred = clf.predict(xtrain_SY) + p_pred\n\n\n\n\n#s1_test_pred = np.expm1(model_lasso.predict(xtest))\ns1_test_pred = (np.expm1(model_lasso.predict(xtest)) \n               # + np.expm1(model_lasso_1.predict(xtest)) + np.expm1(model_lasso_2.predict(xtest))\n               # + np.expm1(model_lasso_3.predict(xtest)) + np.expm1(model_lasso_4.predict(xtest))\n               # + np.expm1(model_lasso_5.predict(xtest)) + np.expm1(model_lasso_6.predict(xtest)) \n               ) / 1\n\n#idx = 0\n#for index, it in xtest.iterrows():\n#    if s1_test_pred[idx] > np.expm1(MidY1):\n##   if ytest[index].item() > MidY:\n#        s1_test_pred[idx] = np.expm1(model_lasso_P.predict(it))\n#    idx = idx + 1\n\n#s1_test_pred = np.median( [np.expm1(model_lasso.predict(xtest)),\n #               np.expm1(model_lasso_1.predict(xtest)),\n#              np.expm1(model_lasso_2.predict(xtest)),\n#               np.expm1(model_lasso_3.predict(xtest)),\n #              np.expm1(model_lasso_4.predict(xtest)) ])\n\n#idx = 0\n#for index, it in xtest.iterrows():\n#    if it['1stFlrSF'] / it['GrLivArea'] > 1.1:\n#        s1_test_pred[idx] = np.expm1(model_lassoC1.predict(it))\n#    else:\n#        s1_test_pred[idx] = np.expm1(model_lasso.predict(it))\n#    idx = idx + 1\n\nelas_preds = np.expm1(clf2.predict(xtest))\nxgb_preds = np.expm1(clf3.predict(xtest))\nlasso_preds = s1_test_pred\ns1_test_pred = WK1*lasso_preds + WK2*xgb_preds+WK3*elas_preds\n\n\n\n#xtest[\"s1Y\"] = np.log1p(s1_test_pred)\n\n\n\ntest_pred = s1_test_pred + clf.predict(xtest)\n\nprint(\"Stage 1 score\")\nprint(rmsle(np.expm1(ytest), s1_test_pred))\n\n#idx = 0\n#for index, it in xtest.iterrows():\n#    if test_pred[idx] > np.expm1(MidY1):\n#        s1_test_pred[idx] = np.expm1(model_lasso_P.predict(it))\n#        test_pred[idx] = np.expm1(model_lasso_P.predict(it)) + clf.predict(it)\n#    idx = idx + 1\n\n#lenTest = len(ytest)\n#ytest = ytest[int(lenTest/2):]\n#test_pred = test_pred[int(lenTest/2):]\n#s1_test_pred = s1_test_pred[int(lenTest/2):]\n\n#print(len(xtest))\n#print(len(test_pred))\n#print(len(s1_test_pred))\n\n#xtest.reindex_axis()\n#print(xtest)\n#print()\n#print(ytest)\n\n#for it in test_pred:\n#    if it < min(np.expm1(ytrain)):\n#        it = min(np.expm1(ytrain))\n\nprint(max(np.expm1(ytrain)), max(s1_test_pred))\nprint(min(np.expm1(ytrain)), min(s1_test_pred))\n\n#test_pred[xtest['1stFlrSF'] / xtest['GrLivArea'] < 1.1] = s1_test_pred[xtest['1stFlrSF'] / xtest['GrLivArea'] < 1.1] + clf.predict(xtest[xtest['1stFlrSF'] / xtest['GrLivArea'] < 1.1])\nprint(\"new Lasso\")\n\nup_resid = np.expm1(ytrain) - new_pred \n\n#clf1 = RandomForestRegressor(n_estimators=300, n_jobs=-1, max_features = 0.9,\n #                              max_depth = 5, min_samples_split = 25, min_samples_leaf = 10,\n#random_state = 51\n #                         )   \n\n#clf1 = xgboost.XGBRegressor(n_estimators=10, max_depth = 7, colsample_bytree = 0.5,\n##clf = xgboost.XGBRegressor(n_estimators=100, max_depth = 5, colsample_bytree = 0.5,\n #                          min_child_weight = 20, gamma = 0.5, subsample = 0.96,\n#                   #reg_lambda = 0.9, reg_alpha = 0.8, missing = 0,\n  #                seed = 36)\n\n#clf1 = MLPRegressor(hidden_layer_sizes = (50, 30), solver = 'adam', random_state = 35,\n  #                 alpha = 0.0001, max_iter = 500, activation = 'logistic',\n#               learning_rate_init = 0.001, batch_size = 40)\n    \n#clf1 = MLPRegressor(hidden_layer_sizes = (40, 20), solver = 'adam', random_state = 35,\n #                  alpha = 0.001, max_iter = 300, activation = 'logistic')\n    \n#clf1.fit(xtrain, up_resid)\n#test_pred = test_pred + clf1.predict(xtest)\n\n\n#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\nidx = 0\nfor index, it in xtest.iterrows():\n    if it['OverallQual'] == 1.25:\n        test_pred[idx] = s1_test_pred[idx]\n    idx = idx + 1\n\n\n#model_lasso_up = Lasso(alpha=1e-2, max_iter=200000).fit(xtrain, np.log1p(up_resid))\n#test_pred = test_pred + np.expm1(model_lasso_up.predict(xtest))\n\n#model_lasso_up = Lasso(alpha=1e-3, max_iter=200000).fit(xtrain, up_resid)\n#test_pred = test_pred + model_lasso_up.predict(xtest)\n\n\n#features = X_train.columns\n#imp = clf.feature_importances_\n#fimp = np.argsort(imp)\n#fimp = fimp[-16:]\n#plt.title('Feature Importances')\n#plt.barh(range(len(fimp)), imp[fimp], color='b', align='center')\n#plt.yticks(range(len(fimp)), features[fimp])\n#plt.xlabel('Relative Importance')\n\n\ntp = test_pred[xtest['1stFlrSF'] / xtest['GrLivArea'] < 1.1]\n\n#plt.scatter(new_pred, np.expm1(y))\n#plt.plot([min(new_pred),max(new_pred)], [min(new_pred),max(new_pred)], c=\"red\")\n\n\nprint(\"Stage 1 score\")\nprint(rmsle(np.expm1(ytest), s1_test_pred))\n#print(rmsle(np.expm1(y), p_pred))\nprint(\"Stage 2 score\")\nprint(rmsle(np.expm1(ytest), test_pred))\n\nif(rmsle(np.expm1(ytest), test_pred) < rmsle(np.expm1(ytest), s1_test_pred)):\n    print(\"============== OK =================\")\n#print(rmsle(np.expm1(y), new_pred))","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"ca10ffb3-cc8d-b9a5-dd28-5cdeafd238aa","_active":false},"source":"Some point are far from the red line. May be they are outliers like the 524th and the 1299th","execution_count":null,"outputs":[],"execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6772895c-191f-98dd-b99c-f574a68ebe0c","_active":false},"outputs":[],"source":"# save to file to make a submission\nps1 = (np.expm1(model_lasso.predict(X_test)) \n   #  + np.expm1(model_lasso_1.predict(X_test)) + np.expm1(model_lasso_2.predict(X_test))\n   #  + np.expm1(model_lasso_3.predict(X_test)) + np.expm1(model_lasso_4.predict(X_test))\n     #+ np.expm1(model_lasso_5.predict(X_test)) + np.expm1(model_lasso_6.predict(X_test))\n    ) / 1\n\nelas_preds = np.expm1(clf2.predict(X_test))\nxgb_preds = np.expm1(clf3.predict(X_test))\nlasso_preds = ps1\n\nps1 = WK1*lasso_preds + WK2*xgb_preds+WK3*elas_preds\n\n#idx = 0\n#for index, it in X_test.iterrows():\n#    if it['1stFlrSF'] / it['GrLivArea'] > 1.1:\n#        ps1[idx] = np.expm1(model_lassoC1.predict(it))\n#    else:\n#        ps1[idx] = np.expm1(model_lasso.predict(it))\n#    idx = idx + 1\n\n#X_test[\"s1Y\"] = ps1\n\np = ps1 + clf.predict(X_test)# + clf1.predict(X_test)\n\nidx = 0\nfor index, it in X_test.iterrows():\n    if it['OverallQual'] == 1.25:\n        p[idx] = ps1[idx]\n    idx = idx + 1\n\n#solution = pd.DataFrame({\"id\":test.Id, \"SalePrice\":p}, columns=['id', 'SalePrice'])\nsolution = pd.DataFrame({\"id\":p, \"SalePrice\":test.Id}, columns=['SalePrice', 'id'])\nsolution.to_csv(\"lasso_sol22_Median.csv\", index = False)\nprint(\"Write Solution\")\n\n\n#p_pred = np.expm1(model_lasso.predict(xtrain))\np_pred = (np.expm1(model_lasso.predict(xtrain)) \n          #+ np.expm1(model_lasso_1.predict(xtrain)) + np.expm1(model_lasso_2.predict(xtrain))\n          #+ np.expm1(model_lasso_3.predict(xtrain)) + np.expm1(model_lasso_4.predict(xtrain))\n         # + np.expm1(model_lasso_5.predict(xtrain)) + np.expm1(model_lasso_6.predict(xtrain))\n          ) / 1\n\nlasso_pred = p_pred","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"f05a8111-558e-3d8e-0b91-9febf6e45696","_active":false},"source":"## Model improvement##\nWith various model tunnings I've got 0.11720 in public leaderboard. Ways of improvement are find some more outliers and exlude (or include) features.","execution_count":null,"outputs":[],"execution_state":"idle"}]}